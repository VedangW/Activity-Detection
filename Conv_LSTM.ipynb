{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudeep/.conda/envs/keras_gpu_tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Dropout, LSTM, BatchNormalization, Input,Activation, MaxPool2D, Flatten, Dense,TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "from keras import metrics \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VIDEOS_DIR = './Videos/'\n",
    "IMAGES_DIR = './Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicking',\n",
       " 'Riding-Horse',\n",
       " 'Running',\n",
       " 'SkateBoarding',\n",
       " 'Swing-Bench',\n",
       " 'Lifting',\n",
       " 'Swing-Side',\n",
       " 'Walking',\n",
       " 'Golf-Swing']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['Kicking', 'Riding-Horse', 'Running', 'SkateBoarding', 'Swing-Bench', 'Lifting', 'Swing-Side', 'Walking', 'Golf-Swing']\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Golf-Swing': 8,\n",
       " 'Kicking': 0,\n",
       " 'Lifting': 5,\n",
       " 'Riding-Horse': 1,\n",
       " 'Running': 2,\n",
       " 'SkateBoarding': 3,\n",
       " 'Swing-Bench': 4,\n",
       " 'Swing-Side': 6,\n",
       " 'Walking': 7}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_index = {}\n",
    "for i in range(len(classes)):\n",
    "    class_to_index[classes[i]] = i\n",
    "class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['014',\n",
       "  '009',\n",
       "  '005',\n",
       "  '011',\n",
       "  '010',\n",
       "  '003',\n",
       "  '012',\n",
       "  '006',\n",
       "  '013',\n",
       "  '004',\n",
       "  '016',\n",
       "  '001',\n",
       "  '007',\n",
       "  '002',\n",
       "  '017',\n",
       "  '015'],\n",
       " ['009', '005', '010', '003', '006', '004', '001', '007', '008', '002'],\n",
       " ['009', '005', '010', '006', '004', '001', '007', '008', '002'],\n",
       " ['009', '005', '010', '003', '006', '004', '001', '007', '008', '002'],\n",
       " ['014',\n",
       "  '009',\n",
       "  '005',\n",
       "  '011',\n",
       "  '010',\n",
       "  '003',\n",
       "  '012',\n",
       "  '006',\n",
       "  '013',\n",
       "  '004',\n",
       "  '016',\n",
       "  '001',\n",
       "  '007',\n",
       "  '008',\n",
       "  '002',\n",
       "  '017',\n",
       "  '015'],\n",
       " ['005', '003', '004', '001', '002'],\n",
       " ['009', '005', '011', '010', '003', '006', '004', '001', '007', '008', '002'],\n",
       " ['014',\n",
       "  '009',\n",
       "  '005',\n",
       "  '011',\n",
       "  '010',\n",
       "  '018',\n",
       "  '003',\n",
       "  '012',\n",
       "  '006',\n",
       "  '013',\n",
       "  '004',\n",
       "  '016',\n",
       "  '001',\n",
       "  '019',\n",
       "  '007',\n",
       "  '008',\n",
       "  '002',\n",
       "  '017',\n",
       "  '015'],\n",
       " ['014',\n",
       "  '009',\n",
       "  '005',\n",
       "  '011',\n",
       "  '010',\n",
       "  '003',\n",
       "  '012',\n",
       "  '006',\n",
       "  '013',\n",
       "  '004',\n",
       "  '001',\n",
       "  '007',\n",
       "  '008',\n",
       "  '002']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = []\n",
    "for x in classes:\n",
    "    videos.append(list(os.listdir(VIDEOS_DIR+x+'/')))\n",
    "videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permute(X,Y):\n",
    "    train_size = X.shape[0]\n",
    "    permutation_train = np.random.permutation(train_size)\n",
    "    X = X[permutation_train]\n",
    "    Y = Y[permutation_train]\n",
    "    return X,Y\n",
    "\n",
    "def load_image(path,image_size):\n",
    "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, image_size)\n",
    "    return image\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y\n",
    "\n",
    "def model_predict(model,images):\n",
    "    output = K.function([model.layers[0].input,K.learning_phase()],\n",
    "                        [model.layers[13].output])\n",
    "    return output([images,0])[0]\n",
    "\n",
    "def pad(X_cnn,max_len):\n",
    "    features_len = X_cnn.shape[1]\n",
    "    length = X_cnn.shape[0]\n",
    "    X_cnn = list(X_cnn)\n",
    "    pad_arr = [0 for i in range(features_len)]\n",
    "    for i in range(max_len-length):\n",
    "        X_cnn.append(pad_arr)\n",
    "    return np.array(X_cnn)\n",
    "\n",
    "def evaluate(X_test,Y_test,model):\n",
    "    count = 0\n",
    "    for i in range(len(X_test)):\n",
    "        pred = model.predict(X_test[i])\n",
    "        max_pred = [np.argmax(i) for i in pred]\n",
    "        counts = np.bincount(max_pred)\n",
    "        class_pred = np.argmax(counts)\n",
    "        #class_pred = max_pred\n",
    "        actual = np.argmax(Y_test[i])\n",
    "        #print(\"Max Preds time\", max_pred)\n",
    "        #print(\"Pred\",classes[class_pred],\"Actual\",classes[actual])\n",
    "        #print()\n",
    "        if class_pred == actual:\n",
    "            count += 1\n",
    "    return float(count)/float(len(Y_test)) * 100.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset_for_lstm_strided(image_size, stride = 10, max_len = 40):\n",
    "    \n",
    "    model = load_model('models/Conv/17epochs_valacc_94.h5')\n",
    "    \n",
    "    X_train_images = []\n",
    "    Y_train_images = []\n",
    "    X_test_images = []\n",
    "    Y_test_images = []\n",
    "    \n",
    "    test_videos = [['002', '009'], ['005', '010'], ['007'], \\\n",
    "                   ['003'], ['006', '012'], ['004'], ['008'], ['004', '012'], ['001', '013']]\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        cls = classes[i]\n",
    "        #test_video = random.randint(0,len(videos[i])-1)\n",
    "        test = test_videos[i] \n",
    "        #print(\"Selected Video for test is\",[videos[i][test_video] for test_video in test])\n",
    "\n",
    "        for j in range(len(videos[i])):\n",
    "            vid = videos[i][j]\n",
    "            video_r = VIDEOS_DIR+cls+'/'+ vid +'/'\n",
    "            image_r = IMAGES_DIR+cls+'/'+ vid +'/'\n",
    "            \n",
    "            filelist = sorted(list(os.listdir(image_r)))\n",
    "            X_train_images_class = []\n",
    "            \n",
    "            for file in filelist:\n",
    "                if file.endswith(\".png\"):\n",
    "                    image = load_image(image_r+file,image_size)\n",
    "                    X_train_images_class.append(image)\n",
    "            X_cnn = model_predict(model,np.array(X_train_images_class))\n",
    "            #print(X_cnn.shape)\n",
    "            \n",
    "            del X_train_images_class\n",
    "            X_test_frames = []                                \n",
    "            for k in range(0,X_cnn.shape[0],stride):\n",
    "                lower = k\n",
    "                upper = min(X_cnn.shape[0],k+max_len)\n",
    "                if upper == X_cnn.shape[0]:\n",
    "                    if vid not in test:                \n",
    "                        X_train_images.append(pad(X_cnn[lower:upper],max_len))\n",
    "                        Y_train_images.append(i)\n",
    "                    else:\n",
    "                        X_test_frames.append(pad(X_cnn[lower:upper],max_len))\n",
    "                        X_test_images.append(np.array(X_test_frames))        \n",
    "                        Y_test_images.append(i)\n",
    "                    #print(\"Padded frames\" , lower , \"to\" , upper)\n",
    "                    break\n",
    "                else:\n",
    "                    if vid not in test:                \n",
    "                        X_train_images.append(X_cnn[lower:upper])\n",
    "                        Y_train_images.append(i)\n",
    "                    else:\n",
    "                        X_test_frames.append(X_cnn[lower:upper])\n",
    "                    #print(\"Added frames\" , lower , \"to\" , upper)\n",
    "                    \n",
    "            print(\"Processed\",videos[i][j],\"of\",\"class\",classes[i])\n",
    "\n",
    "        #X_test_images.append(np.array(X_test_frames))        \n",
    "        #Y_test_images.append(i)\n",
    "    return X_train_images,Y_train_images,X_test_images,Y_test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    X_input = Input(input_shape, name = \"Input\")\n",
    "    \n",
    "    X = BatchNormalization(name = 'BatchNorm_1')(X_input)\n",
    "    X = Conv2D(32, (7, 7), strides = (5, 5), name=\"Conv_1a\", padding=\"same\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(32, (3, 3), name = \"Conv_1b\", padding=\"same\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPool2D((2, 2), name = \"Pool_1\")(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    X = Conv2D(32, (3, 3), name =\"Conv_2\", padding = \"same\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPool2D((4, 4), name = \"Pool_2\")(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    X = Conv2D(8,(1,1), name='Conv_1x1')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    return Model(X_input, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CNN_model(prev_model):\n",
    "    X = Dense(9,activation='softmax',name='final')(prev_model.output)\n",
    "    return Model(prev_model.input, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "BatchNorm_1 (BatchNormalizat (None, 172, 172, 3)       12        \n",
      "_________________________________________________________________\n",
      "Conv_1a (Conv2D)             (None, 35, 35, 32)        4736      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_1b (Conv2D)             (None, 35, 35, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_1 (MaxPooling2D)        (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 17, 17, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_2 (MaxPooling2D)        (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "Conv_1x1 (Conv2D)            (None, 4, 4, 8)           264       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 23,508\n",
      "Trainable params: 23,502\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model((172, 172, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "BatchNorm_1 (BatchNormalizat (None, 172, 172, 3)       12        \n",
      "_________________________________________________________________\n",
      "Conv_1a (Conv2D)             (None, 35, 35, 32)        4736      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_1b (Conv2D)             (None, 35, 35, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_1 (MaxPooling2D)        (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 17, 17, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_2 (MaxPooling2D)        (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "Conv_1x1 (Conv2D)            (None, 4, 4, 8)           264       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "final (Dense)                (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 24,669\n",
      "Trainable params: 24,663\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN_model(model)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.compile(loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'], \n",
    "            optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_model(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    X = LSTM(32, return_sequences=True)(X_input)\n",
    "    X = Dropout(0.3)(X)\n",
    "    X = LSTM(32, return_sequences=False)(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "    X = Dense(9,activation='softmax')(X)\n",
    "    return Model(X_input, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30, 32)            20608     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 29,225\n",
      "Trainable params: 29,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn = rnn_model((30,128))\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.compile(loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'], \n",
    "            optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_loader(stride=10, max_len=40):\n",
    "    X_train = None\n",
    "    Y_train = None\n",
    "    X_test = None\n",
    "    Y_test = None\n",
    "    try:\n",
    "        os.path.exists('Numpy/LSTM_Strided/train_X_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "        X_train = np.load('Numpy/LSTM_Strided/train_X_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "        Y_train = np.load('Numpy/LSTM_Strided/train_Y_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "        X_test = np.load('Numpy/LSTM_Strided/test_X_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "        Y_test = np.load('Numpy/LSTM_Strided/test_Y_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "    except FileNotFoundError:\n",
    "        X_train,Y_train,X_test,Y_test = build_dataset_for_lstm_strided((172,172), stride, max_len)\n",
    "        X_train = np.array(X_train)\n",
    "        X_test = np.array(X_test)\n",
    "        Y_train = convert_to_one_hot(np.array(Y_train),9)\n",
    "        Y_test = convert_to_one_hot(np.array(Y_test),9)\n",
    "\n",
    "        np.save('Numpy/LSTM_Strided/train_X_'+str(stride)+'_'+str(max_len)+'.npy',X_train)\n",
    "        np.save('Numpy/LSTM_Strided/train_Y_'+str(stride)+'_'+str(max_len)+'.npy',Y_train)\n",
    "        np.save('Numpy/LSTM_Strided/test_X_'+str(stride)+'_'+str(max_len)+'.npy',X_test)\n",
    "        np.save('Numpy/LSTM_Strided/test_Y_'+str(stride)+'_'+str(max_len)+'.npy',Y_test)\n",
    "    print(\"Training\")    \n",
    "    print(\"Shape X\",X_train.shape)\n",
    "    print(\"Shape Y\",Y_train.shape)\n",
    "    print()\n",
    "    print(\"Test\")\n",
    "    print(\"Shape X\",X_test.shape)\n",
    "    print(\"Shape Y\",Y_test.shape)\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded frames 0 to 23\n",
      "Processed 014 of class Kicking\n",
      "Padded frames 0 to 22\n",
      "Processed 009 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 005 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 011 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 010 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 003 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 012 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 006 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 013 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 004 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 016 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 001 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 007 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 002 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 017 of class Kicking\n",
      "Padded frames 0 to 23\n",
      "Processed 015 of class Kicking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 58\n",
      "Processed 009 of class Riding-Horse\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 005 of class Riding-Horse\n",
      "Added frames 0 to 30\n",
      "Padded frames 10 to 36\n",
      "Processed 010 of class Riding-Horse\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 003 of class Riding-Horse\n",
      "Added frames 0 to 30\n",
      "Padded frames 10 to 39\n",
      "Processed 006 of class Riding-Horse\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 004 of class Riding-Horse\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 001 of class Riding-Horse\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 57\n",
      "Processed 007 of class Riding-Horse\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 008 of class Riding-Horse\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 002 of class Riding-Horse\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 65\n",
      "Processed 009 of class Running\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 65\n",
      "Processed 005 of class Running\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 65\n",
      "Processed 010 of class Running\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 65\n",
      "Processed 006 of class Running\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 65\n",
      "Processed 004 of class Running\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 65\n",
      "Processed 001 of class Running\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 65\n",
      "Processed 007 of class Running\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 65\n",
      "Processed 008 of class Running\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 65\n",
      "Processed 002 of class Running\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 70\n",
      "Processed 009 of class SkateBoarding\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 70\n",
      "Processed 005 of class SkateBoarding\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 70\n",
      "Processed 010 of class SkateBoarding\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 70\n",
      "Processed 003 of class SkateBoarding\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 70\n",
      "Processed 006 of class SkateBoarding\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 70\n",
      "Processed 004 of class SkateBoarding\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 70\n",
      "Processed 001 of class SkateBoarding\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 70\n",
      "Processed 007 of class SkateBoarding\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 70\n",
      "Processed 008 of class SkateBoarding\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Padded frames 40 to 70\n",
      "Processed 002 of class SkateBoarding\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 014 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 009 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 005 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 011 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 010 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 003 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 012 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 006 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 013 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 004 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 016 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 001 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 007 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 008 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 002 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 017 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Padded frames 20 to 50\n",
      "Processed 015 of class Swing-Bench\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Added frames 80 to 110\n",
      "Added frames 90 to 120\n",
      "Padded frames 100 to 127\n",
      "Processed 005 of class Lifting\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Added frames 80 to 110\n",
      "Added frames 90 to 120\n",
      "Padded frames 100 to 123\n",
      "Processed 003 of class Lifting\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Added frames 80 to 110\n",
      "Added frames 90 to 120\n",
      "Padded frames 100 to 122\n",
      "Processed 004 of class Lifting\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Added frames 80 to 110\n",
      "Padded frames 90 to 113\n",
      "Processed 001 of class Lifting\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Added frames 80 to 110\n",
      "Padded frames 90 to 111\n",
      "Processed 002 of class Lifting\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Padded frames 50 to 75\n",
      "Processed 009 of class Swing-Side\n",
      "Padded frames 0 to 4\n",
      "Processed 005 of class Swing-Side\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Padded frames 50 to 75\n",
      "Processed 011 of class Swing-Side\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Padded frames 50 to 75\n",
      "Processed 010 of class Swing-Side\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded frames 0 to 3\n",
      "Processed 003 of class Swing-Side\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Padded frames 50 to 75\n",
      "Processed 006 of class Swing-Side\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Padded frames 50 to 75\n",
      "Processed 004 of class Swing-Side\n",
      "Added frames 0 to 30\n",
      "Padded frames 10 to 35\n",
      "Processed 001 of class Swing-Side\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Padded frames 50 to 75\n",
      "Processed 007 of class Swing-Side\n",
      "Padded frames 0 to 14\n",
      "Processed 008 of class Swing-Side\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Padded frames 50 to 75\n",
      "Processed 002 of class Swing-Side\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 101\n",
      "Processed 014 of class Walking\n",
      "Added frames 0 to 30\n",
      "Padded frames 10 to 37\n",
      "Processed 009 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 101\n",
      "Processed 005 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 101\n",
      "Processed 011 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 101\n",
      "Processed 010 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 109\n",
      "Processed 018 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 101\n",
      "Processed 003 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 012 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 102\n",
      "Processed 006 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 101\n",
      "Processed 013 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 101\n",
      "Processed 004 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Added frames 80 to 110\n",
      "Added frames 90 to 120\n",
      "Added frames 100 to 130\n",
      "Added frames 110 to 140\n",
      "Padded frames 120 to 144\n",
      "Processed 016 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 101\n",
      "Processed 001 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 101\n",
      "Processed 019 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 103\n",
      "Processed 007 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Padded frames 70 to 95\n",
      "Processed 008 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 101\n",
      "Processed 002 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Padded frames 50 to 71\n",
      "Processed 017 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Added frames 30 to 60\n",
      "Added frames 40 to 70\n",
      "Added frames 50 to 80\n",
      "Added frames 60 to 90\n",
      "Added frames 70 to 100\n",
      "Padded frames 80 to 101\n",
      "Processed 015 of class Walking\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 014 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 009 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 005 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 011 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 010 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 003 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 012 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 006 of class Golf-Swing\n",
      "Padded frames 0 to 17\n",
      "Processed 013 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 004 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 001 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 007 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 008 of class Golf-Swing\n",
      "Added frames 0 to 30\n",
      "Added frames 10 to 40\n",
      "Added frames 20 to 50\n",
      "Padded frames 30 to 60\n",
      "Processed 002 of class Golf-Swing\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data_loader(stride=7, max_len=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Shape X (456, 30, 128)\n",
      "Shape Y (456, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train_rnn,Y_train_rnn = permute(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 30, 128),\n",
       " (1, 30, 128),\n",
       " (4, 30, 128),\n",
       " (2, 30, 128),\n",
       " (5, 30, 128),\n",
       " (5, 30, 128),\n",
       " (3, 30, 128),\n",
       " (3, 30, 128),\n",
       " (11, 30, 128),\n",
       " (1, 30, 128),\n",
       " (4, 30, 128),\n",
       " (9, 30, 128),\n",
       " (1, 30, 128),\n",
       " (4, 30, 128)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search():\n",
    "    results = {}\n",
    "    histories = {}\n",
    "    strides = [5, 7, 11, 13]\n",
    "    lengths = [20, 30, 40, 50]\n",
    "    for stride in strides:\n",
    "        for length in lengths:\n",
    "            rnn = rnn_model((length,128))\n",
    "            X_train, Y_train, X_test, Y_test = data_loader(stride, length)\n",
    "            X_train_rnn,Y_train_rnn = permute(X_train,Y_train)\n",
    "            rnn.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "            histories[str(stride) + '_' + str(length)] = rnn.fit(X_train_rnn, Y_train_rnn, epochs=100, batch_size = X_train_rnn.shape[0], validation_split=0.2)\n",
    "            rnn.save('models/LSTM_Strided/100ep_double_LSTM_dropout_'+ str(stride) + '_' + str(length)+'.h5')\n",
    "            results[str(stride) + '_' + str(length)] = evaluate(X_test, Y_test, rnn)\n",
    "    return results, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Shape X (957, 20, 128)\n",
      "Shape Y (957, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 765 samples, validate on 192 samples\n",
      "Epoch 1/100\n",
      "765/765 [==============================] - 2s 2ms/step - loss: 2.1601 - acc: 0.1869 - val_loss: 2.0984 - val_acc: 0.2812\n",
      "Epoch 2/100\n",
      "765/765 [==============================] - 0s 425us/step - loss: 2.1045 - acc: 0.2654 - val_loss: 2.0434 - val_acc: 0.3750\n",
      "Epoch 3/100\n",
      "765/765 [==============================] - 0s 424us/step - loss: 2.0562 - acc: 0.3150 - val_loss: 1.9897 - val_acc: 0.4479\n",
      "Epoch 4/100\n",
      "765/765 [==============================] - 0s 392us/step - loss: 1.9905 - acc: 0.3987 - val_loss: 1.9378 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "765/765 [==============================] - 0s 380us/step - loss: 1.9369 - acc: 0.4641 - val_loss: 1.8877 - val_acc: 0.5312\n",
      "Epoch 6/100\n",
      "765/765 [==============================] - 0s 394us/step - loss: 1.8947 - acc: 0.5085 - val_loss: 1.8385 - val_acc: 0.5833\n",
      "Epoch 7/100\n",
      "765/765 [==============================] - 0s 377us/step - loss: 1.8409 - acc: 0.5346 - val_loss: 1.7901 - val_acc: 0.6302\n",
      "Epoch 8/100\n",
      "765/765 [==============================] - 0s 385us/step - loss: 1.7888 - acc: 0.5856 - val_loss: 1.7418 - val_acc: 0.6719\n",
      "Epoch 9/100\n",
      "765/765 [==============================] - 0s 377us/step - loss: 1.7395 - acc: 0.6026 - val_loss: 1.6933 - val_acc: 0.6875\n",
      "Epoch 10/100\n",
      "765/765 [==============================] - 0s 381us/step - loss: 1.7042 - acc: 0.6327 - val_loss: 1.6448 - val_acc: 0.7135\n",
      "Epoch 11/100\n",
      "765/765 [==============================] - 0s 376us/step - loss: 1.6343 - acc: 0.6562 - val_loss: 1.5962 - val_acc: 0.7240\n",
      "Epoch 12/100\n",
      "765/765 [==============================] - 0s 380us/step - loss: 1.6000 - acc: 0.6902 - val_loss: 1.5474 - val_acc: 0.7240\n",
      "Epoch 13/100\n",
      "765/765 [==============================] - 0s 403us/step - loss: 1.5501 - acc: 0.7059 - val_loss: 1.4980 - val_acc: 0.7292\n",
      "Epoch 14/100\n",
      "765/765 [==============================] - 0s 521us/step - loss: 1.5060 - acc: 0.7176 - val_loss: 1.4484 - val_acc: 0.7292\n",
      "Epoch 15/100\n",
      "765/765 [==============================] - 0s 535us/step - loss: 1.4622 - acc: 0.7137 - val_loss: 1.4000 - val_acc: 0.7396\n",
      "Epoch 16/100\n",
      "765/765 [==============================] - 0s 428us/step - loss: 1.4145 - acc: 0.7203 - val_loss: 1.3529 - val_acc: 0.7448\n",
      "Epoch 17/100\n",
      "765/765 [==============================] - 0s 473us/step - loss: 1.3556 - acc: 0.7425 - val_loss: 1.3068 - val_acc: 0.7448\n",
      "Epoch 18/100\n",
      "765/765 [==============================] - 0s 411us/step - loss: 1.3305 - acc: 0.7503 - val_loss: 1.2622 - val_acc: 0.7604\n",
      "Epoch 19/100\n",
      "765/765 [==============================] - 0s 428us/step - loss: 1.2775 - acc: 0.7529 - val_loss: 1.2188 - val_acc: 0.7812\n",
      "Epoch 20/100\n",
      "765/765 [==============================] - 0s 463us/step - loss: 1.2271 - acc: 0.7582 - val_loss: 1.1764 - val_acc: 0.7865\n",
      "Epoch 21/100\n",
      "765/765 [==============================] - 0s 538us/step - loss: 1.1990 - acc: 0.7804 - val_loss: 1.1350 - val_acc: 0.7917\n",
      "Epoch 22/100\n",
      "765/765 [==============================] - 0s 410us/step - loss: 1.1539 - acc: 0.7817 - val_loss: 1.0950 - val_acc: 0.7917\n",
      "Epoch 23/100\n",
      "765/765 [==============================] - 0s 408us/step - loss: 1.1234 - acc: 0.7935 - val_loss: 1.0564 - val_acc: 0.8125\n",
      "Epoch 24/100\n",
      "765/765 [==============================] - 0s 428us/step - loss: 1.0911 - acc: 0.7922 - val_loss: 1.0191 - val_acc: 0.8281\n",
      "Epoch 25/100\n",
      "765/765 [==============================] - 0s 425us/step - loss: 1.0449 - acc: 0.8039 - val_loss: 0.9836 - val_acc: 0.8385\n",
      "Epoch 26/100\n",
      "765/765 [==============================] - 0s 423us/step - loss: 1.0152 - acc: 0.8196 - val_loss: 0.9495 - val_acc: 0.8594\n",
      "Epoch 27/100\n",
      "765/765 [==============================] - 0s 438us/step - loss: 0.9768 - acc: 0.8209 - val_loss: 0.9168 - val_acc: 0.8594\n",
      "Epoch 28/100\n",
      "765/765 [==============================] - 0s 435us/step - loss: 0.9632 - acc: 0.8418 - val_loss: 0.8857 - val_acc: 0.8594\n",
      "Epoch 29/100\n",
      "765/765 [==============================] - 0s 539us/step - loss: 0.9281 - acc: 0.8340 - val_loss: 0.8559 - val_acc: 0.8646\n",
      "Epoch 30/100\n",
      "765/765 [==============================] - 0s 439us/step - loss: 0.9079 - acc: 0.8431 - val_loss: 0.8274 - val_acc: 0.8750\n",
      "Epoch 31/100\n",
      "765/765 [==============================] - 0s 409us/step - loss: 0.8409 - acc: 0.8588 - val_loss: 0.7998 - val_acc: 0.8854\n",
      "Epoch 32/100\n",
      "765/765 [==============================] - 0s 425us/step - loss: 0.8468 - acc: 0.8680 - val_loss: 0.7732 - val_acc: 0.8906\n",
      "Epoch 33/100\n",
      "765/765 [==============================] - 0s 408us/step - loss: 0.7936 - acc: 0.8797 - val_loss: 0.7474 - val_acc: 0.8958\n",
      "Epoch 34/100\n",
      "765/765 [==============================] - 0s 427us/step - loss: 0.7776 - acc: 0.8797 - val_loss: 0.7224 - val_acc: 0.8958\n",
      "Epoch 35/100\n",
      "765/765 [==============================] - 0s 492us/step - loss: 0.7632 - acc: 0.8797 - val_loss: 0.6985 - val_acc: 0.9010\n",
      "Epoch 36/100\n",
      "765/765 [==============================] - 0s 445us/step - loss: 0.7306 - acc: 0.8980 - val_loss: 0.6757 - val_acc: 0.9010\n",
      "Epoch 37/100\n",
      "765/765 [==============================] - 0s 484us/step - loss: 0.7047 - acc: 0.9020 - val_loss: 0.6541 - val_acc: 0.9062\n",
      "Epoch 38/100\n",
      "765/765 [==============================] - 0s 535us/step - loss: 0.6830 - acc: 0.9111 - val_loss: 0.6332 - val_acc: 0.9062\n",
      "Epoch 39/100\n",
      "765/765 [==============================] - 0s 529us/step - loss: 0.6636 - acc: 0.8993 - val_loss: 0.6133 - val_acc: 0.9323\n",
      "Epoch 40/100\n",
      "765/765 [==============================] - 0s 468us/step - loss: 0.6542 - acc: 0.9085 - val_loss: 0.5942 - val_acc: 0.9375\n",
      "Epoch 41/100\n",
      "765/765 [==============================] - 0s 533us/step - loss: 0.6297 - acc: 0.9072 - val_loss: 0.5759 - val_acc: 0.9427\n",
      "Epoch 42/100\n",
      "765/765 [==============================] - 0s 507us/step - loss: 0.6116 - acc: 0.9216 - val_loss: 0.5580 - val_acc: 0.9479\n",
      "Epoch 43/100\n",
      "765/765 [==============================] - 0s 403us/step - loss: 0.5935 - acc: 0.9190 - val_loss: 0.5405 - val_acc: 0.9479\n",
      "Epoch 44/100\n",
      "765/765 [==============================] - 0s 465us/step - loss: 0.5674 - acc: 0.9242 - val_loss: 0.5233 - val_acc: 0.9479\n",
      "Epoch 45/100\n",
      "765/765 [==============================] - 0s 448us/step - loss: 0.5544 - acc: 0.9242 - val_loss: 0.5065 - val_acc: 0.9479\n",
      "Epoch 46/100\n",
      "765/765 [==============================] - 0s 418us/step - loss: 0.5533 - acc: 0.9268 - val_loss: 0.4899 - val_acc: 0.9479\n",
      "Epoch 47/100\n",
      "765/765 [==============================] - 0s 407us/step - loss: 0.5268 - acc: 0.9281 - val_loss: 0.4729 - val_acc: 0.9479\n",
      "Epoch 48/100\n",
      "765/765 [==============================] - 0s 421us/step - loss: 0.5185 - acc: 0.9333 - val_loss: 0.4565 - val_acc: 0.9479\n",
      "Epoch 49/100\n",
      "765/765 [==============================] - 0s 385us/step - loss: 0.5019 - acc: 0.9333 - val_loss: 0.4412 - val_acc: 0.9479\n",
      "Epoch 50/100\n",
      "765/765 [==============================] - 0s 494us/step - loss: 0.4830 - acc: 0.9346 - val_loss: 0.4263 - val_acc: 0.9479\n",
      "Epoch 51/100\n",
      "765/765 [==============================] - 0s 499us/step - loss: 0.4661 - acc: 0.9412 - val_loss: 0.4113 - val_acc: 0.9531\n",
      "Epoch 52/100\n",
      "765/765 [==============================] - 0s 385us/step - loss: 0.4572 - acc: 0.9425 - val_loss: 0.3967 - val_acc: 0.9583\n",
      "Epoch 53/100\n",
      "765/765 [==============================] - 0s 381us/step - loss: 0.4439 - acc: 0.9451 - val_loss: 0.3825 - val_acc: 0.9583\n",
      "Epoch 54/100\n",
      "765/765 [==============================] - 0s 448us/step - loss: 0.4337 - acc: 0.9490 - val_loss: 0.3687 - val_acc: 0.9583\n",
      "Epoch 55/100\n",
      "765/765 [==============================] - 0s 420us/step - loss: 0.4172 - acc: 0.9542 - val_loss: 0.3555 - val_acc: 0.9688\n",
      "Epoch 56/100\n",
      "765/765 [==============================] - 0s 431us/step - loss: 0.4027 - acc: 0.9516 - val_loss: 0.3427 - val_acc: 0.9688\n",
      "Epoch 57/100\n",
      "765/765 [==============================] - 0s 396us/step - loss: 0.3945 - acc: 0.9542 - val_loss: 0.3303 - val_acc: 0.9688\n",
      "Epoch 58/100\n",
      "765/765 [==============================] - 0s 378us/step - loss: 0.3836 - acc: 0.9529 - val_loss: 0.3182 - val_acc: 0.9688\n",
      "Epoch 59/100\n",
      "765/765 [==============================] - 0s 407us/step - loss: 0.3675 - acc: 0.9556 - val_loss: 0.3064 - val_acc: 0.9688\n",
      "Epoch 60/100\n",
      "765/765 [==============================] - 0s 394us/step - loss: 0.3605 - acc: 0.9542 - val_loss: 0.2949 - val_acc: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "765/765 [==============================] - 0s 394us/step - loss: 0.3497 - acc: 0.9608 - val_loss: 0.2837 - val_acc: 0.9740\n",
      "Epoch 62/100\n",
      "765/765 [==============================] - 0s 366us/step - loss: 0.3321 - acc: 0.9582 - val_loss: 0.2725 - val_acc: 0.9740\n",
      "Epoch 63/100\n",
      "765/765 [==============================] - 0s 353us/step - loss: 0.3170 - acc: 0.9647 - val_loss: 0.2618 - val_acc: 0.9740\n",
      "Epoch 64/100\n",
      "765/765 [==============================] - 0s 348us/step - loss: 0.3171 - acc: 0.9621 - val_loss: 0.2513 - val_acc: 0.9740\n",
      "Epoch 65/100\n",
      "765/765 [==============================] - 0s 349us/step - loss: 0.2935 - acc: 0.9634 - val_loss: 0.2420 - val_acc: 0.9740\n",
      "Epoch 66/100\n",
      "765/765 [==============================] - 0s 349us/step - loss: 0.2851 - acc: 0.9673 - val_loss: 0.2334 - val_acc: 0.9740\n",
      "Epoch 67/100\n",
      "765/765 [==============================] - 0s 355us/step - loss: 0.2811 - acc: 0.9660 - val_loss: 0.2251 - val_acc: 0.9740\n",
      "Epoch 68/100\n",
      "765/765 [==============================] - 0s 350us/step - loss: 0.2715 - acc: 0.9686 - val_loss: 0.2173 - val_acc: 0.9740\n",
      "Epoch 69/100\n",
      "765/765 [==============================] - 0s 350us/step - loss: 0.2621 - acc: 0.9712 - val_loss: 0.2099 - val_acc: 0.9740\n",
      "Epoch 70/100\n",
      "765/765 [==============================] - 0s 356us/step - loss: 0.2555 - acc: 0.9673 - val_loss: 0.2028 - val_acc: 0.9740\n",
      "Epoch 71/100\n",
      "765/765 [==============================] - 0s 363us/step - loss: 0.2553 - acc: 0.9686 - val_loss: 0.1960 - val_acc: 0.9740\n",
      "Epoch 72/100\n",
      "765/765 [==============================] - 0s 352us/step - loss: 0.2409 - acc: 0.9712 - val_loss: 0.1894 - val_acc: 0.9740\n",
      "Epoch 73/100\n",
      "765/765 [==============================] - 0s 353us/step - loss: 0.2420 - acc: 0.9686 - val_loss: 0.1831 - val_acc: 0.9740\n",
      "Epoch 74/100\n",
      "765/765 [==============================] - 0s 357us/step - loss: 0.2239 - acc: 0.9673 - val_loss: 0.1770 - val_acc: 0.9740\n",
      "Epoch 75/100\n",
      "765/765 [==============================] - 0s 358us/step - loss: 0.2088 - acc: 0.9725 - val_loss: 0.1712 - val_acc: 0.9740\n",
      "Epoch 76/100\n",
      "765/765 [==============================] - 0s 355us/step - loss: 0.2196 - acc: 0.9712 - val_loss: 0.1654 - val_acc: 0.9740\n",
      "Epoch 77/100\n",
      "765/765 [==============================] - 0s 354us/step - loss: 0.2035 - acc: 0.9725 - val_loss: 0.1598 - val_acc: 0.9740\n",
      "Epoch 78/100\n",
      "765/765 [==============================] - 0s 351us/step - loss: 0.2053 - acc: 0.9739 - val_loss: 0.1543 - val_acc: 0.9740\n",
      "Epoch 79/100\n",
      "765/765 [==============================] - 0s 346us/step - loss: 0.1952 - acc: 0.9739 - val_loss: 0.1490 - val_acc: 0.9740\n",
      "Epoch 80/100\n",
      "765/765 [==============================] - 0s 349us/step - loss: 0.1930 - acc: 0.9712 - val_loss: 0.1442 - val_acc: 0.9740\n",
      "Epoch 81/100\n",
      "765/765 [==============================] - 0s 354us/step - loss: 0.1869 - acc: 0.9739 - val_loss: 0.1397 - val_acc: 0.9740\n",
      "Epoch 82/100\n",
      "765/765 [==============================] - 0s 362us/step - loss: 0.1762 - acc: 0.9752 - val_loss: 0.1357 - val_acc: 0.9740\n",
      "Epoch 83/100\n",
      "765/765 [==============================] - 0s 355us/step - loss: 0.1716 - acc: 0.9765 - val_loss: 0.1319 - val_acc: 0.9740\n",
      "Epoch 84/100\n",
      "765/765 [==============================] - 0s 356us/step - loss: 0.1735 - acc: 0.9712 - val_loss: 0.1280 - val_acc: 0.9740\n",
      "Epoch 85/100\n",
      "765/765 [==============================] - 0s 347us/step - loss: 0.1676 - acc: 0.9725 - val_loss: 0.1239 - val_acc: 0.9740\n",
      "Epoch 86/100\n",
      "765/765 [==============================] - 0s 354us/step - loss: 0.1606 - acc: 0.9739 - val_loss: 0.1198 - val_acc: 0.9740\n",
      "Epoch 87/100\n",
      "765/765 [==============================] - 0s 360us/step - loss: 0.1540 - acc: 0.9752 - val_loss: 0.1161 - val_acc: 0.9792\n",
      "Epoch 88/100\n",
      "765/765 [==============================] - 0s 354us/step - loss: 0.1509 - acc: 0.9778 - val_loss: 0.1128 - val_acc: 0.9792\n",
      "Epoch 89/100\n",
      "765/765 [==============================] - 0s 352us/step - loss: 0.1463 - acc: 0.9739 - val_loss: 0.1097 - val_acc: 0.9792\n",
      "Epoch 90/100\n",
      "765/765 [==============================] - 0s 353us/step - loss: 0.1451 - acc: 0.9752 - val_loss: 0.1066 - val_acc: 0.9792\n",
      "Epoch 91/100\n",
      "765/765 [==============================] - 0s 354us/step - loss: 0.1390 - acc: 0.9765 - val_loss: 0.1035 - val_acc: 0.9792\n",
      "Epoch 92/100\n",
      "765/765 [==============================] - 0s 356us/step - loss: 0.1428 - acc: 0.9752 - val_loss: 0.1005 - val_acc: 0.9792\n",
      "Epoch 93/100\n",
      "765/765 [==============================] - 0s 357us/step - loss: 0.1329 - acc: 0.9778 - val_loss: 0.0976 - val_acc: 0.9792\n",
      "Epoch 94/100\n",
      "765/765 [==============================] - 0s 364us/step - loss: 0.1305 - acc: 0.9752 - val_loss: 0.0949 - val_acc: 0.9792\n",
      "Epoch 95/100\n",
      "765/765 [==============================] - 0s 355us/step - loss: 0.1269 - acc: 0.9765 - val_loss: 0.0922 - val_acc: 0.9792\n",
      "Epoch 96/100\n",
      "765/765 [==============================] - 0s 359us/step - loss: 0.1189 - acc: 0.9778 - val_loss: 0.0897 - val_acc: 0.9792\n",
      "Epoch 97/100\n",
      "765/765 [==============================] - 0s 354us/step - loss: 0.1243 - acc: 0.9752 - val_loss: 0.0873 - val_acc: 0.9792\n",
      "Epoch 98/100\n",
      "765/765 [==============================] - 0s 357us/step - loss: 0.1170 - acc: 0.9765 - val_loss: 0.0849 - val_acc: 0.9792\n",
      "Epoch 99/100\n",
      "765/765 [==============================] - 0s 356us/step - loss: 0.1192 - acc: 0.9752 - val_loss: 0.0827 - val_acc: 0.9792\n",
      "Epoch 100/100\n",
      "765/765 [==============================] - 0s 363us/step - loss: 0.1095 - acc: 0.9791 - val_loss: 0.0805 - val_acc: 0.9792\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (781, 30, 128)\n",
      "Shape Y (781, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 624 samples, validate on 157 samples\n",
      "Epoch 1/100\n",
      "624/624 [==============================] - 2s 3ms/step - loss: 2.2615 - acc: 0.0849 - val_loss: 2.1795 - val_acc: 0.1529\n",
      "Epoch 2/100\n",
      "624/624 [==============================] - 0s 528us/step - loss: 2.1881 - acc: 0.1250 - val_loss: 2.1234 - val_acc: 0.2484\n",
      "Epoch 3/100\n",
      "624/624 [==============================] - 0s 532us/step - loss: 2.1337 - acc: 0.1955 - val_loss: 2.0692 - val_acc: 0.3057\n",
      "Epoch 4/100\n",
      "624/624 [==============================] - 0s 526us/step - loss: 2.0835 - acc: 0.2532 - val_loss: 2.0180 - val_acc: 0.3439\n",
      "Epoch 5/100\n",
      "624/624 [==============================] - 0s 528us/step - loss: 2.0313 - acc: 0.3077 - val_loss: 1.9694 - val_acc: 0.4650\n",
      "Epoch 6/100\n",
      "624/624 [==============================] - 0s 522us/step - loss: 1.9806 - acc: 0.3574 - val_loss: 1.9224 - val_acc: 0.5096\n",
      "Epoch 7/100\n",
      "624/624 [==============================] - 0s 550us/step - loss: 1.9456 - acc: 0.4135 - val_loss: 1.8763 - val_acc: 0.5478\n",
      "Epoch 8/100\n",
      "624/624 [==============================] - 0s 547us/step - loss: 1.8900 - acc: 0.4663 - val_loss: 1.8294 - val_acc: 0.5796\n",
      "Epoch 9/100\n",
      "624/624 [==============================] - 0s 531us/step - loss: 1.8452 - acc: 0.5144 - val_loss: 1.7839 - val_acc: 0.5987\n",
      "Epoch 10/100\n",
      "624/624 [==============================] - 0s 536us/step - loss: 1.7938 - acc: 0.5641 - val_loss: 1.7380 - val_acc: 0.6688\n",
      "Epoch 11/100\n",
      "624/624 [==============================] - 0s 538us/step - loss: 1.7530 - acc: 0.6154 - val_loss: 1.6925 - val_acc: 0.6879\n",
      "Epoch 12/100\n",
      "624/624 [==============================] - 0s 533us/step - loss: 1.7090 - acc: 0.6474 - val_loss: 1.6486 - val_acc: 0.7197\n",
      "Epoch 13/100\n",
      "624/624 [==============================] - 0s 555us/step - loss: 1.6701 - acc: 0.6795 - val_loss: 1.6050 - val_acc: 0.7325\n",
      "Epoch 14/100\n",
      "624/624 [==============================] - 0s 541us/step - loss: 1.6116 - acc: 0.6987 - val_loss: 1.5616 - val_acc: 0.7580\n",
      "Epoch 15/100\n",
      "624/624 [==============================] - 0s 531us/step - loss: 1.5844 - acc: 0.7067 - val_loss: 1.5176 - val_acc: 0.7898\n",
      "Epoch 16/100\n",
      "624/624 [==============================] - 0s 544us/step - loss: 1.5310 - acc: 0.7468 - val_loss: 1.4733 - val_acc: 0.8153\n",
      "Epoch 17/100\n",
      "624/624 [==============================] - 0s 539us/step - loss: 1.5013 - acc: 0.7516 - val_loss: 1.4291 - val_acc: 0.8153\n",
      "Epoch 18/100\n",
      "624/624 [==============================] - 0s 528us/step - loss: 1.4541 - acc: 0.7548 - val_loss: 1.3851 - val_acc: 0.8217\n",
      "Epoch 19/100\n",
      "624/624 [==============================] - 0s 568us/step - loss: 1.4121 - acc: 0.7676 - val_loss: 1.3406 - val_acc: 0.8153\n",
      "Epoch 20/100\n",
      "624/624 [==============================] - 0s 538us/step - loss: 1.3777 - acc: 0.7628 - val_loss: 1.2950 - val_acc: 0.8408\n",
      "Epoch 21/100\n",
      "624/624 [==============================] - 0s 539us/step - loss: 1.3371 - acc: 0.7917 - val_loss: 1.2495 - val_acc: 0.8408\n",
      "Epoch 22/100\n",
      "624/624 [==============================] - 0s 540us/step - loss: 1.2754 - acc: 0.8061 - val_loss: 1.2041 - val_acc: 0.8790\n",
      "Epoch 23/100\n",
      "624/624 [==============================] - 0s 542us/step - loss: 1.2615 - acc: 0.7869 - val_loss: 1.1586 - val_acc: 0.8790\n",
      "Epoch 24/100\n",
      "624/624 [==============================] - 0s 538us/step - loss: 1.2175 - acc: 0.8205 - val_loss: 1.1129 - val_acc: 0.8917\n",
      "Epoch 25/100\n",
      "624/624 [==============================] - 0s 541us/step - loss: 1.1859 - acc: 0.8333 - val_loss: 1.0669 - val_acc: 0.8981\n",
      "Epoch 26/100\n",
      "624/624 [==============================] - 0s 541us/step - loss: 1.1068 - acc: 0.8397 - val_loss: 1.0207 - val_acc: 0.9299\n",
      "Epoch 27/100\n",
      "624/624 [==============================] - 0s 536us/step - loss: 1.1090 - acc: 0.8462 - val_loss: 0.9751 - val_acc: 0.9236\n",
      "Epoch 28/100\n",
      "624/624 [==============================] - 0s 541us/step - loss: 1.0561 - acc: 0.8462 - val_loss: 0.9310 - val_acc: 0.9172\n",
      "Epoch 29/100\n",
      "624/624 [==============================] - 0s 549us/step - loss: 1.0083 - acc: 0.8686 - val_loss: 0.8882 - val_acc: 0.9045\n",
      "Epoch 30/100\n",
      "624/624 [==============================] - 0s 537us/step - loss: 0.9680 - acc: 0.8846 - val_loss: 0.8465 - val_acc: 0.9045\n",
      "Epoch 31/100\n",
      "624/624 [==============================] - 0s 546us/step - loss: 0.9338 - acc: 0.8702 - val_loss: 0.8056 - val_acc: 0.9108\n",
      "Epoch 32/100\n",
      "624/624 [==============================] - 0s 535us/step - loss: 0.8887 - acc: 0.8958 - val_loss: 0.7652 - val_acc: 0.9172\n",
      "Epoch 33/100\n",
      "624/624 [==============================] - 0s 536us/step - loss: 0.8592 - acc: 0.8958 - val_loss: 0.7260 - val_acc: 0.9236\n",
      "Epoch 34/100\n",
      "624/624 [==============================] - 0s 537us/step - loss: 0.8272 - acc: 0.8958 - val_loss: 0.6877 - val_acc: 0.9427\n",
      "Epoch 35/100\n",
      "624/624 [==============================] - 0s 540us/step - loss: 0.7734 - acc: 0.9183 - val_loss: 0.6507 - val_acc: 0.9490\n",
      "Epoch 36/100\n",
      "624/624 [==============================] - 0s 535us/step - loss: 0.7670 - acc: 0.9119 - val_loss: 0.6154 - val_acc: 0.9554\n",
      "Epoch 37/100\n",
      "624/624 [==============================] - 0s 542us/step - loss: 0.7197 - acc: 0.9199 - val_loss: 0.5809 - val_acc: 0.9554\n",
      "Epoch 38/100\n",
      "624/624 [==============================] - 0s 528us/step - loss: 0.6874 - acc: 0.9167 - val_loss: 0.5474 - val_acc: 0.9554\n",
      "Epoch 39/100\n",
      "624/624 [==============================] - 0s 536us/step - loss: 0.6645 - acc: 0.9295 - val_loss: 0.5155 - val_acc: 0.9682\n",
      "Epoch 40/100\n",
      "624/624 [==============================] - 0s 539us/step - loss: 0.6147 - acc: 0.9375 - val_loss: 0.4851 - val_acc: 0.9682\n",
      "Epoch 41/100\n",
      "624/624 [==============================] - 0s 536us/step - loss: 0.5943 - acc: 0.9375 - val_loss: 0.4559 - val_acc: 0.9809\n",
      "Epoch 42/100\n",
      "624/624 [==============================] - 0s 541us/step - loss: 0.5558 - acc: 0.9503 - val_loss: 0.4282 - val_acc: 0.9809\n",
      "Epoch 43/100\n",
      "624/624 [==============================] - 0s 535us/step - loss: 0.5382 - acc: 0.9503 - val_loss: 0.4018 - val_acc: 0.9809\n",
      "Epoch 44/100\n",
      "624/624 [==============================] - 0s 541us/step - loss: 0.5076 - acc: 0.9583 - val_loss: 0.3775 - val_acc: 0.9809\n",
      "Epoch 45/100\n",
      "624/624 [==============================] - 0s 534us/step - loss: 0.4928 - acc: 0.9519 - val_loss: 0.3555 - val_acc: 0.9809\n",
      "Epoch 46/100\n",
      "624/624 [==============================] - 0s 537us/step - loss: 0.4542 - acc: 0.9567 - val_loss: 0.3353 - val_acc: 0.9809\n",
      "Epoch 47/100\n",
      "624/624 [==============================] - 0s 531us/step - loss: 0.4412 - acc: 0.9615 - val_loss: 0.3165 - val_acc: 0.9809\n",
      "Epoch 48/100\n",
      "624/624 [==============================] - 0s 538us/step - loss: 0.4243 - acc: 0.9631 - val_loss: 0.2991 - val_acc: 0.9873\n",
      "Epoch 49/100\n",
      "624/624 [==============================] - 0s 539us/step - loss: 0.4064 - acc: 0.9631 - val_loss: 0.2832 - val_acc: 0.9873\n",
      "Epoch 50/100\n",
      "624/624 [==============================] - 0s 542us/step - loss: 0.3921 - acc: 0.9712 - val_loss: 0.2684 - val_acc: 0.9873\n",
      "Epoch 51/100\n",
      "624/624 [==============================] - 0s 536us/step - loss: 0.3754 - acc: 0.9696 - val_loss: 0.2540 - val_acc: 0.9873\n",
      "Epoch 52/100\n",
      "624/624 [==============================] - 0s 544us/step - loss: 0.3608 - acc: 0.9712 - val_loss: 0.2400 - val_acc: 0.9873\n",
      "Epoch 53/100\n",
      "624/624 [==============================] - 0s 546us/step - loss: 0.3449 - acc: 0.9744 - val_loss: 0.2275 - val_acc: 0.9873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "624/624 [==============================] - 0s 524us/step - loss: 0.3345 - acc: 0.9712 - val_loss: 0.2161 - val_acc: 0.9873\n",
      "Epoch 55/100\n",
      "624/624 [==============================] - 0s 535us/step - loss: 0.3066 - acc: 0.9744 - val_loss: 0.2053 - val_acc: 0.9873\n",
      "Epoch 56/100\n",
      "624/624 [==============================] - 0s 541us/step - loss: 0.3073 - acc: 0.9760 - val_loss: 0.1953 - val_acc: 0.9873\n",
      "Epoch 57/100\n",
      "624/624 [==============================] - 0s 529us/step - loss: 0.2835 - acc: 0.9728 - val_loss: 0.1859 - val_acc: 0.9873\n",
      "Epoch 58/100\n",
      "624/624 [==============================] - 0s 531us/step - loss: 0.2768 - acc: 0.9744 - val_loss: 0.1768 - val_acc: 0.9873\n",
      "Epoch 59/100\n",
      "624/624 [==============================] - 0s 533us/step - loss: 0.2660 - acc: 0.9712 - val_loss: 0.1682 - val_acc: 0.9936\n",
      "Epoch 60/100\n",
      "624/624 [==============================] - 0s 531us/step - loss: 0.2662 - acc: 0.9728 - val_loss: 0.1601 - val_acc: 0.9936\n",
      "Epoch 61/100\n",
      "624/624 [==============================] - 0s 535us/step - loss: 0.2498 - acc: 0.9760 - val_loss: 0.1525 - val_acc: 0.9936\n",
      "Epoch 62/100\n",
      "624/624 [==============================] - 0s 537us/step - loss: 0.2396 - acc: 0.9760 - val_loss: 0.1456 - val_acc: 0.9936\n",
      "Epoch 63/100\n",
      "624/624 [==============================] - 0s 536us/step - loss: 0.2344 - acc: 0.9760 - val_loss: 0.1394 - val_acc: 0.9936\n",
      "Epoch 64/100\n",
      "624/624 [==============================] - 0s 537us/step - loss: 0.2185 - acc: 0.9728 - val_loss: 0.1335 - val_acc: 0.9936\n",
      "Epoch 65/100\n",
      "624/624 [==============================] - 0s 535us/step - loss: 0.2111 - acc: 0.9776 - val_loss: 0.1281 - val_acc: 0.9936\n",
      "Epoch 66/100\n",
      "624/624 [==============================] - 0s 532us/step - loss: 0.2117 - acc: 0.9760 - val_loss: 0.1230 - val_acc: 0.9936\n",
      "Epoch 67/100\n",
      "624/624 [==============================] - 0s 537us/step - loss: 0.1918 - acc: 0.9744 - val_loss: 0.1181 - val_acc: 0.9936\n",
      "Epoch 68/100\n",
      "624/624 [==============================] - 0s 549us/step - loss: 0.2046 - acc: 0.9760 - val_loss: 0.1134 - val_acc: 0.9936\n",
      "Epoch 69/100\n",
      "624/624 [==============================] - 0s 547us/step - loss: 0.1979 - acc: 0.9744 - val_loss: 0.1089 - val_acc: 0.9936\n",
      "Epoch 70/100\n",
      "624/624 [==============================] - 0s 528us/step - loss: 0.1863 - acc: 0.9744 - val_loss: 0.1044 - val_acc: 0.9936\n",
      "Epoch 71/100\n",
      "624/624 [==============================] - 0s 543us/step - loss: 0.1829 - acc: 0.9760 - val_loss: 0.1001 - val_acc: 0.9936\n",
      "Epoch 72/100\n",
      "624/624 [==============================] - 0s 534us/step - loss: 0.1724 - acc: 0.9760 - val_loss: 0.0961 - val_acc: 0.9936\n",
      "Epoch 73/100\n",
      "624/624 [==============================] - 0s 524us/step - loss: 0.1644 - acc: 0.9744 - val_loss: 0.0922 - val_acc: 0.9936\n",
      "Epoch 74/100\n",
      "624/624 [==============================] - 0s 551us/step - loss: 0.1606 - acc: 0.9776 - val_loss: 0.0885 - val_acc: 0.9936\n",
      "Epoch 75/100\n",
      "624/624 [==============================] - 0s 533us/step - loss: 0.1571 - acc: 0.9760 - val_loss: 0.0850 - val_acc: 0.9936\n",
      "Epoch 76/100\n",
      "624/624 [==============================] - 0s 528us/step - loss: 0.1563 - acc: 0.9792 - val_loss: 0.0818 - val_acc: 0.9936\n",
      "Epoch 77/100\n",
      "624/624 [==============================] - 0s 533us/step - loss: 0.1485 - acc: 0.9760 - val_loss: 0.0787 - val_acc: 0.9936\n",
      "Epoch 78/100\n",
      "624/624 [==============================] - 0s 534us/step - loss: 0.1449 - acc: 0.9792 - val_loss: 0.0759 - val_acc: 0.9936\n",
      "Epoch 79/100\n",
      "624/624 [==============================] - 0s 525us/step - loss: 0.1417 - acc: 0.9776 - val_loss: 0.0732 - val_acc: 0.9936\n",
      "Epoch 80/100\n",
      "624/624 [==============================] - 0s 540us/step - loss: 0.1441 - acc: 0.9792 - val_loss: 0.0706 - val_acc: 0.9936\n",
      "Epoch 81/100\n",
      "624/624 [==============================] - 0s 540us/step - loss: 0.1328 - acc: 0.9808 - val_loss: 0.0683 - val_acc: 0.9936\n",
      "Epoch 82/100\n",
      "624/624 [==============================] - 0s 533us/step - loss: 0.1337 - acc: 0.9792 - val_loss: 0.0661 - val_acc: 0.9936\n",
      "Epoch 83/100\n",
      "624/624 [==============================] - 0s 539us/step - loss: 0.1339 - acc: 0.9760 - val_loss: 0.0640 - val_acc: 0.9936\n",
      "Epoch 84/100\n",
      "624/624 [==============================] - 0s 542us/step - loss: 0.1244 - acc: 0.9808 - val_loss: 0.0621 - val_acc: 0.9936\n",
      "Epoch 85/100\n",
      "624/624 [==============================] - 0s 523us/step - loss: 0.1228 - acc: 0.9776 - val_loss: 0.0602 - val_acc: 0.9936\n",
      "Epoch 86/100\n",
      "624/624 [==============================] - 0s 530us/step - loss: 0.1167 - acc: 0.9776 - val_loss: 0.0584 - val_acc: 0.9936\n",
      "Epoch 87/100\n",
      "624/624 [==============================] - 0s 535us/step - loss: 0.1203 - acc: 0.9776 - val_loss: 0.0567 - val_acc: 0.9936\n",
      "Epoch 88/100\n",
      "624/624 [==============================] - 0s 545us/step - loss: 0.1119 - acc: 0.9792 - val_loss: 0.0550 - val_acc: 0.9936\n",
      "Epoch 89/100\n",
      "624/624 [==============================] - 0s 542us/step - loss: 0.1118 - acc: 0.9792 - val_loss: 0.0534 - val_acc: 0.9936\n",
      "Epoch 90/100\n",
      "624/624 [==============================] - 0s 534us/step - loss: 0.1077 - acc: 0.9792 - val_loss: 0.0518 - val_acc: 0.9936\n",
      "Epoch 91/100\n",
      "624/624 [==============================] - 0s 532us/step - loss: 0.1035 - acc: 0.9840 - val_loss: 0.0502 - val_acc: 0.9936\n",
      "Epoch 92/100\n",
      "624/624 [==============================] - 0s 533us/step - loss: 0.1082 - acc: 0.9872 - val_loss: 0.0486 - val_acc: 0.9936\n",
      "Epoch 93/100\n",
      "624/624 [==============================] - 0s 540us/step - loss: 0.1028 - acc: 0.9808 - val_loss: 0.0471 - val_acc: 0.9936\n",
      "Epoch 94/100\n",
      "624/624 [==============================] - 0s 529us/step - loss: 0.1024 - acc: 0.9840 - val_loss: 0.0456 - val_acc: 0.9936\n",
      "Epoch 95/100\n",
      "624/624 [==============================] - 0s 535us/step - loss: 0.0946 - acc: 0.9840 - val_loss: 0.0442 - val_acc: 0.9936\n",
      "Epoch 96/100\n",
      "624/624 [==============================] - 0s 549us/step - loss: 0.1023 - acc: 0.9792 - val_loss: 0.0429 - val_acc: 0.9936\n",
      "Epoch 97/100\n",
      "624/624 [==============================] - 0s 537us/step - loss: 0.0971 - acc: 0.9824 - val_loss: 0.0418 - val_acc: 0.9936\n",
      "Epoch 98/100\n",
      "624/624 [==============================] - 0s 530us/step - loss: 0.0966 - acc: 0.9840 - val_loss: 0.0407 - val_acc: 0.9936\n",
      "Epoch 99/100\n",
      "624/624 [==============================] - 0s 537us/step - loss: 0.0938 - acc: 0.9840 - val_loss: 0.0397 - val_acc: 0.9936\n",
      "Epoch 100/100\n",
      "624/624 [==============================] - 0s 525us/step - loss: 0.0887 - acc: 0.9856 - val_loss: 0.0388 - val_acc: 0.9936\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (620, 40, 128)\n",
      "Shape Y (620, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 496 samples, validate on 124 samples\n",
      "Epoch 1/100\n",
      "496/496 [==============================] - 2s 4ms/step - loss: 2.1442 - acc: 0.1714 - val_loss: 2.0665 - val_acc: 0.2742\n",
      "Epoch 2/100\n",
      "496/496 [==============================] - 0s 712us/step - loss: 2.0743 - acc: 0.2540 - val_loss: 2.0115 - val_acc: 0.3548\n",
      "Epoch 3/100\n",
      "496/496 [==============================] - 0s 692us/step - loss: 2.0363 - acc: 0.3004 - val_loss: 1.9601 - val_acc: 0.3952\n",
      "Epoch 4/100\n",
      "496/496 [==============================] - 0s 689us/step - loss: 1.9553 - acc: 0.4032 - val_loss: 1.9126 - val_acc: 0.5081\n",
      "Epoch 5/100\n",
      "496/496 [==============================] - 0s 703us/step - loss: 1.9097 - acc: 0.4516 - val_loss: 1.8654 - val_acc: 0.5565\n",
      "Epoch 6/100\n",
      "496/496 [==============================] - 0s 732us/step - loss: 1.8616 - acc: 0.4718 - val_loss: 1.8237 - val_acc: 0.6129\n",
      "Epoch 7/100\n",
      "496/496 [==============================] - 0s 732us/step - loss: 1.8021 - acc: 0.5605 - val_loss: 1.7829 - val_acc: 0.6290\n",
      "Epoch 8/100\n",
      "496/496 [==============================] - 0s 737us/step - loss: 1.7600 - acc: 0.5988 - val_loss: 1.7415 - val_acc: 0.6290\n",
      "Epoch 9/100\n",
      "496/496 [==============================] - 0s 731us/step - loss: 1.7346 - acc: 0.6129 - val_loss: 1.6988 - val_acc: 0.7097\n",
      "Epoch 10/100\n",
      "496/496 [==============================] - 0s 721us/step - loss: 1.6716 - acc: 0.6613 - val_loss: 1.6541 - val_acc: 0.7339\n",
      "Epoch 11/100\n",
      "496/496 [==============================] - 0s 731us/step - loss: 1.6321 - acc: 0.6855 - val_loss: 1.6079 - val_acc: 0.7339\n",
      "Epoch 12/100\n",
      "496/496 [==============================] - 0s 714us/step - loss: 1.5711 - acc: 0.6996 - val_loss: 1.5619 - val_acc: 0.7500\n",
      "Epoch 13/100\n",
      "496/496 [==============================] - 0s 730us/step - loss: 1.5464 - acc: 0.7157 - val_loss: 1.5167 - val_acc: 0.7661\n",
      "Epoch 14/100\n",
      "496/496 [==============================] - 0s 730us/step - loss: 1.5045 - acc: 0.7460 - val_loss: 1.4712 - val_acc: 0.7903\n",
      "Epoch 15/100\n",
      "496/496 [==============================] - 0s 718us/step - loss: 1.4633 - acc: 0.7339 - val_loss: 1.4262 - val_acc: 0.8226\n",
      "Epoch 16/100\n",
      "496/496 [==============================] - 0s 721us/step - loss: 1.4224 - acc: 0.7520 - val_loss: 1.3811 - val_acc: 0.8145\n",
      "Epoch 17/100\n",
      "496/496 [==============================] - 0s 722us/step - loss: 1.3751 - acc: 0.7802 - val_loss: 1.3369 - val_acc: 0.7984\n",
      "Epoch 18/100\n",
      "496/496 [==============================] - 0s 729us/step - loss: 1.3367 - acc: 0.7984 - val_loss: 1.2924 - val_acc: 0.8226\n",
      "Epoch 19/100\n",
      "496/496 [==============================] - 0s 720us/step - loss: 1.3174 - acc: 0.7722 - val_loss: 1.2496 - val_acc: 0.8145\n",
      "Epoch 20/100\n",
      "496/496 [==============================] - 0s 742us/step - loss: 1.2585 - acc: 0.8004 - val_loss: 1.2086 - val_acc: 0.8145\n",
      "Epoch 21/100\n",
      "496/496 [==============================] - 0s 727us/step - loss: 1.2127 - acc: 0.8125 - val_loss: 1.1671 - val_acc: 0.8145\n",
      "Epoch 22/100\n",
      "496/496 [==============================] - 0s 722us/step - loss: 1.1823 - acc: 0.8065 - val_loss: 1.1257 - val_acc: 0.8306\n",
      "Epoch 23/100\n",
      "496/496 [==============================] - 0s 727us/step - loss: 1.1528 - acc: 0.8145 - val_loss: 1.0874 - val_acc: 0.8387\n",
      "Epoch 24/100\n",
      "496/496 [==============================] - 0s 733us/step - loss: 1.1191 - acc: 0.8226 - val_loss: 1.0507 - val_acc: 0.8387\n",
      "Epoch 25/100\n",
      "496/496 [==============================] - 0s 722us/step - loss: 1.0762 - acc: 0.8407 - val_loss: 1.0144 - val_acc: 0.8468\n",
      "Epoch 26/100\n",
      "496/496 [==============================] - 0s 727us/step - loss: 1.0298 - acc: 0.8387 - val_loss: 0.9796 - val_acc: 0.8548\n",
      "Epoch 27/100\n",
      "496/496 [==============================] - 0s 736us/step - loss: 0.9897 - acc: 0.8367 - val_loss: 0.9456 - val_acc: 0.8548\n",
      "Epoch 28/100\n",
      "496/496 [==============================] - 0s 732us/step - loss: 0.9617 - acc: 0.8448 - val_loss: 0.9125 - val_acc: 0.8548\n",
      "Epoch 29/100\n",
      "496/496 [==============================] - 0s 712us/step - loss: 0.9465 - acc: 0.8347 - val_loss: 0.8801 - val_acc: 0.8629\n",
      "Epoch 30/100\n",
      "496/496 [==============================] - 0s 733us/step - loss: 0.8934 - acc: 0.8548 - val_loss: 0.8489 - val_acc: 0.8790\n",
      "Epoch 31/100\n",
      "496/496 [==============================] - 0s 722us/step - loss: 0.8654 - acc: 0.8448 - val_loss: 0.8187 - val_acc: 0.8871\n",
      "Epoch 32/100\n",
      "496/496 [==============================] - 0s 725us/step - loss: 0.8470 - acc: 0.8548 - val_loss: 0.7879 - val_acc: 0.8871\n",
      "Epoch 33/100\n",
      "496/496 [==============================] - 0s 735us/step - loss: 0.8074 - acc: 0.8690 - val_loss: 0.7586 - val_acc: 0.8952\n",
      "Epoch 34/100\n",
      "496/496 [==============================] - 0s 714us/step - loss: 0.7661 - acc: 0.8669 - val_loss: 0.7302 - val_acc: 0.9113\n",
      "Epoch 35/100\n",
      "496/496 [==============================] - 0s 726us/step - loss: 0.7363 - acc: 0.8851 - val_loss: 0.7025 - val_acc: 0.9194\n",
      "Epoch 36/100\n",
      "496/496 [==============================] - 0s 727us/step - loss: 0.7267 - acc: 0.8931 - val_loss: 0.6758 - val_acc: 0.9194\n",
      "Epoch 37/100\n",
      "496/496 [==============================] - 0s 718us/step - loss: 0.6845 - acc: 0.8931 - val_loss: 0.6491 - val_acc: 0.9194\n",
      "Epoch 38/100\n",
      "496/496 [==============================] - 0s 729us/step - loss: 0.6556 - acc: 0.9173 - val_loss: 0.6233 - val_acc: 0.9274\n",
      "Epoch 39/100\n",
      "496/496 [==============================] - 0s 732us/step - loss: 0.6300 - acc: 0.9254 - val_loss: 0.5994 - val_acc: 0.9597\n",
      "Epoch 40/100\n",
      "496/496 [==============================] - 0s 720us/step - loss: 0.6036 - acc: 0.9335 - val_loss: 0.5771 - val_acc: 0.9597\n",
      "Epoch 41/100\n",
      "496/496 [==============================] - 0s 745us/step - loss: 0.5864 - acc: 0.9476 - val_loss: 0.5550 - val_acc: 0.9597\n",
      "Epoch 42/100\n",
      "496/496 [==============================] - 0s 733us/step - loss: 0.5577 - acc: 0.9476 - val_loss: 0.5337 - val_acc: 0.9677\n",
      "Epoch 43/100\n",
      "496/496 [==============================] - 0s 717us/step - loss: 0.5342 - acc: 0.9536 - val_loss: 0.5145 - val_acc: 0.9677\n",
      "Epoch 44/100\n",
      "496/496 [==============================] - 0s 727us/step - loss: 0.5255 - acc: 0.9597 - val_loss: 0.4979 - val_acc: 0.9677\n",
      "Epoch 45/100\n",
      "496/496 [==============================] - 0s 730us/step - loss: 0.4999 - acc: 0.9698 - val_loss: 0.4836 - val_acc: 0.9677\n",
      "Epoch 46/100\n",
      "496/496 [==============================] - 0s 710us/step - loss: 0.4742 - acc: 0.9657 - val_loss: 0.4679 - val_acc: 0.9677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "496/496 [==============================] - 0s 730us/step - loss: 0.4558 - acc: 0.9637 - val_loss: 0.4503 - val_acc: 0.9677\n",
      "Epoch 48/100\n",
      "496/496 [==============================] - 0s 716us/step - loss: 0.4349 - acc: 0.9718 - val_loss: 0.4346 - val_acc: 0.9677\n",
      "Epoch 49/100\n",
      "496/496 [==============================] - 0s 715us/step - loss: 0.4208 - acc: 0.9718 - val_loss: 0.4204 - val_acc: 0.9677\n",
      "Epoch 50/100\n",
      "496/496 [==============================] - 0s 725us/step - loss: 0.4263 - acc: 0.9698 - val_loss: 0.4065 - val_acc: 0.9677\n",
      "Epoch 51/100\n",
      "496/496 [==============================] - 0s 722us/step - loss: 0.4010 - acc: 0.9657 - val_loss: 0.3933 - val_acc: 0.9677\n",
      "Epoch 52/100\n",
      "496/496 [==============================] - 0s 712us/step - loss: 0.3793 - acc: 0.9718 - val_loss: 0.3807 - val_acc: 0.9677\n",
      "Epoch 53/100\n",
      "496/496 [==============================] - 0s 724us/step - loss: 0.3607 - acc: 0.9718 - val_loss: 0.3688 - val_acc: 0.9677\n",
      "Epoch 54/100\n",
      "496/496 [==============================] - 0s 709us/step - loss: 0.3631 - acc: 0.9698 - val_loss: 0.3576 - val_acc: 0.9677\n",
      "Epoch 55/100\n",
      "496/496 [==============================] - 0s 711us/step - loss: 0.3456 - acc: 0.9677 - val_loss: 0.3470 - val_acc: 0.9677\n",
      "Epoch 56/100\n",
      "496/496 [==============================] - 0s 729us/step - loss: 0.3375 - acc: 0.9698 - val_loss: 0.3367 - val_acc: 0.9677\n",
      "Epoch 57/100\n",
      "496/496 [==============================] - 0s 718us/step - loss: 0.3188 - acc: 0.9738 - val_loss: 0.3266 - val_acc: 0.9677\n",
      "Epoch 58/100\n",
      "496/496 [==============================] - 0s 717us/step - loss: 0.3110 - acc: 0.9718 - val_loss: 0.3170 - val_acc: 0.9677\n",
      "Epoch 59/100\n",
      "496/496 [==============================] - 0s 719us/step - loss: 0.3000 - acc: 0.9718 - val_loss: 0.3081 - val_acc: 0.9677\n",
      "Epoch 60/100\n",
      "496/496 [==============================] - 0s 723us/step - loss: 0.2847 - acc: 0.9738 - val_loss: 0.2998 - val_acc: 0.9677\n",
      "Epoch 61/100\n",
      "496/496 [==============================] - 0s 720us/step - loss: 0.2850 - acc: 0.9758 - val_loss: 0.2919 - val_acc: 0.9677\n",
      "Epoch 62/100\n",
      "496/496 [==============================] - 0s 733us/step - loss: 0.2785 - acc: 0.9738 - val_loss: 0.2844 - val_acc: 0.9677\n",
      "Epoch 63/100\n",
      "496/496 [==============================] - 0s 718us/step - loss: 0.2827 - acc: 0.9738 - val_loss: 0.2812 - val_acc: 0.9677\n",
      "Epoch 64/100\n",
      "496/496 [==============================] - 0s 715us/step - loss: 0.2564 - acc: 0.9738 - val_loss: 0.2769 - val_acc: 0.9597\n",
      "Epoch 65/100\n",
      "496/496 [==============================] - 0s 726us/step - loss: 0.2621 - acc: 0.9718 - val_loss: 0.2685 - val_acc: 0.9597\n",
      "Epoch 66/100\n",
      "496/496 [==============================] - 0s 718us/step - loss: 0.2534 - acc: 0.9718 - val_loss: 0.2589 - val_acc: 0.9677\n",
      "Epoch 67/100\n",
      "496/496 [==============================] - 0s 721us/step - loss: 0.2357 - acc: 0.9677 - val_loss: 0.2486 - val_acc: 0.9677\n",
      "Epoch 68/100\n",
      "496/496 [==============================] - 0s 711us/step - loss: 0.2271 - acc: 0.9758 - val_loss: 0.2406 - val_acc: 0.9677\n",
      "Epoch 69/100\n",
      "496/496 [==============================] - 0s 713us/step - loss: 0.2242 - acc: 0.9758 - val_loss: 0.2338 - val_acc: 0.9677\n",
      "Epoch 70/100\n",
      "496/496 [==============================] - 0s 715us/step - loss: 0.2190 - acc: 0.9778 - val_loss: 0.2275 - val_acc: 0.9677\n",
      "Epoch 71/100\n",
      "496/496 [==============================] - 0s 710us/step - loss: 0.2142 - acc: 0.9778 - val_loss: 0.2216 - val_acc: 0.9677\n",
      "Epoch 72/100\n",
      "496/496 [==============================] - 0s 731us/step - loss: 0.2136 - acc: 0.9758 - val_loss: 0.2161 - val_acc: 0.9677\n",
      "Epoch 73/100\n",
      "496/496 [==============================] - 0s 715us/step - loss: 0.2022 - acc: 0.9758 - val_loss: 0.2108 - val_acc: 0.9677\n",
      "Epoch 74/100\n",
      "496/496 [==============================] - 0s 719us/step - loss: 0.2021 - acc: 0.9758 - val_loss: 0.2059 - val_acc: 0.9677\n",
      "Epoch 75/100\n",
      "496/496 [==============================] - 0s 717us/step - loss: 0.2033 - acc: 0.9778 - val_loss: 0.2010 - val_acc: 0.9677\n",
      "Epoch 76/100\n",
      "496/496 [==============================] - 0s 713us/step - loss: 0.1973 - acc: 0.9798 - val_loss: 0.1962 - val_acc: 0.9677\n",
      "Epoch 77/100\n",
      "496/496 [==============================] - 0s 753us/step - loss: 0.1891 - acc: 0.9758 - val_loss: 0.1913 - val_acc: 0.9677\n",
      "Epoch 78/100\n",
      "496/496 [==============================] - 0s 721us/step - loss: 0.1824 - acc: 0.9758 - val_loss: 0.1864 - val_acc: 0.9677\n",
      "Epoch 79/100\n",
      "496/496 [==============================] - 0s 1ms/step - loss: 0.1892 - acc: 0.9718 - val_loss: 0.1821 - val_acc: 0.9677\n",
      "Epoch 80/100\n",
      "496/496 [==============================] - 1s 1ms/step - loss: 0.1758 - acc: 0.9778 - val_loss: 0.1807 - val_acc: 0.9677\n",
      "Epoch 81/100\n",
      "496/496 [==============================] - 0s 931us/step - loss: 0.1696 - acc: 0.9798 - val_loss: 0.1935 - val_acc: 0.9597\n",
      "Epoch 82/100\n",
      "496/496 [==============================] - 0s 980us/step - loss: 0.1642 - acc: 0.9758 - val_loss: 0.1906 - val_acc: 0.9597\n",
      "Epoch 83/100\n",
      "496/496 [==============================] - 0s 893us/step - loss: 0.1612 - acc: 0.9819 - val_loss: 0.1874 - val_acc: 0.9597\n",
      "Epoch 84/100\n",
      "496/496 [==============================] - 0s 803us/step - loss: 0.1545 - acc: 0.9798 - val_loss: 0.1844 - val_acc: 0.9597\n",
      "Epoch 85/100\n",
      "496/496 [==============================] - 0s 770us/step - loss: 0.1593 - acc: 0.9778 - val_loss: 0.1815 - val_acc: 0.9597\n",
      "Epoch 86/100\n",
      "496/496 [==============================] - 0s 973us/step - loss: 0.1488 - acc: 0.9798 - val_loss: 0.1786 - val_acc: 0.9597\n",
      "Epoch 87/100\n",
      "496/496 [==============================] - 1s 1ms/step - loss: 0.1495 - acc: 0.9798 - val_loss: 0.1758 - val_acc: 0.9597\n",
      "Epoch 88/100\n",
      "496/496 [==============================] - 1s 1ms/step - loss: 0.1515 - acc: 0.9798 - val_loss: 0.1730 - val_acc: 0.9597\n",
      "Epoch 89/100\n",
      "496/496 [==============================] - 1s 1ms/step - loss: 0.1476 - acc: 0.9758 - val_loss: 0.1698 - val_acc: 0.9597\n",
      "Epoch 90/100\n",
      "496/496 [==============================] - 1s 1ms/step - loss: 0.1350 - acc: 0.9839 - val_loss: 0.1463 - val_acc: 0.9677\n",
      "Epoch 91/100\n",
      "496/496 [==============================] - 1s 1ms/step - loss: 0.1377 - acc: 0.9798 - val_loss: 0.1436 - val_acc: 0.9677\n",
      "Epoch 92/100\n",
      "496/496 [==============================] - 1s 1ms/step - loss: 0.1428 - acc: 0.9879 - val_loss: 0.1411 - val_acc: 0.9677\n",
      "Epoch 93/100\n",
      "496/496 [==============================] - 0s 883us/step - loss: 0.1335 - acc: 0.9798 - val_loss: 0.1385 - val_acc: 0.9677\n",
      "Epoch 94/100\n",
      "496/496 [==============================] - 0s 835us/step - loss: 0.1230 - acc: 0.9819 - val_loss: 0.1360 - val_acc: 0.9677\n",
      "Epoch 95/100\n",
      "496/496 [==============================] - 1s 1ms/step - loss: 0.1263 - acc: 0.9859 - val_loss: 0.1337 - val_acc: 0.9677\n",
      "Epoch 96/100\n",
      "496/496 [==============================] - 1s 1ms/step - loss: 0.1220 - acc: 0.9859 - val_loss: 0.1314 - val_acc: 0.9677\n",
      "Epoch 97/100\n",
      "496/496 [==============================] - 1s 1ms/step - loss: 0.1295 - acc: 0.9859 - val_loss: 0.1292 - val_acc: 0.9677\n",
      "Epoch 98/100\n",
      "496/496 [==============================] - 0s 825us/step - loss: 0.1164 - acc: 0.9879 - val_loss: 0.1271 - val_acc: 0.9677\n",
      "Epoch 99/100\n",
      "496/496 [==============================] - 0s 794us/step - loss: 0.1173 - acc: 0.9819 - val_loss: 0.1250 - val_acc: 0.9677\n",
      "Epoch 100/100\n",
      "496/496 [==============================] - 0s 777us/step - loss: 0.1160 - acc: 0.9919 - val_loss: 0.1231 - val_acc: 0.9677\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (464, 50, 128)\n",
      "Shape Y (464, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 371 samples, validate on 93 samples\n",
      "Epoch 1/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 2.2587 - acc: 0.0809 - val_loss: 2.1343 - val_acc: 0.0968\n",
      "Epoch 2/100\n",
      "371/371 [==============================] - 0s 909us/step - loss: 2.1878 - acc: 0.1240 - val_loss: 2.0717 - val_acc: 0.3441\n",
      "Epoch 3/100\n",
      "371/371 [==============================] - 0s 928us/step - loss: 2.1008 - acc: 0.2318 - val_loss: 2.0150 - val_acc: 0.4301\n",
      "Epoch 4/100\n",
      "371/371 [==============================] - 0s 909us/step - loss: 2.0282 - acc: 0.2857 - val_loss: 1.9667 - val_acc: 0.4624\n",
      "Epoch 5/100\n",
      "371/371 [==============================] - 0s 907us/step - loss: 1.9778 - acc: 0.3396 - val_loss: 1.9219 - val_acc: 0.4839\n",
      "Epoch 6/100\n",
      "371/371 [==============================] - 0s 970us/step - loss: 1.9273 - acc: 0.3989 - val_loss: 1.8807 - val_acc: 0.5914\n",
      "Epoch 7/100\n",
      "371/371 [==============================] - 0s 976us/step - loss: 1.8910 - acc: 0.4151 - val_loss: 1.8403 - val_acc: 0.6559\n",
      "Epoch 8/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 1.8483 - acc: 0.4906 - val_loss: 1.8008 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "371/371 [==============================] - 0s 945us/step - loss: 1.8089 - acc: 0.5418 - val_loss: 1.7618 - val_acc: 0.6989\n",
      "Epoch 10/100\n",
      "371/371 [==============================] - 0s 948us/step - loss: 1.7800 - acc: 0.5580 - val_loss: 1.7237 - val_acc: 0.7097\n",
      "Epoch 11/100\n",
      "371/371 [==============================] - 0s 967us/step - loss: 1.7212 - acc: 0.5903 - val_loss: 1.6857 - val_acc: 0.7204\n",
      "Epoch 12/100\n",
      "371/371 [==============================] - 0s 952us/step - loss: 1.6716 - acc: 0.6631 - val_loss: 1.6479 - val_acc: 0.7204\n",
      "Epoch 13/100\n",
      "371/371 [==============================] - 0s 939us/step - loss: 1.6365 - acc: 0.6739 - val_loss: 1.6099 - val_acc: 0.7419\n",
      "Epoch 14/100\n",
      "371/371 [==============================] - 0s 972us/step - loss: 1.5856 - acc: 0.6981 - val_loss: 1.5719 - val_acc: 0.7527\n",
      "Epoch 15/100\n",
      "371/371 [==============================] - 0s 959us/step - loss: 1.5670 - acc: 0.6900 - val_loss: 1.5342 - val_acc: 0.7527\n",
      "Epoch 16/100\n",
      "371/371 [==============================] - 0s 944us/step - loss: 1.5299 - acc: 0.6819 - val_loss: 1.4972 - val_acc: 0.7527\n",
      "Epoch 17/100\n",
      "371/371 [==============================] - 0s 938us/step - loss: 1.4922 - acc: 0.7062 - val_loss: 1.4604 - val_acc: 0.7527\n",
      "Epoch 18/100\n",
      "371/371 [==============================] - 0s 938us/step - loss: 1.4214 - acc: 0.7493 - val_loss: 1.4233 - val_acc: 0.7527\n",
      "Epoch 19/100\n",
      "371/371 [==============================] - 0s 965us/step - loss: 1.3775 - acc: 0.7493 - val_loss: 1.3867 - val_acc: 0.7527\n",
      "Epoch 20/100\n",
      "371/371 [==============================] - 0s 950us/step - loss: 1.3424 - acc: 0.7601 - val_loss: 1.3498 - val_acc: 0.7634\n",
      "Epoch 21/100\n",
      "371/371 [==============================] - 0s 944us/step - loss: 1.2858 - acc: 0.7601 - val_loss: 1.3135 - val_acc: 0.7527\n",
      "Epoch 22/100\n",
      "371/371 [==============================] - 0s 949us/step - loss: 1.2866 - acc: 0.7736 - val_loss: 1.2780 - val_acc: 0.7527\n",
      "Epoch 23/100\n",
      "371/371 [==============================] - 0s 952us/step - loss: 1.2074 - acc: 0.7817 - val_loss: 1.2430 - val_acc: 0.7634\n",
      "Epoch 24/100\n",
      "371/371 [==============================] - 0s 945us/step - loss: 1.1827 - acc: 0.7978 - val_loss: 1.2095 - val_acc: 0.7742\n",
      "Epoch 25/100\n",
      "371/371 [==============================] - 0s 962us/step - loss: 1.1535 - acc: 0.7844 - val_loss: 1.1769 - val_acc: 0.7742\n",
      "Epoch 26/100\n",
      "371/371 [==============================] - 0s 953us/step - loss: 1.1168 - acc: 0.8059 - val_loss: 1.1449 - val_acc: 0.7849\n",
      "Epoch 27/100\n",
      "371/371 [==============================] - 0s 941us/step - loss: 1.0578 - acc: 0.8059 - val_loss: 1.1134 - val_acc: 0.7849\n",
      "Epoch 28/100\n",
      "371/371 [==============================] - 0s 976us/step - loss: 1.0434 - acc: 0.8221 - val_loss: 1.0824 - val_acc: 0.8065\n",
      "Epoch 29/100\n",
      "371/371 [==============================] - 0s 957us/step - loss: 0.9919 - acc: 0.8221 - val_loss: 1.0522 - val_acc: 0.8172\n",
      "Epoch 30/100\n",
      "371/371 [==============================] - 0s 943us/step - loss: 0.9799 - acc: 0.8275 - val_loss: 1.0225 - val_acc: 0.8280\n",
      "Epoch 31/100\n",
      "371/371 [==============================] - 0s 977us/step - loss: 0.9303 - acc: 0.8544 - val_loss: 0.9942 - val_acc: 0.8387\n",
      "Epoch 32/100\n",
      "371/371 [==============================] - 0s 928us/step - loss: 0.9079 - acc: 0.8679 - val_loss: 0.9670 - val_acc: 0.8495\n",
      "Epoch 33/100\n",
      "371/371 [==============================] - 0s 996us/step - loss: 0.8897 - acc: 0.8302 - val_loss: 0.9397 - val_acc: 0.8495\n",
      "Epoch 34/100\n",
      "371/371 [==============================] - 0s 972us/step - loss: 0.8324 - acc: 0.8598 - val_loss: 0.9114 - val_acc: 0.8495\n",
      "Epoch 35/100\n",
      "371/371 [==============================] - 0s 952us/step - loss: 0.8086 - acc: 0.8733 - val_loss: 0.8833 - val_acc: 0.8602\n",
      "Epoch 36/100\n",
      "371/371 [==============================] - 0s 949us/step - loss: 0.7727 - acc: 0.8841 - val_loss: 0.8543 - val_acc: 0.8602\n",
      "Epoch 37/100\n",
      "371/371 [==============================] - 0s 964us/step - loss: 0.7410 - acc: 0.9111 - val_loss: 0.8265 - val_acc: 0.8710\n",
      "Epoch 38/100\n",
      "371/371 [==============================] - 0s 938us/step - loss: 0.7233 - acc: 0.8760 - val_loss: 0.8002 - val_acc: 0.8710\n",
      "Epoch 39/100\n",
      "371/371 [==============================] - 0s 954us/step - loss: 0.6968 - acc: 0.9111 - val_loss: 0.7751 - val_acc: 0.8710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "371/371 [==============================] - 0s 939us/step - loss: 0.6665 - acc: 0.9218 - val_loss: 0.7512 - val_acc: 0.8710\n",
      "Epoch 41/100\n",
      "371/371 [==============================] - 0s 942us/step - loss: 0.6416 - acc: 0.9272 - val_loss: 0.7281 - val_acc: 0.8925\n",
      "Epoch 42/100\n",
      "371/371 [==============================] - 0s 948us/step - loss: 0.6130 - acc: 0.9380 - val_loss: 0.7064 - val_acc: 0.8925\n",
      "Epoch 43/100\n",
      "371/371 [==============================] - 0s 942us/step - loss: 0.5904 - acc: 0.9461 - val_loss: 0.6861 - val_acc: 0.9032\n",
      "Epoch 44/100\n",
      "371/371 [==============================] - 0s 926us/step - loss: 0.5629 - acc: 0.9326 - val_loss: 0.6670 - val_acc: 0.9032\n",
      "Epoch 45/100\n",
      "371/371 [==============================] - 0s 966us/step - loss: 0.5346 - acc: 0.9380 - val_loss: 0.6491 - val_acc: 0.9032\n",
      "Epoch 46/100\n",
      "371/371 [==============================] - 0s 923us/step - loss: 0.5196 - acc: 0.9515 - val_loss: 0.6322 - val_acc: 0.9032\n",
      "Epoch 47/100\n",
      "371/371 [==============================] - 0s 938us/step - loss: 0.5331 - acc: 0.9299 - val_loss: 0.6159 - val_acc: 0.9140\n",
      "Epoch 48/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.4996 - acc: 0.9434 - val_loss: 0.6002 - val_acc: 0.9140\n",
      "Epoch 49/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.4809 - acc: 0.9515 - val_loss: 0.5855 - val_acc: 0.9247\n",
      "Epoch 50/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.4580 - acc: 0.9542 - val_loss: 0.5754 - val_acc: 0.9247\n",
      "Epoch 51/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.4476 - acc: 0.9623 - val_loss: 0.5679 - val_acc: 0.9140\n",
      "Epoch 52/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.4249 - acc: 0.9596 - val_loss: 0.5583 - val_acc: 0.9140\n",
      "Epoch 53/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.4164 - acc: 0.9596 - val_loss: 0.5441 - val_acc: 0.9140\n",
      "Epoch 54/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.4065 - acc: 0.9596 - val_loss: 0.5299 - val_acc: 0.9140\n",
      "Epoch 55/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.3803 - acc: 0.9650 - val_loss: 0.5164 - val_acc: 0.9140\n",
      "Epoch 56/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.3692 - acc: 0.9596 - val_loss: 0.5066 - val_acc: 0.9140\n",
      "Epoch 57/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.3671 - acc: 0.9596 - val_loss: 0.4960 - val_acc: 0.9140\n",
      "Epoch 58/100\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.3426 - acc: 0.9677 - val_loss: 0.4823 - val_acc: 0.9140\n",
      "Epoch 59/100\n",
      "371/371 [==============================] - 0s 919us/step - loss: 0.3373 - acc: 0.9596 - val_loss: 0.4617 - val_acc: 0.9247\n",
      "Epoch 60/100\n",
      "371/371 [==============================] - 0s 953us/step - loss: 0.3349 - acc: 0.9623 - val_loss: 0.4512 - val_acc: 0.9247\n",
      "Epoch 61/100\n",
      "371/371 [==============================] - 0s 951us/step - loss: 0.3135 - acc: 0.9730 - val_loss: 0.4415 - val_acc: 0.9247\n",
      "Epoch 62/100\n",
      "371/371 [==============================] - 0s 948us/step - loss: 0.3006 - acc: 0.9704 - val_loss: 0.4322 - val_acc: 0.9355\n",
      "Epoch 63/100\n",
      "371/371 [==============================] - 0s 949us/step - loss: 0.2963 - acc: 0.9704 - val_loss: 0.4232 - val_acc: 0.9355\n",
      "Epoch 64/100\n",
      "371/371 [==============================] - 0s 954us/step - loss: 0.2912 - acc: 0.9757 - val_loss: 0.4141 - val_acc: 0.9355\n",
      "Epoch 65/100\n",
      "371/371 [==============================] - 0s 936us/step - loss: 0.2874 - acc: 0.9730 - val_loss: 0.4054 - val_acc: 0.9355\n",
      "Epoch 66/100\n",
      "371/371 [==============================] - 0s 943us/step - loss: 0.2740 - acc: 0.9757 - val_loss: 0.3973 - val_acc: 0.9355\n",
      "Epoch 67/100\n",
      "371/371 [==============================] - 0s 924us/step - loss: 0.2705 - acc: 0.9704 - val_loss: 0.3897 - val_acc: 0.9355\n",
      "Epoch 68/100\n",
      "371/371 [==============================] - 0s 945us/step - loss: 0.2610 - acc: 0.9730 - val_loss: 0.3822 - val_acc: 0.9462\n",
      "Epoch 69/100\n",
      "371/371 [==============================] - 0s 949us/step - loss: 0.2496 - acc: 0.9865 - val_loss: 0.3752 - val_acc: 0.9462\n",
      "Epoch 70/100\n",
      "371/371 [==============================] - 0s 935us/step - loss: 0.2482 - acc: 0.9838 - val_loss: 0.3683 - val_acc: 0.9462\n",
      "Epoch 71/100\n",
      "371/371 [==============================] - 0s 948us/step - loss: 0.2346 - acc: 0.9919 - val_loss: 0.3612 - val_acc: 0.9462\n",
      "Epoch 72/100\n",
      "371/371 [==============================] - 0s 953us/step - loss: 0.2257 - acc: 0.9838 - val_loss: 0.3544 - val_acc: 0.9462\n",
      "Epoch 73/100\n",
      "371/371 [==============================] - 0s 927us/step - loss: 0.2345 - acc: 0.9838 - val_loss: 0.3475 - val_acc: 0.9462\n",
      "Epoch 74/100\n",
      "371/371 [==============================] - 0s 965us/step - loss: 0.2230 - acc: 0.9811 - val_loss: 0.3407 - val_acc: 0.9462\n",
      "Epoch 75/100\n",
      "371/371 [==============================] - 0s 918us/step - loss: 0.2156 - acc: 0.9919 - val_loss: 0.3338 - val_acc: 0.9570\n",
      "Epoch 76/100\n",
      "371/371 [==============================] - 0s 941us/step - loss: 0.2127 - acc: 0.9919 - val_loss: 0.3265 - val_acc: 0.9570\n",
      "Epoch 77/100\n",
      "371/371 [==============================] - 0s 950us/step - loss: 0.2007 - acc: 0.9946 - val_loss: 0.3187 - val_acc: 0.9570\n",
      "Epoch 78/100\n",
      "371/371 [==============================] - 0s 952us/step - loss: 0.1985 - acc: 0.9919 - val_loss: 0.3105 - val_acc: 0.9570\n",
      "Epoch 79/100\n",
      "371/371 [==============================] - 0s 933us/step - loss: 0.1839 - acc: 0.9919 - val_loss: 0.3090 - val_acc: 0.9570\n",
      "Epoch 80/100\n",
      "371/371 [==============================] - 0s 948us/step - loss: 0.1923 - acc: 0.9865 - val_loss: 0.2935 - val_acc: 0.9570\n",
      "Epoch 81/100\n",
      "371/371 [==============================] - 0s 928us/step - loss: 0.1926 - acc: 0.9919 - val_loss: 0.2858 - val_acc: 0.9570\n",
      "Epoch 82/100\n",
      "371/371 [==============================] - 0s 929us/step - loss: 0.1896 - acc: 0.9838 - val_loss: 0.2783 - val_acc: 0.9570\n",
      "Epoch 83/100\n",
      "371/371 [==============================] - 0s 943us/step - loss: 0.1810 - acc: 0.9919 - val_loss: 0.2714 - val_acc: 0.9570\n",
      "Epoch 84/100\n",
      "371/371 [==============================] - 0s 930us/step - loss: 0.1644 - acc: 0.9919 - val_loss: 0.2655 - val_acc: 0.9570\n",
      "Epoch 85/100\n",
      "371/371 [==============================] - 0s 964us/step - loss: 0.1684 - acc: 0.9919 - val_loss: 0.2605 - val_acc: 0.9570\n",
      "Epoch 86/100\n",
      "371/371 [==============================] - 0s 946us/step - loss: 0.1719 - acc: 0.9892 - val_loss: 0.2560 - val_acc: 0.9570\n",
      "Epoch 87/100\n",
      "371/371 [==============================] - 0s 933us/step - loss: 0.1661 - acc: 0.9865 - val_loss: 0.2520 - val_acc: 0.9570\n",
      "Epoch 88/100\n",
      "371/371 [==============================] - 0s 945us/step - loss: 0.1604 - acc: 0.9892 - val_loss: 0.2490 - val_acc: 0.9570\n",
      "Epoch 89/100\n",
      "371/371 [==============================] - 0s 955us/step - loss: 0.1583 - acc: 0.9892 - val_loss: 0.2449 - val_acc: 0.9570\n",
      "Epoch 90/100\n",
      "371/371 [==============================] - 0s 926us/step - loss: 0.1495 - acc: 0.9946 - val_loss: 0.2418 - val_acc: 0.9570\n",
      "Epoch 91/100\n",
      "371/371 [==============================] - 0s 955us/step - loss: 0.1488 - acc: 0.9892 - val_loss: 0.2390 - val_acc: 0.9570\n",
      "Epoch 92/100\n",
      "371/371 [==============================] - 0s 952us/step - loss: 0.1402 - acc: 0.9865 - val_loss: 0.2361 - val_acc: 0.9570\n",
      "Epoch 93/100\n",
      "371/371 [==============================] - 0s 927us/step - loss: 0.1452 - acc: 0.9865 - val_loss: 0.2331 - val_acc: 0.9570\n",
      "Epoch 94/100\n",
      "371/371 [==============================] - 0s 960us/step - loss: 0.1483 - acc: 0.9811 - val_loss: 0.2300 - val_acc: 0.9570\n",
      "Epoch 95/100\n",
      "371/371 [==============================] - 0s 946us/step - loss: 0.1401 - acc: 0.9892 - val_loss: 0.2271 - val_acc: 0.9570\n",
      "Epoch 96/100\n",
      "371/371 [==============================] - 0s 944us/step - loss: 0.1383 - acc: 0.9892 - val_loss: 0.2243 - val_acc: 0.9570\n",
      "Epoch 97/100\n",
      "371/371 [==============================] - 0s 958us/step - loss: 0.1394 - acc: 0.9892 - val_loss: 0.2216 - val_acc: 0.9570\n",
      "Epoch 98/100\n",
      "371/371 [==============================] - 0s 935us/step - loss: 0.1389 - acc: 0.9811 - val_loss: 0.2191 - val_acc: 0.9570\n",
      "Epoch 99/100\n",
      "371/371 [==============================] - 0s 944us/step - loss: 0.1320 - acc: 0.9919 - val_loss: 0.2167 - val_acc: 0.9570\n",
      "Epoch 100/100\n",
      "371/371 [==============================] - 0s 954us/step - loss: 0.1332 - acc: 0.9838 - val_loss: 0.2146 - val_acc: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (745, 20, 128)\n",
      "Shape Y (745, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 596 samples, validate on 149 samples\n",
      "Epoch 1/100\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 2.2580 - acc: 0.0990 - val_loss: 2.1626 - val_acc: 0.1745\n",
      "Epoch 2/100\n",
      "596/596 [==============================] - 0s 361us/step - loss: 2.1947 - acc: 0.1191 - val_loss: 2.1046 - val_acc: 0.2215\n",
      "Epoch 3/100\n",
      "596/596 [==============================] - 0s 360us/step - loss: 2.1348 - acc: 0.1477 - val_loss: 2.0506 - val_acc: 0.2550\n",
      "Epoch 4/100\n",
      "596/596 [==============================] - 0s 364us/step - loss: 2.0732 - acc: 0.2399 - val_loss: 1.9989 - val_acc: 0.3826\n",
      "Epoch 5/100\n",
      "596/596 [==============================] - 0s 346us/step - loss: 2.0231 - acc: 0.2936 - val_loss: 1.9489 - val_acc: 0.4362\n",
      "Epoch 6/100\n",
      "596/596 [==============================] - 0s 361us/step - loss: 1.9896 - acc: 0.3423 - val_loss: 1.9002 - val_acc: 0.5235\n",
      "Epoch 7/100\n",
      "596/596 [==============================] - 0s 356us/step - loss: 1.9229 - acc: 0.4346 - val_loss: 1.8519 - val_acc: 0.5839\n",
      "Epoch 8/100\n",
      "596/596 [==============================] - 0s 348us/step - loss: 1.8922 - acc: 0.4530 - val_loss: 1.8044 - val_acc: 0.6577\n",
      "Epoch 9/100\n",
      "596/596 [==============================] - 0s 355us/step - loss: 1.8299 - acc: 0.5235 - val_loss: 1.7583 - val_acc: 0.6980\n",
      "Epoch 10/100\n",
      "596/596 [==============================] - 0s 353us/step - loss: 1.7920 - acc: 0.5587 - val_loss: 1.7120 - val_acc: 0.7584\n",
      "Epoch 11/100\n",
      "596/596 [==============================] - 0s 355us/step - loss: 1.7474 - acc: 0.6141 - val_loss: 1.6672 - val_acc: 0.7852\n",
      "Epoch 12/100\n",
      "596/596 [==============================] - 0s 377us/step - loss: 1.7080 - acc: 0.6443 - val_loss: 1.6235 - val_acc: 0.7919\n",
      "Epoch 13/100\n",
      "596/596 [==============================] - 0s 373us/step - loss: 1.6568 - acc: 0.7030 - val_loss: 1.5802 - val_acc: 0.8121\n",
      "Epoch 14/100\n",
      "596/596 [==============================] - 0s 390us/step - loss: 1.6223 - acc: 0.6963 - val_loss: 1.5373 - val_acc: 0.8121\n",
      "Epoch 15/100\n",
      "596/596 [==============================] - 0s 366us/step - loss: 1.5901 - acc: 0.7181 - val_loss: 1.4950 - val_acc: 0.7987\n",
      "Epoch 16/100\n",
      "596/596 [==============================] - 0s 366us/step - loss: 1.5495 - acc: 0.7366 - val_loss: 1.4529 - val_acc: 0.8054\n",
      "Epoch 17/100\n",
      "596/596 [==============================] - 0s 371us/step - loss: 1.4990 - acc: 0.7919 - val_loss: 1.4109 - val_acc: 0.8188\n",
      "Epoch 18/100\n",
      "596/596 [==============================] - 0s 372us/step - loss: 1.4537 - acc: 0.7685 - val_loss: 1.3692 - val_acc: 0.8389\n",
      "Epoch 19/100\n",
      "596/596 [==============================] - 0s 367us/step - loss: 1.4183 - acc: 0.7970 - val_loss: 1.3281 - val_acc: 0.8389\n",
      "Epoch 20/100\n",
      "596/596 [==============================] - 0s 375us/step - loss: 1.3831 - acc: 0.8037 - val_loss: 1.2876 - val_acc: 0.8389\n",
      "Epoch 21/100\n",
      "596/596 [==============================] - 0s 370us/step - loss: 1.3485 - acc: 0.8054 - val_loss: 1.2479 - val_acc: 0.8456\n",
      "Epoch 22/100\n",
      "596/596 [==============================] - 0s 377us/step - loss: 1.2976 - acc: 0.8372 - val_loss: 1.2096 - val_acc: 0.8456\n",
      "Epoch 23/100\n",
      "596/596 [==============================] - 0s 369us/step - loss: 1.2591 - acc: 0.8272 - val_loss: 1.1723 - val_acc: 0.8456\n",
      "Epoch 24/100\n",
      "596/596 [==============================] - 0s 383us/step - loss: 1.2370 - acc: 0.8339 - val_loss: 1.1359 - val_acc: 0.8523\n",
      "Epoch 25/100\n",
      "596/596 [==============================] - 0s 370us/step - loss: 1.2060 - acc: 0.8423 - val_loss: 1.1005 - val_acc: 0.8523\n",
      "Epoch 26/100\n",
      "596/596 [==============================] - 0s 377us/step - loss: 1.1503 - acc: 0.8624 - val_loss: 1.0660 - val_acc: 0.8591\n",
      "Epoch 27/100\n",
      "596/596 [==============================] - 0s 376us/step - loss: 1.1265 - acc: 0.8607 - val_loss: 1.0324 - val_acc: 0.8591\n",
      "Epoch 28/100\n",
      "596/596 [==============================] - 0s 373us/step - loss: 1.0865 - acc: 0.8758 - val_loss: 0.9995 - val_acc: 0.8591\n",
      "Epoch 29/100\n",
      "596/596 [==============================] - 0s 372us/step - loss: 1.0694 - acc: 0.8557 - val_loss: 0.9673 - val_acc: 0.8658\n",
      "Epoch 30/100\n",
      "596/596 [==============================] - 0s 375us/step - loss: 1.0254 - acc: 0.8842 - val_loss: 0.9358 - val_acc: 0.8725\n",
      "Epoch 31/100\n",
      "596/596 [==============================] - 0s 372us/step - loss: 0.9905 - acc: 0.8859 - val_loss: 0.9050 - val_acc: 0.8725\n",
      "Epoch 32/100\n",
      "596/596 [==============================] - 0s 376us/step - loss: 0.9647 - acc: 0.9027 - val_loss: 0.8752 - val_acc: 0.8725\n",
      "Epoch 33/100\n",
      "596/596 [==============================] - 0s 384us/step - loss: 0.9254 - acc: 0.9010 - val_loss: 0.8463 - val_acc: 0.8725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "596/596 [==============================] - 0s 368us/step - loss: 0.8953 - acc: 0.9161 - val_loss: 0.8182 - val_acc: 0.8725\n",
      "Epoch 35/100\n",
      "596/596 [==============================] - 0s 376us/step - loss: 0.8788 - acc: 0.9060 - val_loss: 0.7909 - val_acc: 0.8792\n",
      "Epoch 36/100\n",
      "596/596 [==============================] - 0s 362us/step - loss: 0.8211 - acc: 0.9178 - val_loss: 0.7641 - val_acc: 0.8792\n",
      "Epoch 37/100\n",
      "596/596 [==============================] - 0s 362us/step - loss: 0.8115 - acc: 0.9128 - val_loss: 0.7380 - val_acc: 0.8792\n",
      "Epoch 38/100\n",
      "596/596 [==============================] - 0s 378us/step - loss: 0.7720 - acc: 0.9211 - val_loss: 0.7127 - val_acc: 0.8792\n",
      "Epoch 39/100\n",
      "596/596 [==============================] - 0s 362us/step - loss: 0.7499 - acc: 0.9178 - val_loss: 0.6882 - val_acc: 0.8926\n",
      "Epoch 40/100\n",
      "596/596 [==============================] - 0s 367us/step - loss: 0.7105 - acc: 0.9245 - val_loss: 0.6642 - val_acc: 0.8993\n",
      "Epoch 41/100\n",
      "596/596 [==============================] - 0s 374us/step - loss: 0.6788 - acc: 0.9279 - val_loss: 0.6408 - val_acc: 0.8993\n",
      "Epoch 42/100\n",
      "596/596 [==============================] - 0s 356us/step - loss: 0.6716 - acc: 0.9312 - val_loss: 0.6182 - val_acc: 0.8993\n",
      "Epoch 43/100\n",
      "596/596 [==============================] - 0s 364us/step - loss: 0.6489 - acc: 0.9295 - val_loss: 0.5961 - val_acc: 0.8993\n",
      "Epoch 44/100\n",
      "596/596 [==============================] - 0s 360us/step - loss: 0.6208 - acc: 0.9312 - val_loss: 0.5744 - val_acc: 0.8993\n",
      "Epoch 45/100\n",
      "596/596 [==============================] - 0s 379us/step - loss: 0.6106 - acc: 0.9329 - val_loss: 0.5530 - val_acc: 0.9195\n",
      "Epoch 46/100\n",
      "596/596 [==============================] - 0s 369us/step - loss: 0.5680 - acc: 0.9379 - val_loss: 0.5327 - val_acc: 0.9262\n",
      "Epoch 47/100\n",
      "596/596 [==============================] - 0s 382us/step - loss: 0.5608 - acc: 0.9446 - val_loss: 0.5129 - val_acc: 0.9262\n",
      "Epoch 48/100\n",
      "596/596 [==============================] - 0s 363us/step - loss: 0.5375 - acc: 0.9413 - val_loss: 0.4942 - val_acc: 0.9262\n",
      "Epoch 49/100\n",
      "596/596 [==============================] - 0s 370us/step - loss: 0.5158 - acc: 0.9446 - val_loss: 0.4760 - val_acc: 0.9262\n",
      "Epoch 50/100\n",
      "596/596 [==============================] - 0s 371us/step - loss: 0.4951 - acc: 0.9497 - val_loss: 0.4575 - val_acc: 0.9262\n",
      "Epoch 51/100\n",
      "596/596 [==============================] - 0s 370us/step - loss: 0.4841 - acc: 0.9413 - val_loss: 0.4378 - val_acc: 0.9262\n",
      "Epoch 52/100\n",
      "596/596 [==============================] - 0s 373us/step - loss: 0.4742 - acc: 0.9513 - val_loss: 0.4191 - val_acc: 0.9329\n",
      "Epoch 53/100\n",
      "596/596 [==============================] - 0s 360us/step - loss: 0.4340 - acc: 0.9530 - val_loss: 0.4027 - val_acc: 0.9329\n",
      "Epoch 54/100\n",
      "596/596 [==============================] - 0s 365us/step - loss: 0.4257 - acc: 0.9631 - val_loss: 0.3881 - val_acc: 0.9396\n",
      "Epoch 55/100\n",
      "596/596 [==============================] - 0s 359us/step - loss: 0.4063 - acc: 0.9614 - val_loss: 0.3743 - val_acc: 0.9463\n",
      "Epoch 56/100\n",
      "596/596 [==============================] - 0s 377us/step - loss: 0.3946 - acc: 0.9581 - val_loss: 0.3605 - val_acc: 0.9463\n",
      "Epoch 57/100\n",
      "596/596 [==============================] - 0s 369us/step - loss: 0.3912 - acc: 0.9564 - val_loss: 0.3479 - val_acc: 0.9463\n",
      "Epoch 58/100\n",
      "596/596 [==============================] - 0s 371us/step - loss: 0.3833 - acc: 0.9581 - val_loss: 0.3368 - val_acc: 0.9463\n",
      "Epoch 59/100\n",
      "596/596 [==============================] - 0s 360us/step - loss: 0.3532 - acc: 0.9664 - val_loss: 0.3265 - val_acc: 0.9463\n",
      "Epoch 60/100\n",
      "596/596 [==============================] - 0s 366us/step - loss: 0.3443 - acc: 0.9597 - val_loss: 0.3170 - val_acc: 0.9463\n",
      "Epoch 61/100\n",
      "596/596 [==============================] - 0s 381us/step - loss: 0.3337 - acc: 0.9631 - val_loss: 0.3083 - val_acc: 0.9463\n",
      "Epoch 62/100\n",
      "596/596 [==============================] - 0s 357us/step - loss: 0.3194 - acc: 0.9631 - val_loss: 0.2997 - val_acc: 0.9463\n",
      "Epoch 63/100\n",
      "596/596 [==============================] - 0s 372us/step - loss: 0.3161 - acc: 0.9681 - val_loss: 0.2916 - val_acc: 0.9463\n",
      "Epoch 64/100\n",
      "596/596 [==============================] - 0s 367us/step - loss: 0.3050 - acc: 0.9715 - val_loss: 0.2839 - val_acc: 0.9463\n",
      "Epoch 65/100\n",
      "596/596 [==============================] - 0s 362us/step - loss: 0.2953 - acc: 0.9732 - val_loss: 0.2772 - val_acc: 0.9463\n",
      "Epoch 66/100\n",
      "596/596 [==============================] - 0s 363us/step - loss: 0.2876 - acc: 0.9715 - val_loss: 0.2710 - val_acc: 0.9396\n",
      "Epoch 67/100\n",
      "596/596 [==============================] - 0s 380us/step - loss: 0.2707 - acc: 0.9698 - val_loss: 0.2654 - val_acc: 0.9396\n",
      "Epoch 68/100\n",
      "596/596 [==============================] - 0s 364us/step - loss: 0.2689 - acc: 0.9715 - val_loss: 0.2601 - val_acc: 0.9396\n",
      "Epoch 69/100\n",
      "596/596 [==============================] - 0s 365us/step - loss: 0.2629 - acc: 0.9732 - val_loss: 0.2545 - val_acc: 0.9396\n",
      "Epoch 70/100\n",
      "596/596 [==============================] - 0s 369us/step - loss: 0.2533 - acc: 0.9748 - val_loss: 0.2490 - val_acc: 0.9396\n",
      "Epoch 71/100\n",
      "596/596 [==============================] - 0s 365us/step - loss: 0.2356 - acc: 0.9782 - val_loss: 0.2436 - val_acc: 0.9396\n",
      "Epoch 72/100\n",
      "596/596 [==============================] - 0s 384us/step - loss: 0.2402 - acc: 0.9815 - val_loss: 0.2384 - val_acc: 0.9396\n",
      "Epoch 73/100\n",
      "596/596 [==============================] - 0s 370us/step - loss: 0.2369 - acc: 0.9815 - val_loss: 0.2333 - val_acc: 0.9396\n",
      "Epoch 74/100\n",
      "596/596 [==============================] - 0s 363us/step - loss: 0.2193 - acc: 0.9832 - val_loss: 0.2281 - val_acc: 0.9396\n",
      "Epoch 75/100\n",
      "596/596 [==============================] - 0s 373us/step - loss: 0.2246 - acc: 0.9815 - val_loss: 0.2228 - val_acc: 0.9396\n",
      "Epoch 76/100\n",
      "596/596 [==============================] - 0s 378us/step - loss: 0.2190 - acc: 0.9832 - val_loss: 0.2174 - val_acc: 0.9530\n",
      "Epoch 77/100\n",
      "596/596 [==============================] - 0s 373us/step - loss: 0.2009 - acc: 0.9849 - val_loss: 0.2119 - val_acc: 0.9530\n",
      "Epoch 78/100\n",
      "596/596 [==============================] - 0s 368us/step - loss: 0.1988 - acc: 0.9883 - val_loss: 0.2064 - val_acc: 0.9530\n",
      "Epoch 79/100\n",
      "596/596 [==============================] - 0s 370us/step - loss: 0.1933 - acc: 0.9883 - val_loss: 0.2012 - val_acc: 0.9530\n",
      "Epoch 80/100\n",
      "596/596 [==============================] - 0s 375us/step - loss: 0.1888 - acc: 0.9849 - val_loss: 0.1964 - val_acc: 0.9530\n",
      "Epoch 81/100\n",
      "596/596 [==============================] - 0s 360us/step - loss: 0.1784 - acc: 0.9849 - val_loss: 0.1918 - val_acc: 0.9530\n",
      "Epoch 82/100\n",
      "596/596 [==============================] - 0s 376us/step - loss: 0.1701 - acc: 0.9883 - val_loss: 0.1866 - val_acc: 0.9530\n",
      "Epoch 83/100\n",
      "596/596 [==============================] - 0s 376us/step - loss: 0.1781 - acc: 0.9899 - val_loss: 0.1812 - val_acc: 0.9530\n",
      "Epoch 84/100\n",
      "596/596 [==============================] - 0s 370us/step - loss: 0.1656 - acc: 0.9883 - val_loss: 0.1756 - val_acc: 0.9530\n",
      "Epoch 85/100\n",
      "596/596 [==============================] - 0s 363us/step - loss: 0.1659 - acc: 0.9832 - val_loss: 0.1705 - val_acc: 0.9530\n",
      "Epoch 86/100\n",
      "596/596 [==============================] - 0s 366us/step - loss: 0.1579 - acc: 0.9916 - val_loss: 0.1657 - val_acc: 0.9530\n",
      "Epoch 87/100\n",
      "596/596 [==============================] - 0s 374us/step - loss: 0.1581 - acc: 0.9899 - val_loss: 0.1611 - val_acc: 0.9530\n",
      "Epoch 88/100\n",
      "596/596 [==============================] - 0s 374us/step - loss: 0.1539 - acc: 0.9916 - val_loss: 0.1566 - val_acc: 0.9530\n",
      "Epoch 89/100\n",
      "596/596 [==============================] - 0s 363us/step - loss: 0.1569 - acc: 0.9883 - val_loss: 0.1517 - val_acc: 0.9530\n",
      "Epoch 90/100\n",
      "596/596 [==============================] - 0s 371us/step - loss: 0.1397 - acc: 0.9916 - val_loss: 0.1455 - val_acc: 0.9530\n",
      "Epoch 91/100\n",
      "596/596 [==============================] - 0s 385us/step - loss: 0.1444 - acc: 0.9916 - val_loss: 0.1397 - val_acc: 0.9530\n",
      "Epoch 92/100\n",
      "596/596 [==============================] - 0s 357us/step - loss: 0.1370 - acc: 0.9933 - val_loss: 0.1300 - val_acc: 0.9597\n",
      "Epoch 93/100\n",
      "596/596 [==============================] - 0s 368us/step - loss: 0.1352 - acc: 0.9950 - val_loss: 0.1239 - val_acc: 0.9597\n",
      "Epoch 94/100\n",
      "596/596 [==============================] - 0s 364us/step - loss: 0.1332 - acc: 0.9933 - val_loss: 0.1197 - val_acc: 0.9597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "596/596 [==============================] - 0s 361us/step - loss: 0.1260 - acc: 0.9933 - val_loss: 0.1161 - val_acc: 0.9664\n",
      "Epoch 96/100\n",
      "596/596 [==============================] - 0s 368us/step - loss: 0.1326 - acc: 0.9916 - val_loss: 0.1127 - val_acc: 0.9732\n",
      "Epoch 97/100\n",
      "596/596 [==============================] - 0s 376us/step - loss: 0.1282 - acc: 0.9950 - val_loss: 0.1093 - val_acc: 0.9732\n",
      "Epoch 98/100\n",
      "596/596 [==============================] - 0s 369us/step - loss: 0.1193 - acc: 0.9933 - val_loss: 0.1062 - val_acc: 0.9732\n",
      "Epoch 99/100\n",
      "596/596 [==============================] - 0s 362us/step - loss: 0.1165 - acc: 0.9933 - val_loss: 0.1034 - val_acc: 0.9799\n",
      "Epoch 100/100\n",
      "596/596 [==============================] - 0s 431us/step - loss: 0.1108 - acc: 0.9950 - val_loss: 0.1016 - val_acc: 0.9866\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (611, 30, 128)\n",
      "Shape Y (611, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 488 samples, validate on 123 samples\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 2.2788 - acc: 0.1066 - val_loss: 2.2302 - val_acc: 0.1463\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 0s 540us/step - loss: 2.2287 - acc: 0.1434 - val_loss: 2.1796 - val_acc: 0.1789\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 0s 534us/step - loss: 2.1525 - acc: 0.1865 - val_loss: 2.1311 - val_acc: 0.2276\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 0s 548us/step - loss: 2.1043 - acc: 0.1947 - val_loss: 2.0847 - val_acc: 0.2602\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 0s 551us/step - loss: 2.0434 - acc: 0.2746 - val_loss: 2.0396 - val_acc: 0.3089\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 0s 529us/step - loss: 1.9891 - acc: 0.3689 - val_loss: 1.9949 - val_acc: 0.3415\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 0s 548us/step - loss: 1.9288 - acc: 0.3934 - val_loss: 1.9523 - val_acc: 0.3659\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 0s 524us/step - loss: 1.8769 - acc: 0.4447 - val_loss: 1.9106 - val_acc: 0.3902\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 0s 547us/step - loss: 1.8204 - acc: 0.4959 - val_loss: 1.8705 - val_acc: 0.3984\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 0s 537us/step - loss: 1.7747 - acc: 0.5184 - val_loss: 1.8319 - val_acc: 0.4065\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 0s 543us/step - loss: 1.7514 - acc: 0.5594 - val_loss: 1.7935 - val_acc: 0.4634\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 0s 559us/step - loss: 1.6939 - acc: 0.6148 - val_loss: 1.7546 - val_acc: 0.5203\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 0s 578us/step - loss: 1.6509 - acc: 0.6516 - val_loss: 1.7160 - val_acc: 0.5528\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 0s 568us/step - loss: 1.6095 - acc: 0.6639 - val_loss: 1.6775 - val_acc: 0.5691\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 0s 557us/step - loss: 1.5613 - acc: 0.6721 - val_loss: 1.6388 - val_acc: 0.5772\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 0s 580us/step - loss: 1.5027 - acc: 0.7070 - val_loss: 1.6004 - val_acc: 0.6179\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 0s 563us/step - loss: 1.4733 - acc: 0.7111 - val_loss: 1.5611 - val_acc: 0.6341\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 0s 565us/step - loss: 1.4255 - acc: 0.7459 - val_loss: 1.5206 - val_acc: 0.6667\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 0s 556us/step - loss: 1.3718 - acc: 0.7684 - val_loss: 1.4795 - val_acc: 0.6667\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 0s 566us/step - loss: 1.3086 - acc: 0.7787 - val_loss: 1.4388 - val_acc: 0.6829\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 0s 563us/step - loss: 1.2918 - acc: 0.7787 - val_loss: 1.3991 - val_acc: 0.6829\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 0s 572us/step - loss: 1.2408 - acc: 0.7910 - val_loss: 1.3608 - val_acc: 0.6829\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 0s 549us/step - loss: 1.1802 - acc: 0.8176 - val_loss: 1.3222 - val_acc: 0.6829\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 0s 569us/step - loss: 1.1428 - acc: 0.8299 - val_loss: 1.2841 - val_acc: 0.6829\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 0s 562us/step - loss: 1.0922 - acc: 0.8299 - val_loss: 1.2451 - val_acc: 0.6911\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 0s 574us/step - loss: 1.0647 - acc: 0.8361 - val_loss: 1.2067 - val_acc: 0.6992\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 0s 564us/step - loss: 0.9962 - acc: 0.8402 - val_loss: 1.1689 - val_acc: 0.6992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "488/488 [==============================] - 0s 553us/step - loss: 0.9876 - acc: 0.8504 - val_loss: 1.1321 - val_acc: 0.7073\n",
      "Epoch 29/100\n",
      "488/488 [==============================] - 0s 570us/step - loss: 0.9315 - acc: 0.8668 - val_loss: 1.0954 - val_acc: 0.7236\n",
      "Epoch 30/100\n",
      "488/488 [==============================] - 0s 570us/step - loss: 0.9122 - acc: 0.8607 - val_loss: 1.0580 - val_acc: 0.7642\n",
      "Epoch 31/100\n",
      "488/488 [==============================] - 0s 542us/step - loss: 0.8594 - acc: 0.8709 - val_loss: 1.0212 - val_acc: 0.7642\n",
      "Epoch 32/100\n",
      "488/488 [==============================] - 0s 552us/step - loss: 0.8175 - acc: 0.8852 - val_loss: 0.9855 - val_acc: 0.7805\n",
      "Epoch 33/100\n",
      "488/488 [==============================] - 0s 564us/step - loss: 0.7851 - acc: 0.9078 - val_loss: 0.9503 - val_acc: 0.7967\n",
      "Epoch 34/100\n",
      "488/488 [==============================] - 0s 556us/step - loss: 0.7626 - acc: 0.9201 - val_loss: 0.9179 - val_acc: 0.7967\n",
      "Epoch 35/100\n",
      "488/488 [==============================] - 0s 554us/step - loss: 0.7197 - acc: 0.9242 - val_loss: 0.8883 - val_acc: 0.7967\n",
      "Epoch 36/100\n",
      "488/488 [==============================] - 0s 563us/step - loss: 0.7073 - acc: 0.9283 - val_loss: 0.8590 - val_acc: 0.7967\n",
      "Epoch 37/100\n",
      "488/488 [==============================] - 0s 558us/step - loss: 0.6699 - acc: 0.9406 - val_loss: 0.8298 - val_acc: 0.8211\n",
      "Epoch 38/100\n",
      "488/488 [==============================] - 0s 551us/step - loss: 0.6393 - acc: 0.9467 - val_loss: 0.8018 - val_acc: 0.8293\n",
      "Epoch 39/100\n",
      "488/488 [==============================] - 0s 549us/step - loss: 0.6267 - acc: 0.9467 - val_loss: 0.7756 - val_acc: 0.8293\n",
      "Epoch 40/100\n",
      "488/488 [==============================] - 0s 559us/step - loss: 0.5923 - acc: 0.9447 - val_loss: 0.7510 - val_acc: 0.8293\n",
      "Epoch 41/100\n",
      "488/488 [==============================] - 0s 556us/step - loss: 0.5600 - acc: 0.9488 - val_loss: 0.7285 - val_acc: 0.8374\n",
      "Epoch 42/100\n",
      "488/488 [==============================] - 0s 566us/step - loss: 0.5473 - acc: 0.9529 - val_loss: 0.7072 - val_acc: 0.8537\n",
      "Epoch 43/100\n",
      "488/488 [==============================] - 0s 546us/step - loss: 0.5341 - acc: 0.9488 - val_loss: 0.6864 - val_acc: 0.8618\n",
      "Epoch 44/100\n",
      "488/488 [==============================] - 0s 566us/step - loss: 0.5190 - acc: 0.9570 - val_loss: 0.6665 - val_acc: 0.8618\n",
      "Epoch 45/100\n",
      "488/488 [==============================] - 0s 562us/step - loss: 0.4817 - acc: 0.9549 - val_loss: 0.6482 - val_acc: 0.8699\n",
      "Epoch 46/100\n",
      "488/488 [==============================] - 0s 556us/step - loss: 0.4669 - acc: 0.9631 - val_loss: 0.6309 - val_acc: 0.8699\n",
      "Epoch 47/100\n",
      "488/488 [==============================] - 0s 563us/step - loss: 0.4645 - acc: 0.9570 - val_loss: 0.6144 - val_acc: 0.8699\n",
      "Epoch 48/100\n",
      "488/488 [==============================] - 0s 548us/step - loss: 0.4498 - acc: 0.9611 - val_loss: 0.5987 - val_acc: 0.8699\n",
      "Epoch 49/100\n",
      "488/488 [==============================] - 0s 554us/step - loss: 0.4070 - acc: 0.9693 - val_loss: 0.5843 - val_acc: 0.8699\n",
      "Epoch 50/100\n",
      "488/488 [==============================] - 0s 560us/step - loss: 0.4167 - acc: 0.9631 - val_loss: 0.5705 - val_acc: 0.8699\n",
      "Epoch 51/100\n",
      "488/488 [==============================] - 0s 551us/step - loss: 0.4000 - acc: 0.9672 - val_loss: 0.5565 - val_acc: 0.8699\n",
      "Epoch 52/100\n",
      "488/488 [==============================] - 0s 571us/step - loss: 0.3874 - acc: 0.9631 - val_loss: 0.5418 - val_acc: 0.8699\n",
      "Epoch 53/100\n",
      "488/488 [==============================] - 0s 574us/step - loss: 0.3681 - acc: 0.9693 - val_loss: 0.5277 - val_acc: 0.8699\n",
      "Epoch 54/100\n",
      "488/488 [==============================] - 0s 561us/step - loss: 0.3454 - acc: 0.9734 - val_loss: 0.5144 - val_acc: 0.8780\n",
      "Epoch 55/100\n",
      "488/488 [==============================] - 0s 574us/step - loss: 0.3544 - acc: 0.9754 - val_loss: 0.5021 - val_acc: 0.8780\n",
      "Epoch 56/100\n",
      "488/488 [==============================] - 0s 547us/step - loss: 0.3378 - acc: 0.9713 - val_loss: 0.4903 - val_acc: 0.8780\n",
      "Epoch 57/100\n",
      "488/488 [==============================] - 0s 560us/step - loss: 0.3359 - acc: 0.9754 - val_loss: 0.4785 - val_acc: 0.8780\n",
      "Epoch 58/100\n",
      "488/488 [==============================] - 0s 559us/step - loss: 0.3188 - acc: 0.9795 - val_loss: 0.4683 - val_acc: 0.8780\n",
      "Epoch 59/100\n",
      "488/488 [==============================] - 0s 552us/step - loss: 0.3051 - acc: 0.9775 - val_loss: 0.4587 - val_acc: 0.8862\n",
      "Epoch 60/100\n",
      "488/488 [==============================] - 0s 558us/step - loss: 0.2968 - acc: 0.9795 - val_loss: 0.4490 - val_acc: 0.8862\n",
      "Epoch 61/100\n",
      "488/488 [==============================] - 0s 565us/step - loss: 0.2936 - acc: 0.9754 - val_loss: 0.4400 - val_acc: 0.8943\n",
      "Epoch 62/100\n",
      "488/488 [==============================] - 0s 555us/step - loss: 0.2819 - acc: 0.9754 - val_loss: 0.4315 - val_acc: 0.8943\n",
      "Epoch 63/100\n",
      "488/488 [==============================] - 0s 563us/step - loss: 0.2753 - acc: 0.9754 - val_loss: 0.4229 - val_acc: 0.8943\n",
      "Epoch 64/100\n",
      "488/488 [==============================] - 0s 554us/step - loss: 0.2668 - acc: 0.9857 - val_loss: 0.4145 - val_acc: 0.8943\n",
      "Epoch 65/100\n",
      "488/488 [==============================] - 0s 555us/step - loss: 0.2421 - acc: 0.9795 - val_loss: 0.4067 - val_acc: 0.8943\n",
      "Epoch 66/100\n",
      "488/488 [==============================] - 0s 554us/step - loss: 0.2423 - acc: 0.9816 - val_loss: 0.3992 - val_acc: 0.8943\n",
      "Epoch 67/100\n",
      "488/488 [==============================] - 0s 567us/step - loss: 0.2376 - acc: 0.9836 - val_loss: 0.3919 - val_acc: 0.8943\n",
      "Epoch 68/100\n",
      "488/488 [==============================] - 0s 553us/step - loss: 0.2254 - acc: 0.9836 - val_loss: 0.3847 - val_acc: 0.8943\n",
      "Epoch 69/100\n",
      "488/488 [==============================] - 0s 560us/step - loss: 0.2154 - acc: 0.9816 - val_loss: 0.3776 - val_acc: 0.9024\n",
      "Epoch 70/100\n",
      "488/488 [==============================] - 0s 551us/step - loss: 0.2183 - acc: 0.9857 - val_loss: 0.3708 - val_acc: 0.9024\n",
      "Epoch 71/100\n",
      "488/488 [==============================] - 0s 565us/step - loss: 0.2085 - acc: 0.9857 - val_loss: 0.3642 - val_acc: 0.9024\n",
      "Epoch 72/100\n",
      "488/488 [==============================] - 0s 552us/step - loss: 0.1978 - acc: 0.9857 - val_loss: 0.3579 - val_acc: 0.9024\n",
      "Epoch 73/100\n",
      "488/488 [==============================] - 0s 562us/step - loss: 0.1942 - acc: 0.9857 - val_loss: 0.3521 - val_acc: 0.9106\n",
      "Epoch 74/100\n",
      "488/488 [==============================] - 0s 561us/step - loss: 0.1943 - acc: 0.9857 - val_loss: 0.3468 - val_acc: 0.9106\n",
      "Epoch 75/100\n",
      "488/488 [==============================] - 0s 557us/step - loss: 0.1896 - acc: 0.9857 - val_loss: 0.3420 - val_acc: 0.9106\n",
      "Epoch 76/100\n",
      "488/488 [==============================] - 0s 552us/step - loss: 0.1842 - acc: 0.9857 - val_loss: 0.3372 - val_acc: 0.9106\n",
      "Epoch 77/100\n",
      "488/488 [==============================] - 0s 568us/step - loss: 0.1696 - acc: 0.9857 - val_loss: 0.3326 - val_acc: 0.9106\n",
      "Epoch 78/100\n",
      "488/488 [==============================] - 0s 560us/step - loss: 0.1668 - acc: 0.9836 - val_loss: 0.3281 - val_acc: 0.9106\n",
      "Epoch 79/100\n",
      "488/488 [==============================] - 0s 553us/step - loss: 0.1578 - acc: 0.9857 - val_loss: 0.3238 - val_acc: 0.9106\n",
      "Epoch 80/100\n",
      "488/488 [==============================] - 0s 559us/step - loss: 0.1572 - acc: 0.9857 - val_loss: 0.3195 - val_acc: 0.9106\n",
      "Epoch 81/100\n",
      "488/488 [==============================] - 0s 578us/step - loss: 0.1588 - acc: 0.9857 - val_loss: 0.3154 - val_acc: 0.9106\n",
      "Epoch 82/100\n",
      "488/488 [==============================] - 0s 569us/step - loss: 0.1548 - acc: 0.9857 - val_loss: 0.3115 - val_acc: 0.9106\n",
      "Epoch 83/100\n",
      "488/488 [==============================] - 0s 564us/step - loss: 0.1627 - acc: 0.9857 - val_loss: 0.3077 - val_acc: 0.9106\n",
      "Epoch 84/100\n",
      "488/488 [==============================] - 0s 560us/step - loss: 0.1491 - acc: 0.9857 - val_loss: 0.3039 - val_acc: 0.9106\n",
      "Epoch 85/100\n",
      "488/488 [==============================] - 0s 560us/step - loss: 0.1446 - acc: 0.9857 - val_loss: 0.3001 - val_acc: 0.9106\n",
      "Epoch 86/100\n",
      "488/488 [==============================] - 0s 562us/step - loss: 0.1377 - acc: 0.9857 - val_loss: 0.2964 - val_acc: 0.9187\n",
      "Epoch 87/100\n",
      "488/488 [==============================] - 0s 551us/step - loss: 0.1436 - acc: 0.9857 - val_loss: 0.2929 - val_acc: 0.9268\n",
      "Epoch 88/100\n",
      "488/488 [==============================] - 0s 550us/step - loss: 0.1362 - acc: 0.9857 - val_loss: 0.2894 - val_acc: 0.9268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "488/488 [==============================] - 0s 562us/step - loss: 0.1387 - acc: 0.9836 - val_loss: 0.2860 - val_acc: 0.9268\n",
      "Epoch 90/100\n",
      "488/488 [==============================] - 0s 563us/step - loss: 0.1301 - acc: 0.9836 - val_loss: 0.2828 - val_acc: 0.9268\n",
      "Epoch 91/100\n",
      "488/488 [==============================] - 0s 548us/step - loss: 0.1248 - acc: 0.9857 - val_loss: 0.2796 - val_acc: 0.9268\n",
      "Epoch 92/100\n",
      "488/488 [==============================] - 0s 558us/step - loss: 0.1243 - acc: 0.9877 - val_loss: 0.2765 - val_acc: 0.9268\n",
      "Epoch 93/100\n",
      "488/488 [==============================] - 0s 549us/step - loss: 0.1237 - acc: 0.9857 - val_loss: 0.2732 - val_acc: 0.9268\n",
      "Epoch 94/100\n",
      "488/488 [==============================] - 0s 549us/step - loss: 0.1168 - acc: 0.9877 - val_loss: 0.2699 - val_acc: 0.9268\n",
      "Epoch 95/100\n",
      "488/488 [==============================] - 0s 559us/step - loss: 0.1116 - acc: 0.9857 - val_loss: 0.2666 - val_acc: 0.9268\n",
      "Epoch 96/100\n",
      "488/488 [==============================] - 0s 560us/step - loss: 0.1146 - acc: 0.9857 - val_loss: 0.2635 - val_acc: 0.9268\n",
      "Epoch 97/100\n",
      "488/488 [==============================] - 0s 562us/step - loss: 0.1103 - acc: 0.9857 - val_loss: 0.2609 - val_acc: 0.9268\n",
      "Epoch 98/100\n",
      "488/488 [==============================] - 0s 556us/step - loss: 0.1107 - acc: 0.9877 - val_loss: 0.2586 - val_acc: 0.9268\n",
      "Epoch 99/100\n",
      "488/488 [==============================] - 0s 550us/step - loss: 0.1140 - acc: 0.9877 - val_loss: 0.2567 - val_acc: 0.9268\n",
      "Epoch 100/100\n",
      "488/488 [==============================] - 0s 563us/step - loss: 0.1099 - acc: 0.9877 - val_loss: 0.2549 - val_acc: 0.9268\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (489, 40, 128)\n",
      "Shape Y (489, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 391 samples, validate on 98 samples\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.2916 - acc: 0.0614 - val_loss: 2.2200 - val_acc: 0.1020\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 0s 732us/step - loss: 2.2209 - acc: 0.0946 - val_loss: 2.1516 - val_acc: 0.2143\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 0s 719us/step - loss: 2.1596 - acc: 0.1739 - val_loss: 2.0904 - val_acc: 0.3061\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 0s 707us/step - loss: 2.0852 - acc: 0.2327 - val_loss: 2.0336 - val_acc: 0.4490\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 0s 704us/step - loss: 2.0369 - acc: 0.3197 - val_loss: 1.9787 - val_acc: 0.5306\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 0s 725us/step - loss: 1.9960 - acc: 0.3606 - val_loss: 1.9270 - val_acc: 0.5918\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 0s 702us/step - loss: 1.9423 - acc: 0.4143 - val_loss: 1.8777 - val_acc: 0.6531\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 0s 701us/step - loss: 1.8947 - acc: 0.4783 - val_loss: 1.8301 - val_acc: 0.6939\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 0s 720us/step - loss: 1.8607 - acc: 0.4987 - val_loss: 1.7835 - val_acc: 0.7449\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 0s 721us/step - loss: 1.8150 - acc: 0.5729 - val_loss: 1.7384 - val_acc: 0.7551\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 0s 750us/step - loss: 1.7726 - acc: 0.5857 - val_loss: 1.6938 - val_acc: 0.7653\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 0s 741us/step - loss: 1.7185 - acc: 0.6087 - val_loss: 1.6503 - val_acc: 0.7755\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 0s 772us/step - loss: 1.6964 - acc: 0.6419 - val_loss: 1.6072 - val_acc: 0.7755\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 0s 735us/step - loss: 1.6423 - acc: 0.6624 - val_loss: 1.5616 - val_acc: 0.7959\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 0s 742us/step - loss: 1.6000 - acc: 0.7059 - val_loss: 1.5192 - val_acc: 0.7959\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 0s 754us/step - loss: 1.5538 - acc: 0.6957 - val_loss: 1.4776 - val_acc: 0.7959\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 0s 731us/step - loss: 1.5255 - acc: 0.7187 - val_loss: 1.4361 - val_acc: 0.7959\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 0s 746us/step - loss: 1.4999 - acc: 0.7315 - val_loss: 1.3942 - val_acc: 0.7959\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 0s 744us/step - loss: 1.4334 - acc: 0.7545 - val_loss: 1.3536 - val_acc: 0.7959\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 0s 743us/step - loss: 1.4129 - acc: 0.7136 - val_loss: 1.3133 - val_acc: 0.7959\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 0s 733us/step - loss: 1.3802 - acc: 0.7519 - val_loss: 1.2740 - val_acc: 0.8061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "391/391 [==============================] - 0s 754us/step - loss: 1.3480 - acc: 0.7468 - val_loss: 1.2356 - val_acc: 0.8061\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 0s 778us/step - loss: 1.3145 - acc: 0.7519 - val_loss: 1.1981 - val_acc: 0.8061\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 0s 785us/step - loss: 1.2901 - acc: 0.7724 - val_loss: 1.1611 - val_acc: 0.8163\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 0s 744us/step - loss: 1.2389 - acc: 0.7749 - val_loss: 1.1245 - val_acc: 0.8265\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 0s 720us/step - loss: 1.2117 - acc: 0.7698 - val_loss: 1.0890 - val_acc: 0.8367\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 0s 744us/step - loss: 1.1963 - acc: 0.7801 - val_loss: 1.0541 - val_acc: 0.8367\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 0s 739us/step - loss: 1.1532 - acc: 0.7826 - val_loss: 1.0197 - val_acc: 0.8367\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 0s 733us/step - loss: 1.1104 - acc: 0.8005 - val_loss: 0.9857 - val_acc: 0.8367\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 0s 751us/step - loss: 1.0813 - acc: 0.8107 - val_loss: 0.9522 - val_acc: 0.8469\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 0s 728us/step - loss: 1.0457 - acc: 0.8082 - val_loss: 0.9194 - val_acc: 0.8469\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 0s 737us/step - loss: 1.0355 - acc: 0.8056 - val_loss: 0.8860 - val_acc: 0.8469\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 0s 745us/step - loss: 0.9974 - acc: 0.8414 - val_loss: 0.8530 - val_acc: 0.8571\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 0s 746us/step - loss: 0.9582 - acc: 0.8261 - val_loss: 0.8214 - val_acc: 0.8673\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 0s 724us/step - loss: 0.9124 - acc: 0.8440 - val_loss: 0.7898 - val_acc: 0.8776\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 0s 744us/step - loss: 0.8788 - acc: 0.8696 - val_loss: 0.7593 - val_acc: 0.8776\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 0s 748us/step - loss: 0.8478 - acc: 0.8696 - val_loss: 0.7309 - val_acc: 0.8878\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 0s 729us/step - loss: 0.8375 - acc: 0.8747 - val_loss: 0.7024 - val_acc: 0.8878\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 0s 747us/step - loss: 0.8090 - acc: 0.8772 - val_loss: 0.6750 - val_acc: 0.8980\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 0s 742us/step - loss: 0.7720 - acc: 0.9028 - val_loss: 0.6486 - val_acc: 0.8980\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 0s 734us/step - loss: 0.7662 - acc: 0.8900 - val_loss: 0.6236 - val_acc: 0.8980\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 0s 747us/step - loss: 0.7273 - acc: 0.8875 - val_loss: 0.5993 - val_acc: 0.9082\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 0s 717us/step - loss: 0.7000 - acc: 0.8977 - val_loss: 0.5760 - val_acc: 0.9082\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 0s 742us/step - loss: 0.6943 - acc: 0.9079 - val_loss: 0.5535 - val_acc: 0.9082\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 0s 739us/step - loss: 0.6694 - acc: 0.8926 - val_loss: 0.5316 - val_acc: 0.9082\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 0s 740us/step - loss: 0.6433 - acc: 0.9003 - val_loss: 0.5109 - val_acc: 0.9286\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 0s 746us/step - loss: 0.6121 - acc: 0.9207 - val_loss: 0.4911 - val_acc: 0.9388\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 0s 753us/step - loss: 0.5955 - acc: 0.9079 - val_loss: 0.4724 - val_acc: 0.9388\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 0s 742us/step - loss: 0.5677 - acc: 0.9361 - val_loss: 0.4543 - val_acc: 0.9388\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 0s 741us/step - loss: 0.5382 - acc: 0.9386 - val_loss: 0.4364 - val_acc: 0.9490\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 0s 781us/step - loss: 0.5262 - acc: 0.9488 - val_loss: 0.4183 - val_acc: 0.9490\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 0s 829us/step - loss: 0.5199 - acc: 0.9361 - val_loss: 0.4021 - val_acc: 0.9490\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 0s 737us/step - loss: 0.4972 - acc: 0.9463 - val_loss: 0.3871 - val_acc: 0.9592\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 0s 742us/step - loss: 0.4774 - acc: 0.9361 - val_loss: 0.3730 - val_acc: 0.9592\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 0s 746us/step - loss: 0.4608 - acc: 0.9488 - val_loss: 0.3597 - val_acc: 0.9592\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 0s 720us/step - loss: 0.4444 - acc: 0.9412 - val_loss: 0.3469 - val_acc: 0.9592\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 0s 754us/step - loss: 0.4246 - acc: 0.9488 - val_loss: 0.3347 - val_acc: 0.9592\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 0s 745us/step - loss: 0.4203 - acc: 0.9591 - val_loss: 0.3230 - val_acc: 0.9592\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 0s 733us/step - loss: 0.3961 - acc: 0.9514 - val_loss: 0.3118 - val_acc: 0.9592\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 0s 739us/step - loss: 0.4011 - acc: 0.9591 - val_loss: 0.3009 - val_acc: 0.9592\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 0s 743us/step - loss: 0.3665 - acc: 0.9565 - val_loss: 0.2905 - val_acc: 0.9592\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 0s 731us/step - loss: 0.3867 - acc: 0.9514 - val_loss: 0.2805 - val_acc: 0.9592\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 0s 724us/step - loss: 0.3667 - acc: 0.9540 - val_loss: 0.2707 - val_acc: 0.9592\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 0s 741us/step - loss: 0.3432 - acc: 0.9616 - val_loss: 0.2612 - val_acc: 0.9592\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 0s 734us/step - loss: 0.3338 - acc: 0.9514 - val_loss: 0.2519 - val_acc: 0.9796\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 0s 746us/step - loss: 0.3346 - acc: 0.9668 - val_loss: 0.2423 - val_acc: 0.9796\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 0s 732us/step - loss: 0.3099 - acc: 0.9668 - val_loss: 0.2316 - val_acc: 0.9796\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 0s 764us/step - loss: 0.2992 - acc: 0.9642 - val_loss: 0.2225 - val_acc: 0.9796\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 0s 736us/step - loss: 0.2926 - acc: 0.9616 - val_loss: 0.2145 - val_acc: 0.9796\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 0s 744us/step - loss: 0.2838 - acc: 0.9693 - val_loss: 0.2068 - val_acc: 0.9796\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 0s 760us/step - loss: 0.2847 - acc: 0.9719 - val_loss: 0.1997 - val_acc: 0.9796\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 0s 750us/step - loss: 0.2552 - acc: 0.9719 - val_loss: 0.1931 - val_acc: 0.9796\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 0s 725us/step - loss: 0.2516 - acc: 0.9847 - val_loss: 0.1866 - val_acc: 0.9796\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 0s 741us/step - loss: 0.2486 - acc: 0.9795 - val_loss: 0.1805 - val_acc: 0.9796\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 0s 767us/step - loss: 0.2373 - acc: 0.9847 - val_loss: 0.1746 - val_acc: 0.9796\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 0s 734us/step - loss: 0.2226 - acc: 0.9795 - val_loss: 0.1689 - val_acc: 0.9796\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 0s 757us/step - loss: 0.2269 - acc: 0.9770 - val_loss: 0.1628 - val_acc: 0.9796\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 0s 745us/step - loss: 0.2169 - acc: 0.9795 - val_loss: 0.1567 - val_acc: 0.9796\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 0s 736us/step - loss: 0.2132 - acc: 0.9821 - val_loss: 0.1514 - val_acc: 0.9796\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 0s 834us/step - loss: 0.2044 - acc: 0.9847 - val_loss: 0.1469 - val_acc: 0.9796\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 0s 747us/step - loss: 0.2121 - acc: 0.9770 - val_loss: 0.1423 - val_acc: 0.9796\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 0s 755us/step - loss: 0.2025 - acc: 0.9847 - val_loss: 0.1382 - val_acc: 0.9796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "391/391 [==============================] - 0s 740us/step - loss: 0.1862 - acc: 0.9923 - val_loss: 0.1340 - val_acc: 0.9796\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 0s 716us/step - loss: 0.1864 - acc: 0.9847 - val_loss: 0.1302 - val_acc: 0.9796\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 0s 756us/step - loss: 0.1690 - acc: 0.9923 - val_loss: 0.1269 - val_acc: 0.9796\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 0s 732us/step - loss: 0.1754 - acc: 0.9898 - val_loss: 0.1236 - val_acc: 0.9796\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 0s 743us/step - loss: 0.1642 - acc: 0.9949 - val_loss: 0.1207 - val_acc: 0.9796\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 0s 738us/step - loss: 0.1646 - acc: 0.9949 - val_loss: 0.1178 - val_acc: 0.9796\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 0s 744us/step - loss: 0.1569 - acc: 0.9923 - val_loss: 0.1151 - val_acc: 0.9796\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 0s 730us/step - loss: 0.1625 - acc: 0.9923 - val_loss: 0.1125 - val_acc: 0.9796\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 0s 747us/step - loss: 0.1526 - acc: 0.9923 - val_loss: 0.1105 - val_acc: 0.9796\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 0s 744us/step - loss: 0.1469 - acc: 0.9949 - val_loss: 0.1081 - val_acc: 0.9796\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 0s 718us/step - loss: 0.1468 - acc: 0.9974 - val_loss: 0.1059 - val_acc: 0.9796\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 0s 742us/step - loss: 0.1419 - acc: 0.9923 - val_loss: 0.1042 - val_acc: 0.9796\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 0s 736us/step - loss: 0.1436 - acc: 0.9898 - val_loss: 0.1024 - val_acc: 0.9796\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 0s 838us/step - loss: 0.1376 - acc: 0.9949 - val_loss: 0.1007 - val_acc: 0.9796\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 0s 762us/step - loss: 0.1335 - acc: 0.9974 - val_loss: 0.0991 - val_acc: 0.9796\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 0s 729us/step - loss: 0.1215 - acc: 0.9949 - val_loss: 0.0975 - val_acc: 0.9796\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 0s 761us/step - loss: 0.1260 - acc: 0.9949 - val_loss: 0.0960 - val_acc: 0.9796\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 0s 742us/step - loss: 0.1256 - acc: 0.9898 - val_loss: 0.0947 - val_acc: 0.9898\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (382, 50, 128)\n",
      "Shape Y (382, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 305 samples, validate on 77 samples\n",
      "Epoch 1/100\n",
      "305/305 [==============================] - 3s 10ms/step - loss: 2.2266 - acc: 0.1082 - val_loss: 2.1853 - val_acc: 0.0519\n",
      "Epoch 2/100\n",
      "305/305 [==============================] - 0s 980us/step - loss: 2.1386 - acc: 0.1803 - val_loss: 2.1143 - val_acc: 0.1299\n",
      "Epoch 3/100\n",
      "305/305 [==============================] - 0s 990us/step - loss: 2.0826 - acc: 0.2262 - val_loss: 2.0486 - val_acc: 0.1948\n",
      "Epoch 4/100\n",
      "305/305 [==============================] - 0s 967us/step - loss: 2.0229 - acc: 0.2918 - val_loss: 1.9875 - val_acc: 0.3766\n",
      "Epoch 5/100\n",
      "305/305 [==============================] - 0s 948us/step - loss: 1.9681 - acc: 0.3443 - val_loss: 1.9294 - val_acc: 0.4675\n",
      "Epoch 6/100\n",
      "305/305 [==============================] - 0s 959us/step - loss: 1.9124 - acc: 0.4262 - val_loss: 1.8753 - val_acc: 0.5584\n",
      "Epoch 7/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 1.8522 - acc: 0.5115 - val_loss: 1.8224 - val_acc: 0.5714\n",
      "Epoch 8/100\n",
      "305/305 [==============================] - 0s 979us/step - loss: 1.8236 - acc: 0.5377 - val_loss: 1.7715 - val_acc: 0.6364\n",
      "Epoch 9/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 1.7650 - acc: 0.5639 - val_loss: 1.7217 - val_acc: 0.6753\n",
      "Epoch 10/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 1.7136 - acc: 0.6164 - val_loss: 1.6715 - val_acc: 0.6753\n",
      "Epoch 11/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 1.6885 - acc: 0.6328 - val_loss: 1.6222 - val_acc: 0.7013\n",
      "Epoch 12/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 1.6476 - acc: 0.6492 - val_loss: 1.5738 - val_acc: 0.7013\n",
      "Epoch 13/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 1.5802 - acc: 0.6885 - val_loss: 1.5259 - val_acc: 0.7273\n",
      "Epoch 14/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 1.5291 - acc: 0.7180 - val_loss: 1.4792 - val_acc: 0.7403\n",
      "Epoch 15/100\n",
      "305/305 [==============================] - 0s 999us/step - loss: 1.4965 - acc: 0.7213 - val_loss: 1.4335 - val_acc: 0.7792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 1.4609 - acc: 0.7115 - val_loss: 1.3885 - val_acc: 0.8052\n",
      "Epoch 17/100\n",
      "305/305 [==============================] - 0s 998us/step - loss: 1.4351 - acc: 0.6918 - val_loss: 1.3437 - val_acc: 0.8052\n",
      "Epoch 18/100\n",
      "305/305 [==============================] - 0s 980us/step - loss: 1.3878 - acc: 0.7377 - val_loss: 1.2991 - val_acc: 0.7922\n",
      "Epoch 19/100\n",
      "305/305 [==============================] - 0s 992us/step - loss: 1.3483 - acc: 0.7180 - val_loss: 1.2543 - val_acc: 0.7922\n",
      "Epoch 20/100\n",
      "305/305 [==============================] - 0s 998us/step - loss: 1.2707 - acc: 0.7607 - val_loss: 1.2086 - val_acc: 0.7922\n",
      "Epoch 21/100\n",
      "305/305 [==============================] - 0s 986us/step - loss: 1.2659 - acc: 0.7705 - val_loss: 1.1638 - val_acc: 0.7792\n",
      "Epoch 22/100\n",
      "305/305 [==============================] - 0s 995us/step - loss: 1.2088 - acc: 0.7967 - val_loss: 1.1222 - val_acc: 0.7792\n",
      "Epoch 23/100\n",
      "305/305 [==============================] - 0s 994us/step - loss: 1.1646 - acc: 0.7869 - val_loss: 1.0822 - val_acc: 0.8182\n",
      "Epoch 24/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 1.1360 - acc: 0.7934 - val_loss: 1.0441 - val_acc: 0.8182\n",
      "Epoch 25/100\n",
      "305/305 [==============================] - 0s 988us/step - loss: 1.0895 - acc: 0.8066 - val_loss: 1.0080 - val_acc: 0.8182\n",
      "Epoch 26/100\n",
      "305/305 [==============================] - 0s 999us/step - loss: 1.0716 - acc: 0.7967 - val_loss: 0.9729 - val_acc: 0.8442\n",
      "Epoch 27/100\n",
      "305/305 [==============================] - 0s 989us/step - loss: 1.0224 - acc: 0.8131 - val_loss: 0.9394 - val_acc: 0.8571\n",
      "Epoch 28/100\n",
      "305/305 [==============================] - 0s 984us/step - loss: 0.9778 - acc: 0.8328 - val_loss: 0.9071 - val_acc: 0.8571\n",
      "Epoch 29/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.9417 - acc: 0.8459 - val_loss: 0.8768 - val_acc: 0.8701\n",
      "Epoch 30/100\n",
      "305/305 [==============================] - 0s 987us/step - loss: 0.9212 - acc: 0.8492 - val_loss: 0.8473 - val_acc: 0.8701\n",
      "Epoch 31/100\n",
      "305/305 [==============================] - 0s 998us/step - loss: 0.8858 - acc: 0.8459 - val_loss: 0.8155 - val_acc: 0.8831\n",
      "Epoch 32/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.8413 - acc: 0.8787 - val_loss: 0.7888 - val_acc: 0.8831\n",
      "Epoch 33/100\n",
      "305/305 [==============================] - 0s 995us/step - loss: 0.8297 - acc: 0.8885 - val_loss: 0.7649 - val_acc: 0.8831\n",
      "Epoch 34/100\n",
      "305/305 [==============================] - 0s 989us/step - loss: 0.7732 - acc: 0.8820 - val_loss: 0.7424 - val_acc: 0.8831\n",
      "Epoch 35/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.7500 - acc: 0.8918 - val_loss: 0.7201 - val_acc: 0.8831\n",
      "Epoch 36/100\n",
      "305/305 [==============================] - 0s 994us/step - loss: 0.7198 - acc: 0.9049 - val_loss: 0.6983 - val_acc: 0.8831\n",
      "Epoch 37/100\n",
      "305/305 [==============================] - 0s 996us/step - loss: 0.6901 - acc: 0.9049 - val_loss: 0.6781 - val_acc: 0.8961\n",
      "Epoch 38/100\n",
      "305/305 [==============================] - 0s 988us/step - loss: 0.6832 - acc: 0.8984 - val_loss: 0.6593 - val_acc: 0.8961\n",
      "Epoch 39/100\n",
      "305/305 [==============================] - 0s 990us/step - loss: 0.6623 - acc: 0.9016 - val_loss: 0.6414 - val_acc: 0.8961\n",
      "Epoch 40/100\n",
      "305/305 [==============================] - 0s 997us/step - loss: 0.6458 - acc: 0.9148 - val_loss: 0.6239 - val_acc: 0.9091\n",
      "Epoch 41/100\n",
      "305/305 [==============================] - 0s 973us/step - loss: 0.6235 - acc: 0.9082 - val_loss: 0.6061 - val_acc: 0.9091\n",
      "Epoch 42/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.5900 - acc: 0.9213 - val_loss: 0.5884 - val_acc: 0.9091\n",
      "Epoch 43/100\n",
      "305/305 [==============================] - 0s 990us/step - loss: 0.5756 - acc: 0.9213 - val_loss: 0.5710 - val_acc: 0.9091\n",
      "Epoch 44/100\n",
      "305/305 [==============================] - 0s 989us/step - loss: 0.5529 - acc: 0.9311 - val_loss: 0.5551 - val_acc: 0.9091\n",
      "Epoch 45/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.5356 - acc: 0.9279 - val_loss: 0.5399 - val_acc: 0.9091\n",
      "Epoch 46/100\n",
      "305/305 [==============================] - 0s 997us/step - loss: 0.5074 - acc: 0.9344 - val_loss: 0.5251 - val_acc: 0.9091\n",
      "Epoch 47/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.4940 - acc: 0.9344 - val_loss: 0.5108 - val_acc: 0.9091\n",
      "Epoch 48/100\n",
      "305/305 [==============================] - 0s 986us/step - loss: 0.4715 - acc: 0.9410 - val_loss: 0.4965 - val_acc: 0.9091\n",
      "Epoch 49/100\n",
      "305/305 [==============================] - 0s 1000us/step - loss: 0.4489 - acc: 0.9508 - val_loss: 0.4817 - val_acc: 0.9091\n",
      "Epoch 50/100\n",
      "305/305 [==============================] - 0s 988us/step - loss: 0.4464 - acc: 0.9475 - val_loss: 0.4665 - val_acc: 0.9221\n",
      "Epoch 51/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.4317 - acc: 0.9443 - val_loss: 0.4517 - val_acc: 0.9221\n",
      "Epoch 52/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.4191 - acc: 0.9443 - val_loss: 0.4384 - val_acc: 0.9221\n",
      "Epoch 53/100\n",
      "305/305 [==============================] - 0s 986us/step - loss: 0.3904 - acc: 0.9541 - val_loss: 0.4264 - val_acc: 0.9221\n",
      "Epoch 54/100\n",
      "305/305 [==============================] - 0s 992us/step - loss: 0.3761 - acc: 0.9508 - val_loss: 0.4151 - val_acc: 0.9221\n",
      "Epoch 55/100\n",
      "305/305 [==============================] - 0s 990us/step - loss: 0.3708 - acc: 0.9541 - val_loss: 0.4045 - val_acc: 0.9221\n",
      "Epoch 56/100\n",
      "305/305 [==============================] - 0s 991us/step - loss: 0.3720 - acc: 0.9508 - val_loss: 0.3943 - val_acc: 0.9221\n",
      "Epoch 57/100\n",
      "305/305 [==============================] - 0s 994us/step - loss: 0.3605 - acc: 0.9508 - val_loss: 0.3843 - val_acc: 0.9221\n",
      "Epoch 58/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.3413 - acc: 0.9574 - val_loss: 0.3748 - val_acc: 0.9221\n",
      "Epoch 59/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.3343 - acc: 0.9574 - val_loss: 0.3659 - val_acc: 0.9221\n",
      "Epoch 60/100\n",
      "305/305 [==============================] - 0s 983us/step - loss: 0.3225 - acc: 0.9607 - val_loss: 0.3579 - val_acc: 0.9221\n",
      "Epoch 61/100\n",
      "305/305 [==============================] - 0s 984us/step - loss: 0.3141 - acc: 0.9574 - val_loss: 0.3500 - val_acc: 0.9221\n",
      "Epoch 62/100\n",
      "305/305 [==============================] - 0s 977us/step - loss: 0.3022 - acc: 0.9607 - val_loss: 0.3426 - val_acc: 0.9221\n",
      "Epoch 63/100\n",
      "305/305 [==============================] - 0s 989us/step - loss: 0.2953 - acc: 0.9574 - val_loss: 0.3353 - val_acc: 0.9221\n",
      "Epoch 64/100\n",
      "305/305 [==============================] - 0s 976us/step - loss: 0.2856 - acc: 0.9607 - val_loss: 0.3283 - val_acc: 0.9221\n",
      "Epoch 65/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.2750 - acc: 0.9607 - val_loss: 0.3215 - val_acc: 0.9221\n",
      "Epoch 66/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.2784 - acc: 0.9541 - val_loss: 0.3148 - val_acc: 0.9221\n",
      "Epoch 67/100\n",
      "305/305 [==============================] - 0s 987us/step - loss: 0.2648 - acc: 0.9574 - val_loss: 0.3080 - val_acc: 0.9221\n",
      "Epoch 68/100\n",
      "305/305 [==============================] - 0s 998us/step - loss: 0.2491 - acc: 0.9607 - val_loss: 0.3016 - val_acc: 0.9221\n",
      "Epoch 69/100\n",
      "305/305 [==============================] - 0s 994us/step - loss: 0.2470 - acc: 0.9607 - val_loss: 0.2959 - val_acc: 0.9221\n",
      "Epoch 70/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.2426 - acc: 0.9639 - val_loss: 0.2903 - val_acc: 0.9221\n",
      "Epoch 71/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.2296 - acc: 0.9639 - val_loss: 0.2850 - val_acc: 0.9221\n",
      "Epoch 72/100\n",
      "305/305 [==============================] - 0s 999us/step - loss: 0.2290 - acc: 0.9607 - val_loss: 0.2799 - val_acc: 0.9221\n",
      "Epoch 73/100\n",
      "305/305 [==============================] - 0s 998us/step - loss: 0.2233 - acc: 0.9639 - val_loss: 0.2749 - val_acc: 0.9221\n",
      "Epoch 74/100\n",
      "305/305 [==============================] - 0s 978us/step - loss: 0.2184 - acc: 0.9672 - val_loss: 0.2703 - val_acc: 0.9221\n",
      "Epoch 75/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.2073 - acc: 0.9672 - val_loss: 0.2658 - val_acc: 0.9221\n",
      "Epoch 76/100\n",
      "305/305 [==============================] - 0s 983us/step - loss: 0.2018 - acc: 0.9574 - val_loss: 0.2618 - val_acc: 0.9221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "305/305 [==============================] - 0s 989us/step - loss: 0.2061 - acc: 0.9672 - val_loss: 0.2582 - val_acc: 0.9221\n",
      "Epoch 78/100\n",
      "305/305 [==============================] - 0s 984us/step - loss: 0.1909 - acc: 0.9672 - val_loss: 0.2548 - val_acc: 0.9221\n",
      "Epoch 79/100\n",
      "305/305 [==============================] - 0s 998us/step - loss: 0.2066 - acc: 0.9639 - val_loss: 0.2517 - val_acc: 0.9221\n",
      "Epoch 80/100\n",
      "305/305 [==============================] - 0s 991us/step - loss: 0.1954 - acc: 0.9639 - val_loss: 0.2492 - val_acc: 0.9351\n",
      "Epoch 81/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.1762 - acc: 0.9770 - val_loss: 0.2468 - val_acc: 0.9351\n",
      "Epoch 82/100\n",
      "305/305 [==============================] - 0s 991us/step - loss: 0.1700 - acc: 0.9705 - val_loss: 0.2441 - val_acc: 0.9351\n",
      "Epoch 83/100\n",
      "305/305 [==============================] - 0s 986us/step - loss: 0.1724 - acc: 0.9639 - val_loss: 0.2414 - val_acc: 0.9351\n",
      "Epoch 84/100\n",
      "305/305 [==============================] - 0s 985us/step - loss: 0.1690 - acc: 0.9770 - val_loss: 0.2387 - val_acc: 0.9351\n",
      "Epoch 85/100\n",
      "305/305 [==============================] - 0s 982us/step - loss: 0.1686 - acc: 0.9672 - val_loss: 0.2360 - val_acc: 0.9351\n",
      "Epoch 86/100\n",
      "305/305 [==============================] - 0s 979us/step - loss: 0.1637 - acc: 0.9803 - val_loss: 0.2331 - val_acc: 0.9351\n",
      "Epoch 87/100\n",
      "305/305 [==============================] - 0s 981us/step - loss: 0.1490 - acc: 0.9803 - val_loss: 0.2301 - val_acc: 0.9351\n",
      "Epoch 88/100\n",
      "305/305 [==============================] - 0s 989us/step - loss: 0.1594 - acc: 0.9705 - val_loss: 0.2274 - val_acc: 0.9351\n",
      "Epoch 89/100\n",
      "305/305 [==============================] - 0s 997us/step - loss: 0.1426 - acc: 0.9803 - val_loss: 0.2249 - val_acc: 0.9351\n",
      "Epoch 90/100\n",
      "305/305 [==============================] - 0s 982us/step - loss: 0.1486 - acc: 0.9770 - val_loss: 0.2225 - val_acc: 0.9351\n",
      "Epoch 91/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.1457 - acc: 0.9803 - val_loss: 0.2200 - val_acc: 0.9351\n",
      "Epoch 92/100\n",
      "305/305 [==============================] - 0s 991us/step - loss: 0.1386 - acc: 0.9803 - val_loss: 0.2176 - val_acc: 0.9351\n",
      "Epoch 93/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.1376 - acc: 0.9902 - val_loss: 0.2153 - val_acc: 0.9351\n",
      "Epoch 94/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.1305 - acc: 0.9869 - val_loss: 0.2132 - val_acc: 0.9351\n",
      "Epoch 95/100\n",
      "305/305 [==============================] - 0s 968us/step - loss: 0.1374 - acc: 0.9869 - val_loss: 0.2111 - val_acc: 0.9351\n",
      "Epoch 96/100\n",
      "305/305 [==============================] - 0s 966us/step - loss: 0.1315 - acc: 0.9869 - val_loss: 0.2090 - val_acc: 0.9351\n",
      "Epoch 97/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.1257 - acc: 0.9902 - val_loss: 0.2069 - val_acc: 0.9351\n",
      "Epoch 98/100\n",
      "305/305 [==============================] - 0s 1ms/step - loss: 0.1277 - acc: 0.9836 - val_loss: 0.2048 - val_acc: 0.9351\n",
      "Epoch 99/100\n",
      "305/305 [==============================] - 0s 974us/step - loss: 0.1297 - acc: 0.9803 - val_loss: 0.2026 - val_acc: 0.9351\n",
      "Epoch 100/100\n",
      "305/305 [==============================] - 0s 979us/step - loss: 0.1195 - acc: 0.9836 - val_loss: 0.2004 - val_acc: 0.9351\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (525, 20, 128)\n",
      "Shape Y (525, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 420 samples, validate on 105 samples\n",
      "Epoch 1/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 2.3120 - acc: 0.0810 - val_loss: 2.2832 - val_acc: 0.0857\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 0s 378us/step - loss: 2.2450 - acc: 0.0929 - val_loss: 2.2261 - val_acc: 0.1143\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 0s 394us/step - loss: 2.1848 - acc: 0.1857 - val_loss: 2.1720 - val_acc: 0.1524\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 0s 396us/step - loss: 2.1309 - acc: 0.2000 - val_loss: 2.1212 - val_acc: 0.1905\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 0s 389us/step - loss: 2.0727 - acc: 0.2548 - val_loss: 2.0729 - val_acc: 0.2571\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 0s 391us/step - loss: 2.0457 - acc: 0.3214 - val_loss: 2.0265 - val_acc: 0.3524\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 0s 390us/step - loss: 2.0005 - acc: 0.3857 - val_loss: 1.9819 - val_acc: 0.4190\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 0s 399us/step - loss: 1.9325 - acc: 0.4548 - val_loss: 1.9384 - val_acc: 0.4667\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 0s 396us/step - loss: 1.8883 - acc: 0.5262 - val_loss: 1.8956 - val_acc: 0.5524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "420/420 [==============================] - 0s 381us/step - loss: 1.8540 - acc: 0.5452 - val_loss: 1.8537 - val_acc: 0.6095\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 0s 380us/step - loss: 1.8077 - acc: 0.5881 - val_loss: 1.8128 - val_acc: 0.6476\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 0s 392us/step - loss: 1.7693 - acc: 0.6405 - val_loss: 1.7725 - val_acc: 0.6857\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 0s 382us/step - loss: 1.7195 - acc: 0.6452 - val_loss: 1.7319 - val_acc: 0.6952\n",
      "Epoch 14/100\n",
      "420/420 [==============================] - 0s 403us/step - loss: 1.7033 - acc: 0.6214 - val_loss: 1.6911 - val_acc: 0.6952\n",
      "Epoch 15/100\n",
      "420/420 [==============================] - 0s 453us/step - loss: 1.6464 - acc: 0.7238 - val_loss: 1.6507 - val_acc: 0.7048\n",
      "Epoch 16/100\n",
      "420/420 [==============================] - 0s 388us/step - loss: 1.5993 - acc: 0.7190 - val_loss: 1.6111 - val_acc: 0.7143\n",
      "Epoch 17/100\n",
      "420/420 [==============================] - 0s 395us/step - loss: 1.5629 - acc: 0.7405 - val_loss: 1.5713 - val_acc: 0.7238\n",
      "Epoch 18/100\n",
      "420/420 [==============================] - 0s 388us/step - loss: 1.5192 - acc: 0.7333 - val_loss: 1.5312 - val_acc: 0.7619\n",
      "Epoch 19/100\n",
      "420/420 [==============================] - 0s 390us/step - loss: 1.4952 - acc: 0.7238 - val_loss: 1.4905 - val_acc: 0.7619\n",
      "Epoch 20/100\n",
      "420/420 [==============================] - 0s 398us/step - loss: 1.4509 - acc: 0.7381 - val_loss: 1.4489 - val_acc: 0.7714\n",
      "Epoch 21/100\n",
      "420/420 [==============================] - 0s 385us/step - loss: 1.3862 - acc: 0.7857 - val_loss: 1.4063 - val_acc: 0.7810\n",
      "Epoch 22/100\n",
      "420/420 [==============================] - 0s 400us/step - loss: 1.3699 - acc: 0.7881 - val_loss: 1.3634 - val_acc: 0.7810\n",
      "Epoch 23/100\n",
      "420/420 [==============================] - 0s 407us/step - loss: 1.3264 - acc: 0.7929 - val_loss: 1.3198 - val_acc: 0.7905\n",
      "Epoch 24/100\n",
      "420/420 [==============================] - 0s 413us/step - loss: 1.2761 - acc: 0.8214 - val_loss: 1.2760 - val_acc: 0.7905\n",
      "Epoch 25/100\n",
      "420/420 [==============================] - 0s 395us/step - loss: 1.2496 - acc: 0.8143 - val_loss: 1.2317 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "420/420 [==============================] - 0s 414us/step - loss: 1.2161 - acc: 0.8214 - val_loss: 1.1865 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "420/420 [==============================] - 0s 401us/step - loss: 1.1710 - acc: 0.8262 - val_loss: 1.1416 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "420/420 [==============================] - 0s 408us/step - loss: 1.1409 - acc: 0.8405 - val_loss: 1.0977 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "420/420 [==============================] - 0s 394us/step - loss: 1.0851 - acc: 0.8357 - val_loss: 1.0558 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "420/420 [==============================] - 0s 407us/step - loss: 1.0271 - acc: 0.8667 - val_loss: 1.0156 - val_acc: 0.8095\n",
      "Epoch 31/100\n",
      "420/420 [==============================] - 0s 411us/step - loss: 1.0125 - acc: 0.8643 - val_loss: 0.9773 - val_acc: 0.8095\n",
      "Epoch 32/100\n",
      "420/420 [==============================] - 0s 397us/step - loss: 0.9649 - acc: 0.8619 - val_loss: 0.9404 - val_acc: 0.8190\n",
      "Epoch 33/100\n",
      "420/420 [==============================] - 0s 405us/step - loss: 0.9259 - acc: 0.8643 - val_loss: 0.9044 - val_acc: 0.8190\n",
      "Epoch 34/100\n",
      "420/420 [==============================] - 0s 403us/step - loss: 0.9035 - acc: 0.8690 - val_loss: 0.8702 - val_acc: 0.8381\n",
      "Epoch 35/100\n",
      "420/420 [==============================] - 0s 400us/step - loss: 0.8612 - acc: 0.8667 - val_loss: 0.8365 - val_acc: 0.8476\n",
      "Epoch 36/100\n",
      "420/420 [==============================] - 0s 404us/step - loss: 0.8317 - acc: 0.8810 - val_loss: 0.8044 - val_acc: 0.8476\n",
      "Epoch 37/100\n",
      "420/420 [==============================] - 0s 408us/step - loss: 0.8174 - acc: 0.8738 - val_loss: 0.7744 - val_acc: 0.8476\n",
      "Epoch 38/100\n",
      "420/420 [==============================] - 0s 414us/step - loss: 0.7781 - acc: 0.8952 - val_loss: 0.7465 - val_acc: 0.8476\n",
      "Epoch 39/100\n",
      "420/420 [==============================] - 0s 401us/step - loss: 0.7314 - acc: 0.8929 - val_loss: 0.7199 - val_acc: 0.8476\n",
      "Epoch 40/100\n",
      "420/420 [==============================] - 0s 409us/step - loss: 0.6965 - acc: 0.8881 - val_loss: 0.6947 - val_acc: 0.8476\n",
      "Epoch 41/100\n",
      "420/420 [==============================] - 0s 409us/step - loss: 0.6704 - acc: 0.9000 - val_loss: 0.6706 - val_acc: 0.8476\n",
      "Epoch 42/100\n",
      "420/420 [==============================] - 0s 397us/step - loss: 0.6648 - acc: 0.8952 - val_loss: 0.6476 - val_acc: 0.8571\n",
      "Epoch 43/100\n",
      "420/420 [==============================] - 0s 406us/step - loss: 0.6485 - acc: 0.9095 - val_loss: 0.6257 - val_acc: 0.8762\n",
      "Epoch 44/100\n",
      "420/420 [==============================] - 0s 407us/step - loss: 0.6103 - acc: 0.9048 - val_loss: 0.6044 - val_acc: 0.8952\n",
      "Epoch 45/100\n",
      "420/420 [==============================] - 0s 397us/step - loss: 0.5903 - acc: 0.9095 - val_loss: 0.5837 - val_acc: 0.8952\n",
      "Epoch 46/100\n",
      "420/420 [==============================] - 0s 414us/step - loss: 0.5720 - acc: 0.9095 - val_loss: 0.5639 - val_acc: 0.8952\n",
      "Epoch 47/100\n",
      "420/420 [==============================] - 0s 424us/step - loss: 0.5262 - acc: 0.9119 - val_loss: 0.5446 - val_acc: 0.8952\n",
      "Epoch 48/100\n",
      "420/420 [==============================] - 0s 411us/step - loss: 0.5355 - acc: 0.9048 - val_loss: 0.5252 - val_acc: 0.9048\n",
      "Epoch 49/100\n",
      "420/420 [==============================] - 0s 395us/step - loss: 0.5051 - acc: 0.9214 - val_loss: 0.5062 - val_acc: 0.9048\n",
      "Epoch 50/100\n",
      "420/420 [==============================] - 0s 415us/step - loss: 0.5001 - acc: 0.9357 - val_loss: 0.4875 - val_acc: 0.9143\n",
      "Epoch 51/100\n",
      "420/420 [==============================] - 0s 419us/step - loss: 0.4614 - acc: 0.9381 - val_loss: 0.4692 - val_acc: 0.9143\n",
      "Epoch 52/100\n",
      "420/420 [==============================] - 0s 397us/step - loss: 0.4577 - acc: 0.9286 - val_loss: 0.4511 - val_acc: 0.9429\n",
      "Epoch 53/100\n",
      "420/420 [==============================] - 0s 407us/step - loss: 0.4343 - acc: 0.9524 - val_loss: 0.4333 - val_acc: 0.9429\n",
      "Epoch 54/100\n",
      "420/420 [==============================] - 0s 409us/step - loss: 0.4099 - acc: 0.9429 - val_loss: 0.4158 - val_acc: 0.9429\n",
      "Epoch 55/100\n",
      "420/420 [==============================] - 0s 429us/step - loss: 0.3911 - acc: 0.9595 - val_loss: 0.3983 - val_acc: 0.9429\n",
      "Epoch 56/100\n",
      "420/420 [==============================] - 0s 405us/step - loss: 0.3780 - acc: 0.9619 - val_loss: 0.3816 - val_acc: 0.9333\n",
      "Epoch 57/100\n",
      "420/420 [==============================] - 0s 429us/step - loss: 0.3766 - acc: 0.9690 - val_loss: 0.3661 - val_acc: 0.9429\n",
      "Epoch 58/100\n",
      "420/420 [==============================] - 0s 456us/step - loss: 0.3505 - acc: 0.9619 - val_loss: 0.3512 - val_acc: 0.9429\n",
      "Epoch 59/100\n",
      "420/420 [==============================] - 0s 403us/step - loss: 0.3330 - acc: 0.9786 - val_loss: 0.3359 - val_acc: 0.9429\n",
      "Epoch 60/100\n",
      "420/420 [==============================] - 0s 397us/step - loss: 0.3184 - acc: 0.9690 - val_loss: 0.3208 - val_acc: 0.9429\n",
      "Epoch 61/100\n",
      "420/420 [==============================] - 0s 403us/step - loss: 0.3064 - acc: 0.9786 - val_loss: 0.3068 - val_acc: 0.9429\n",
      "Epoch 62/100\n",
      "420/420 [==============================] - 0s 407us/step - loss: 0.2794 - acc: 0.9810 - val_loss: 0.2937 - val_acc: 0.9524\n",
      "Epoch 63/100\n",
      "420/420 [==============================] - 0s 394us/step - loss: 0.2844 - acc: 0.9786 - val_loss: 0.2812 - val_acc: 0.9524\n",
      "Epoch 64/100\n",
      "420/420 [==============================] - 0s 410us/step - loss: 0.2624 - acc: 0.9857 - val_loss: 0.2692 - val_acc: 0.9524\n",
      "Epoch 65/100\n",
      "420/420 [==============================] - 0s 406us/step - loss: 0.2557 - acc: 0.9857 - val_loss: 0.2581 - val_acc: 0.9714\n",
      "Epoch 66/100\n",
      "420/420 [==============================] - 0s 405us/step - loss: 0.2535 - acc: 0.9786 - val_loss: 0.2475 - val_acc: 0.9714\n",
      "Epoch 67/100\n",
      "420/420 [==============================] - 0s 399us/step - loss: 0.2282 - acc: 0.9929 - val_loss: 0.2374 - val_acc: 0.9714\n",
      "Epoch 68/100\n",
      "420/420 [==============================] - 0s 406us/step - loss: 0.2163 - acc: 0.9857 - val_loss: 0.2276 - val_acc: 0.9714\n",
      "Epoch 69/100\n",
      "420/420 [==============================] - 0s 417us/step - loss: 0.2205 - acc: 0.9952 - val_loss: 0.2181 - val_acc: 0.9714\n",
      "Epoch 70/100\n",
      "420/420 [==============================] - 0s 413us/step - loss: 0.2208 - acc: 0.9857 - val_loss: 0.2091 - val_acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "420/420 [==============================] - 0s 403us/step - loss: 0.2057 - acc: 0.9881 - val_loss: 0.2008 - val_acc: 0.9714\n",
      "Epoch 72/100\n",
      "420/420 [==============================] - 0s 419us/step - loss: 0.1891 - acc: 0.9929 - val_loss: 0.1923 - val_acc: 0.9714\n",
      "Epoch 73/100\n",
      "420/420 [==============================] - 0s 418us/step - loss: 0.1759 - acc: 0.9905 - val_loss: 0.1842 - val_acc: 0.9714\n",
      "Epoch 74/100\n",
      "420/420 [==============================] - 0s 388us/step - loss: 0.1734 - acc: 0.9929 - val_loss: 0.1763 - val_acc: 0.9714\n",
      "Epoch 75/100\n",
      "420/420 [==============================] - 0s 403us/step - loss: 0.1656 - acc: 0.9929 - val_loss: 0.1687 - val_acc: 0.9714\n",
      "Epoch 76/100\n",
      "420/420 [==============================] - 0s 414us/step - loss: 0.1591 - acc: 0.9952 - val_loss: 0.1616 - val_acc: 0.9714\n",
      "Epoch 77/100\n",
      "420/420 [==============================] - 0s 396us/step - loss: 0.1520 - acc: 0.9929 - val_loss: 0.1549 - val_acc: 0.9714\n",
      "Epoch 78/100\n",
      "420/420 [==============================] - 0s 403us/step - loss: 0.1451 - acc: 0.9952 - val_loss: 0.1485 - val_acc: 0.9714\n",
      "Epoch 79/100\n",
      "420/420 [==============================] - 0s 412us/step - loss: 0.1464 - acc: 0.9929 - val_loss: 0.1427 - val_acc: 0.9810\n",
      "Epoch 80/100\n",
      "420/420 [==============================] - 0s 399us/step - loss: 0.1358 - acc: 0.9952 - val_loss: 0.1379 - val_acc: 0.9810\n",
      "Epoch 81/100\n",
      "420/420 [==============================] - 0s 393us/step - loss: 0.1386 - acc: 0.9952 - val_loss: 0.1324 - val_acc: 0.9810\n",
      "Epoch 82/100\n",
      "420/420 [==============================] - 0s 405us/step - loss: 0.1274 - acc: 0.9952 - val_loss: 0.1274 - val_acc: 0.9810\n",
      "Epoch 83/100\n",
      "420/420 [==============================] - 0s 391us/step - loss: 0.1219 - acc: 0.9929 - val_loss: 0.1224 - val_acc: 0.9810\n",
      "Epoch 84/100\n",
      "420/420 [==============================] - 0s 408us/step - loss: 0.1203 - acc: 0.9976 - val_loss: 0.1176 - val_acc: 0.9810\n",
      "Epoch 85/100\n",
      "420/420 [==============================] - 0s 417us/step - loss: 0.1050 - acc: 1.0000 - val_loss: 0.1130 - val_acc: 0.9905\n",
      "Epoch 86/100\n",
      "420/420 [==============================] - 0s 402us/step - loss: 0.1046 - acc: 0.9976 - val_loss: 0.1127 - val_acc: 0.9810\n",
      "Epoch 87/100\n",
      "420/420 [==============================] - 0s 397us/step - loss: 0.1022 - acc: 0.9952 - val_loss: 0.1131 - val_acc: 0.9810\n",
      "Epoch 88/100\n",
      "420/420 [==============================] - 0s 405us/step - loss: 0.0968 - acc: 0.9976 - val_loss: 0.1126 - val_acc: 0.9810\n",
      "Epoch 89/100\n",
      "420/420 [==============================] - 0s 412us/step - loss: 0.0912 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9810\n",
      "Epoch 90/100\n",
      "420/420 [==============================] - 0s 418us/step - loss: 0.0990 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9810\n",
      "Epoch 91/100\n",
      "420/420 [==============================] - 0s 396us/step - loss: 0.0961 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9810\n",
      "Epoch 92/100\n",
      "420/420 [==============================] - 0s 404us/step - loss: 0.0920 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 0.9810\n",
      "Epoch 93/100\n",
      "420/420 [==============================] - 0s 392us/step - loss: 0.0835 - acc: 1.0000 - val_loss: 0.1023 - val_acc: 0.9810\n",
      "Epoch 94/100\n",
      "420/420 [==============================] - 0s 407us/step - loss: 0.0839 - acc: 1.0000 - val_loss: 0.1003 - val_acc: 0.9810\n",
      "Epoch 95/100\n",
      "420/420 [==============================] - 0s 408us/step - loss: 0.0730 - acc: 1.0000 - val_loss: 0.0980 - val_acc: 0.9810\n",
      "Epoch 96/100\n",
      "420/420 [==============================] - 0s 417us/step - loss: 0.0803 - acc: 1.0000 - val_loss: 0.1002 - val_acc: 0.9810\n",
      "Epoch 97/100\n",
      "420/420 [==============================] - 0s 394us/step - loss: 0.0789 - acc: 1.0000 - val_loss: 0.1021 - val_acc: 0.9810\n",
      "Epoch 98/100\n",
      "420/420 [==============================] - 0s 399us/step - loss: 0.0694 - acc: 1.0000 - val_loss: 0.1034 - val_acc: 0.9810\n",
      "Epoch 99/100\n",
      "420/420 [==============================] - 0s 432us/step - loss: 0.0725 - acc: 1.0000 - val_loss: 0.1046 - val_acc: 0.9810\n",
      "Epoch 100/100\n",
      "420/420 [==============================] - 0s 410us/step - loss: 0.0676 - acc: 0.9976 - val_loss: 0.0944 - val_acc: 0.9810\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (437, 30, 128)\n",
      "Shape Y (437, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 349 samples, validate on 88 samples\n",
      "Epoch 1/100\n",
      "349/349 [==============================] - 4s 10ms/step - loss: 2.3100 - acc: 0.0401 - val_loss: 2.2156 - val_acc: 0.0795\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 0s 607us/step - loss: 2.2342 - acc: 0.0774 - val_loss: 2.1558 - val_acc: 0.1591\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 0s 760us/step - loss: 2.1588 - acc: 0.1576 - val_loss: 2.0983 - val_acc: 0.2386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "349/349 [==============================] - 0s 649us/step - loss: 2.1134 - acc: 0.2378 - val_loss: 2.0506 - val_acc: 0.3636\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.0485 - acc: 0.3152 - val_loss: 2.0024 - val_acc: 0.5114\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 0s 582us/step - loss: 1.9922 - acc: 0.4126 - val_loss: 1.9557 - val_acc: 0.5682\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 0s 550us/step - loss: 1.9374 - acc: 0.4871 - val_loss: 1.9102 - val_acc: 0.6250\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 0s 583us/step - loss: 1.8865 - acc: 0.5272 - val_loss: 1.8680 - val_acc: 0.6477\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 0s 576us/step - loss: 1.8660 - acc: 0.5272 - val_loss: 1.8266 - val_acc: 0.6705\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 0s 559us/step - loss: 1.8141 - acc: 0.5845 - val_loss: 1.7861 - val_acc: 0.7386\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 0s 569us/step - loss: 1.7848 - acc: 0.5759 - val_loss: 1.7470 - val_acc: 0.7386\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 0s 572us/step - loss: 1.7286 - acc: 0.6275 - val_loss: 1.7087 - val_acc: 0.7500\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 0s 652us/step - loss: 1.7120 - acc: 0.6046 - val_loss: 1.6710 - val_acc: 0.7386\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 0s 611us/step - loss: 1.6562 - acc: 0.6476 - val_loss: 1.6341 - val_acc: 0.7500\n",
      "Epoch 15/100\n",
      "349/349 [==============================] - 0s 586us/step - loss: 1.6233 - acc: 0.6791 - val_loss: 1.5976 - val_acc: 0.7614\n",
      "Epoch 16/100\n",
      "349/349 [==============================] - 0s 641us/step - loss: 1.5652 - acc: 0.6791 - val_loss: 1.5617 - val_acc: 0.7727\n",
      "Epoch 17/100\n",
      "349/349 [==============================] - 0s 632us/step - loss: 1.5299 - acc: 0.7163 - val_loss: 1.5252 - val_acc: 0.7727\n",
      "Epoch 18/100\n",
      "349/349 [==============================] - 0s 593us/step - loss: 1.4925 - acc: 0.7221 - val_loss: 1.4899 - val_acc: 0.7841\n",
      "Epoch 19/100\n",
      "349/349 [==============================] - 0s 646us/step - loss: 1.4390 - acc: 0.7163 - val_loss: 1.4557 - val_acc: 0.7841\n",
      "Epoch 20/100\n",
      "349/349 [==============================] - 0s 603us/step - loss: 1.4127 - acc: 0.7335 - val_loss: 1.4218 - val_acc: 0.7841\n",
      "Epoch 21/100\n",
      "349/349 [==============================] - 0s 595us/step - loss: 1.3582 - acc: 0.7479 - val_loss: 1.3883 - val_acc: 0.7841\n",
      "Epoch 22/100\n",
      "349/349 [==============================] - 0s 598us/step - loss: 1.3313 - acc: 0.7364 - val_loss: 1.3553 - val_acc: 0.7841\n",
      "Epoch 23/100\n",
      "349/349 [==============================] - 0s 634us/step - loss: 1.3227 - acc: 0.7507 - val_loss: 1.3226 - val_acc: 0.7841\n",
      "Epoch 24/100\n",
      "349/349 [==============================] - 0s 613us/step - loss: 1.2655 - acc: 0.7736 - val_loss: 1.2902 - val_acc: 0.7841\n",
      "Epoch 25/100\n",
      "349/349 [==============================] - 0s 617us/step - loss: 1.2193 - acc: 0.7593 - val_loss: 1.2601 - val_acc: 0.7841\n",
      "Epoch 26/100\n",
      "349/349 [==============================] - 0s 582us/step - loss: 1.2024 - acc: 0.7679 - val_loss: 1.2365 - val_acc: 0.7614\n",
      "Epoch 27/100\n",
      "349/349 [==============================] - 0s 611us/step - loss: 1.1466 - acc: 0.8138 - val_loss: 1.2038 - val_acc: 0.7727\n",
      "Epoch 28/100\n",
      "349/349 [==============================] - 0s 618us/step - loss: 1.1322 - acc: 0.7994 - val_loss: 1.1655 - val_acc: 0.7841\n",
      "Epoch 29/100\n",
      "349/349 [==============================] - 0s 603us/step - loss: 1.0879 - acc: 0.7880 - val_loss: 1.1259 - val_acc: 0.7955\n",
      "Epoch 30/100\n",
      "349/349 [==============================] - 0s 591us/step - loss: 1.0626 - acc: 0.7908 - val_loss: 1.0908 - val_acc: 0.8068\n",
      "Epoch 31/100\n",
      "349/349 [==============================] - 0s 617us/step - loss: 1.0270 - acc: 0.8195 - val_loss: 1.0563 - val_acc: 0.8182\n",
      "Epoch 32/100\n",
      "349/349 [==============================] - 0s 597us/step - loss: 1.0019 - acc: 0.8281 - val_loss: 1.0215 - val_acc: 0.8182\n",
      "Epoch 33/100\n",
      "349/349 [==============================] - 0s 605us/step - loss: 0.9656 - acc: 0.8338 - val_loss: 0.9863 - val_acc: 0.8182\n",
      "Epoch 34/100\n",
      "349/349 [==============================] - 0s 610us/step - loss: 0.9339 - acc: 0.8424 - val_loss: 0.9502 - val_acc: 0.8523\n",
      "Epoch 35/100\n",
      "349/349 [==============================] - 0s 680us/step - loss: 0.8928 - acc: 0.8768 - val_loss: 0.9136 - val_acc: 0.8750\n",
      "Epoch 36/100\n",
      "349/349 [==============================] - 0s 593us/step - loss: 0.8748 - acc: 0.8596 - val_loss: 0.8773 - val_acc: 0.8864\n",
      "Epoch 37/100\n",
      "349/349 [==============================] - 0s 624us/step - loss: 0.8234 - acc: 0.8768 - val_loss: 0.8414 - val_acc: 0.8977\n",
      "Epoch 38/100\n",
      "349/349 [==============================] - 0s 613us/step - loss: 0.7917 - acc: 0.9026 - val_loss: 0.8059 - val_acc: 0.9318\n",
      "Epoch 39/100\n",
      "349/349 [==============================] - 0s 579us/step - loss: 0.7593 - acc: 0.9026 - val_loss: 0.7712 - val_acc: 0.9318\n",
      "Epoch 40/100\n",
      "349/349 [==============================] - 0s 589us/step - loss: 0.7281 - acc: 0.9112 - val_loss: 0.7378 - val_acc: 0.9432\n",
      "Epoch 41/100\n",
      "349/349 [==============================] - 0s 579us/step - loss: 0.6995 - acc: 0.9198 - val_loss: 0.7073 - val_acc: 0.9432\n",
      "Epoch 42/100\n",
      "349/349 [==============================] - 0s 641us/step - loss: 0.6723 - acc: 0.9255 - val_loss: 0.6794 - val_acc: 0.9432\n",
      "Epoch 43/100\n",
      "349/349 [==============================] - 0s 615us/step - loss: 0.6266 - acc: 0.9370 - val_loss: 0.6595 - val_acc: 0.9432\n",
      "Epoch 44/100\n",
      "349/349 [==============================] - 0s 608us/step - loss: 0.6046 - acc: 0.9456 - val_loss: 0.6390 - val_acc: 0.9432\n",
      "Epoch 45/100\n",
      "349/349 [==============================] - 0s 603us/step - loss: 0.5868 - acc: 0.9484 - val_loss: 0.6112 - val_acc: 0.9432\n",
      "Epoch 46/100\n",
      "349/349 [==============================] - 0s 590us/step - loss: 0.5627 - acc: 0.9542 - val_loss: 0.5757 - val_acc: 0.9545\n",
      "Epoch 47/100\n",
      "349/349 [==============================] - 0s 619us/step - loss: 0.5546 - acc: 0.9599 - val_loss: 0.5477 - val_acc: 0.9545\n",
      "Epoch 48/100\n",
      "349/349 [==============================] - 0s 669us/step - loss: 0.5240 - acc: 0.9570 - val_loss: 0.5249 - val_acc: 0.9545\n",
      "Epoch 49/100\n",
      "349/349 [==============================] - 0s 567us/step - loss: 0.4928 - acc: 0.9599 - val_loss: 0.5037 - val_acc: 0.9545\n",
      "Epoch 50/100\n",
      "349/349 [==============================] - 0s 592us/step - loss: 0.4774 - acc: 0.9542 - val_loss: 0.4840 - val_acc: 0.9545\n",
      "Epoch 51/100\n",
      "349/349 [==============================] - 0s 596us/step - loss: 0.4595 - acc: 0.9513 - val_loss: 0.4654 - val_acc: 0.9545\n",
      "Epoch 52/100\n",
      "349/349 [==============================] - 0s 614us/step - loss: 0.4526 - acc: 0.9656 - val_loss: 0.4482 - val_acc: 0.9545\n",
      "Epoch 53/100\n",
      "349/349 [==============================] - 0s 614us/step - loss: 0.4133 - acc: 0.9570 - val_loss: 0.4324 - val_acc: 0.9545\n",
      "Epoch 54/100\n",
      "349/349 [==============================] - 0s 602us/step - loss: 0.4143 - acc: 0.9628 - val_loss: 0.4178 - val_acc: 0.9545\n",
      "Epoch 55/100\n",
      "349/349 [==============================] - 0s 593us/step - loss: 0.3945 - acc: 0.9685 - val_loss: 0.4048 - val_acc: 0.9545\n",
      "Epoch 56/100\n",
      "349/349 [==============================] - 0s 609us/step - loss: 0.3933 - acc: 0.9656 - val_loss: 0.3929 - val_acc: 0.9545\n",
      "Epoch 57/100\n",
      "349/349 [==============================] - 0s 594us/step - loss: 0.3626 - acc: 0.9713 - val_loss: 0.3813 - val_acc: 0.9545\n",
      "Epoch 58/100\n",
      "349/349 [==============================] - 0s 607us/step - loss: 0.3545 - acc: 0.9599 - val_loss: 0.3708 - val_acc: 0.9545\n",
      "Epoch 59/100\n",
      "349/349 [==============================] - 0s 632us/step - loss: 0.3402 - acc: 0.9656 - val_loss: 0.3616 - val_acc: 0.9545\n",
      "Epoch 60/100\n",
      "349/349 [==============================] - 0s 603us/step - loss: 0.3301 - acc: 0.9713 - val_loss: 0.3534 - val_acc: 0.9545\n",
      "Epoch 61/100\n",
      "349/349 [==============================] - 0s 616us/step - loss: 0.3207 - acc: 0.9656 - val_loss: 0.3460 - val_acc: 0.9432\n",
      "Epoch 62/100\n",
      "349/349 [==============================] - 0s 620us/step - loss: 0.3193 - acc: 0.9685 - val_loss: 0.3387 - val_acc: 0.9432\n",
      "Epoch 63/100\n",
      "349/349 [==============================] - 0s 617us/step - loss: 0.3084 - acc: 0.9656 - val_loss: 0.3310 - val_acc: 0.9432\n",
      "Epoch 64/100\n",
      "349/349 [==============================] - 0s 588us/step - loss: 0.2972 - acc: 0.9713 - val_loss: 0.3232 - val_acc: 0.9432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "349/349 [==============================] - 0s 596us/step - loss: 0.2807 - acc: 0.9713 - val_loss: 0.3152 - val_acc: 0.9432\n",
      "Epoch 66/100\n",
      "349/349 [==============================] - 0s 607us/step - loss: 0.2672 - acc: 0.9742 - val_loss: 0.3073 - val_acc: 0.9432\n",
      "Epoch 67/100\n",
      "349/349 [==============================] - 0s 625us/step - loss: 0.2692 - acc: 0.9656 - val_loss: 0.3001 - val_acc: 0.9432\n",
      "Epoch 68/100\n",
      "349/349 [==============================] - 0s 607us/step - loss: 0.2485 - acc: 0.9742 - val_loss: 0.2931 - val_acc: 0.9545\n",
      "Epoch 69/100\n",
      "349/349 [==============================] - 0s 619us/step - loss: 0.2533 - acc: 0.9713 - val_loss: 0.2857 - val_acc: 0.9545\n",
      "Epoch 70/100\n",
      "349/349 [==============================] - 0s 591us/step - loss: 0.2441 - acc: 0.9713 - val_loss: 0.2779 - val_acc: 0.9545\n",
      "Epoch 71/100\n",
      "349/349 [==============================] - 0s 606us/step - loss: 0.2305 - acc: 0.9713 - val_loss: 0.2692 - val_acc: 0.9545\n",
      "Epoch 72/100\n",
      "349/349 [==============================] - 0s 612us/step - loss: 0.2240 - acc: 0.9713 - val_loss: 0.2613 - val_acc: 0.9545\n",
      "Epoch 73/100\n",
      "349/349 [==============================] - 0s 593us/step - loss: 0.2171 - acc: 0.9799 - val_loss: 0.2538 - val_acc: 0.9545\n",
      "Epoch 74/100\n",
      "349/349 [==============================] - 0s 598us/step - loss: 0.2117 - acc: 0.9771 - val_loss: 0.2474 - val_acc: 0.9545\n",
      "Epoch 75/100\n",
      "349/349 [==============================] - 0s 587us/step - loss: 0.2162 - acc: 0.9742 - val_loss: 0.2418 - val_acc: 0.9545\n",
      "Epoch 76/100\n",
      "349/349 [==============================] - 0s 596us/step - loss: 0.2020 - acc: 0.9685 - val_loss: 0.2369 - val_acc: 0.9545\n",
      "Epoch 77/100\n",
      "349/349 [==============================] - 0s 616us/step - loss: 0.1971 - acc: 0.9742 - val_loss: 0.2327 - val_acc: 0.9545\n",
      "Epoch 78/100\n",
      "349/349 [==============================] - 0s 603us/step - loss: 0.1820 - acc: 0.9771 - val_loss: 0.2294 - val_acc: 0.9545\n",
      "Epoch 79/100\n",
      "349/349 [==============================] - 0s 596us/step - loss: 0.1891 - acc: 0.9742 - val_loss: 0.2270 - val_acc: 0.9545\n",
      "Epoch 80/100\n",
      "349/349 [==============================] - 0s 597us/step - loss: 0.1783 - acc: 0.9742 - val_loss: 0.2253 - val_acc: 0.9545\n",
      "Epoch 81/100\n",
      "349/349 [==============================] - 0s 605us/step - loss: 0.1731 - acc: 0.9771 - val_loss: 0.2231 - val_acc: 0.9545\n",
      "Epoch 82/100\n",
      "349/349 [==============================] - 0s 602us/step - loss: 0.1762 - acc: 0.9799 - val_loss: 0.2202 - val_acc: 0.9545\n",
      "Epoch 83/100\n",
      "349/349 [==============================] - 0s 580us/step - loss: 0.1691 - acc: 0.9742 - val_loss: 0.2168 - val_acc: 0.9545\n",
      "Epoch 84/100\n",
      "349/349 [==============================] - 0s 605us/step - loss: 0.1659 - acc: 0.9742 - val_loss: 0.2134 - val_acc: 0.9545\n",
      "Epoch 85/100\n",
      "349/349 [==============================] - 0s 592us/step - loss: 0.1568 - acc: 0.9771 - val_loss: 0.2102 - val_acc: 0.9545\n",
      "Epoch 86/100\n",
      "349/349 [==============================] - 0s 636us/step - loss: 0.1515 - acc: 0.9771 - val_loss: 0.2070 - val_acc: 0.9545\n",
      "Epoch 87/100\n",
      "349/349 [==============================] - 0s 587us/step - loss: 0.1494 - acc: 0.9742 - val_loss: 0.2037 - val_acc: 0.9545\n",
      "Epoch 88/100\n",
      "349/349 [==============================] - 0s 623us/step - loss: 0.1475 - acc: 0.9771 - val_loss: 0.2001 - val_acc: 0.9545\n",
      "Epoch 89/100\n",
      "349/349 [==============================] - 0s 600us/step - loss: 0.1438 - acc: 0.9799 - val_loss: 0.1967 - val_acc: 0.9545\n",
      "Epoch 90/100\n",
      "349/349 [==============================] - 0s 601us/step - loss: 0.1470 - acc: 0.9828 - val_loss: 0.1933 - val_acc: 0.9545\n",
      "Epoch 91/100\n",
      "349/349 [==============================] - 0s 606us/step - loss: 0.1412 - acc: 0.9799 - val_loss: 0.1904 - val_acc: 0.9545\n",
      "Epoch 92/100\n",
      "349/349 [==============================] - 0s 595us/step - loss: 0.1355 - acc: 0.9771 - val_loss: 0.1873 - val_acc: 0.9545\n",
      "Epoch 93/100\n",
      "349/349 [==============================] - 0s 596us/step - loss: 0.1318 - acc: 0.9771 - val_loss: 0.1844 - val_acc: 0.9545\n",
      "Epoch 94/100\n",
      "349/349 [==============================] - 0s 603us/step - loss: 0.1264 - acc: 0.9857 - val_loss: 0.1817 - val_acc: 0.9545\n",
      "Epoch 95/100\n",
      "349/349 [==============================] - 0s 598us/step - loss: 0.1262 - acc: 0.9857 - val_loss: 0.1794 - val_acc: 0.9545\n",
      "Epoch 96/100\n",
      "349/349 [==============================] - 0s 623us/step - loss: 0.1170 - acc: 0.9828 - val_loss: 0.1778 - val_acc: 0.9545\n",
      "Epoch 97/100\n",
      "349/349 [==============================] - 0s 628us/step - loss: 0.1198 - acc: 0.9799 - val_loss: 0.1763 - val_acc: 0.9545\n",
      "Epoch 98/100\n",
      "349/349 [==============================] - 0s 596us/step - loss: 0.1202 - acc: 0.9828 - val_loss: 0.1745 - val_acc: 0.9545\n",
      "Epoch 99/100\n",
      "349/349 [==============================] - 0s 634us/step - loss: 0.1185 - acc: 0.9857 - val_loss: 0.1721 - val_acc: 0.9545\n",
      "Epoch 100/100\n",
      "349/349 [==============================] - 0s 619us/step - loss: 0.1155 - acc: 0.9914 - val_loss: 0.1701 - val_acc: 0.9545\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (356, 40, 128)\n",
      "Shape Y (356, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 284 samples, validate on 72 samples\n",
      "Epoch 1/100\n",
      "284/284 [==============================] - 4s 13ms/step - loss: 2.1959 - acc: 0.1232 - val_loss: 2.1420 - val_acc: 0.1944\n",
      "Epoch 2/100\n",
      "284/284 [==============================] - 0s 777us/step - loss: 2.1289 - acc: 0.1479 - val_loss: 2.0968 - val_acc: 0.2500\n",
      "Epoch 3/100\n",
      "284/284 [==============================] - 0s 782us/step - loss: 2.0798 - acc: 0.2535 - val_loss: 2.0555 - val_acc: 0.3056\n",
      "Epoch 4/100\n",
      "284/284 [==============================] - 0s 779us/step - loss: 2.0191 - acc: 0.3169 - val_loss: 2.0160 - val_acc: 0.3889\n",
      "Epoch 5/100\n",
      "284/284 [==============================] - 0s 811us/step - loss: 1.9599 - acc: 0.4190 - val_loss: 1.9766 - val_acc: 0.4583\n",
      "Epoch 6/100\n",
      "284/284 [==============================] - 0s 767us/step - loss: 1.9391 - acc: 0.4366 - val_loss: 1.9394 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "284/284 [==============================] - 0s 797us/step - loss: 1.8990 - acc: 0.4930 - val_loss: 1.9033 - val_acc: 0.5833\n",
      "Epoch 8/100\n",
      "284/284 [==============================] - 0s 790us/step - loss: 1.8358 - acc: 0.5528 - val_loss: 1.8674 - val_acc: 0.6667\n",
      "Epoch 9/100\n",
      "284/284 [==============================] - 0s 789us/step - loss: 1.7877 - acc: 0.6021 - val_loss: 1.8311 - val_acc: 0.6667\n",
      "Epoch 10/100\n",
      "284/284 [==============================] - 0s 791us/step - loss: 1.7551 - acc: 0.5915 - val_loss: 1.7945 - val_acc: 0.7083\n",
      "Epoch 11/100\n",
      "284/284 [==============================] - 0s 781us/step - loss: 1.7208 - acc: 0.6620 - val_loss: 1.7576 - val_acc: 0.7500\n",
      "Epoch 12/100\n",
      "284/284 [==============================] - 0s 811us/step - loss: 1.6876 - acc: 0.6866 - val_loss: 1.7206 - val_acc: 0.7917\n",
      "Epoch 13/100\n",
      "284/284 [==============================] - 0s 799us/step - loss: 1.6330 - acc: 0.7148 - val_loss: 1.6834 - val_acc: 0.8056\n",
      "Epoch 14/100\n",
      "284/284 [==============================] - 0s 785us/step - loss: 1.5967 - acc: 0.7465 - val_loss: 1.6464 - val_acc: 0.7917\n",
      "Epoch 15/100\n",
      "284/284 [==============================] - 0s 787us/step - loss: 1.5711 - acc: 0.7606 - val_loss: 1.6094 - val_acc: 0.8056\n",
      "Epoch 16/100\n",
      "284/284 [==============================] - 0s 787us/step - loss: 1.5268 - acc: 0.7606 - val_loss: 1.5705 - val_acc: 0.8056\n",
      "Epoch 17/100\n",
      "284/284 [==============================] - 0s 858us/step - loss: 1.4769 - acc: 0.7817 - val_loss: 1.5284 - val_acc: 0.8333\n",
      "Epoch 18/100\n",
      "284/284 [==============================] - 0s 824us/step - loss: 1.4602 - acc: 0.7606 - val_loss: 1.4864 - val_acc: 0.8333\n",
      "Epoch 19/100\n",
      "284/284 [==============================] - 0s 819us/step - loss: 1.3923 - acc: 0.8099 - val_loss: 1.4452 - val_acc: 0.8333\n",
      "Epoch 20/100\n",
      "284/284 [==============================] - 0s 847us/step - loss: 1.3857 - acc: 0.7958 - val_loss: 1.4033 - val_acc: 0.8472\n",
      "Epoch 21/100\n",
      "284/284 [==============================] - 0s 826us/step - loss: 1.2914 - acc: 0.8451 - val_loss: 1.3608 - val_acc: 0.8750\n",
      "Epoch 22/100\n",
      "284/284 [==============================] - 0s 826us/step - loss: 1.2807 - acc: 0.8345 - val_loss: 1.3187 - val_acc: 0.8750\n",
      "Epoch 23/100\n",
      "284/284 [==============================] - 0s 834us/step - loss: 1.2470 - acc: 0.8521 - val_loss: 1.2778 - val_acc: 0.8750\n",
      "Epoch 24/100\n",
      "284/284 [==============================] - 0s 814us/step - loss: 1.2028 - acc: 0.8697 - val_loss: 1.2368 - val_acc: 0.8611\n",
      "Epoch 25/100\n",
      "284/284 [==============================] - 0s 829us/step - loss: 1.1709 - acc: 0.8556 - val_loss: 1.1965 - val_acc: 0.8611\n",
      "Epoch 26/100\n",
      "284/284 [==============================] - 0s 849us/step - loss: 1.1390 - acc: 0.8732 - val_loss: 1.1568 - val_acc: 0.8611\n",
      "Epoch 27/100\n",
      "284/284 [==============================] - 0s 833us/step - loss: 1.1029 - acc: 0.8732 - val_loss: 1.1181 - val_acc: 0.8611\n",
      "Epoch 28/100\n",
      "284/284 [==============================] - 0s 816us/step - loss: 1.0552 - acc: 0.8732 - val_loss: 1.0796 - val_acc: 0.8750\n",
      "Epoch 29/100\n",
      "284/284 [==============================] - 0s 851us/step - loss: 1.0225 - acc: 0.8803 - val_loss: 1.0390 - val_acc: 0.8889\n",
      "Epoch 30/100\n",
      "284/284 [==============================] - 0s 828us/step - loss: 1.0069 - acc: 0.9014 - val_loss: 0.9977 - val_acc: 0.9028\n",
      "Epoch 31/100\n",
      "284/284 [==============================] - 0s 822us/step - loss: 0.9586 - acc: 0.9049 - val_loss: 0.9574 - val_acc: 0.9028\n",
      "Epoch 32/100\n",
      "284/284 [==============================] - 0s 812us/step - loss: 0.9189 - acc: 0.8873 - val_loss: 0.9196 - val_acc: 0.9167\n",
      "Epoch 33/100\n",
      "284/284 [==============================] - 0s 822us/step - loss: 0.8868 - acc: 0.8944 - val_loss: 0.8838 - val_acc: 0.9167\n",
      "Epoch 34/100\n",
      "284/284 [==============================] - 0s 820us/step - loss: 0.8657 - acc: 0.8944 - val_loss: 0.8492 - val_acc: 0.9306\n",
      "Epoch 35/100\n",
      "284/284 [==============================] - 0s 821us/step - loss: 0.8200 - acc: 0.9085 - val_loss: 0.8154 - val_acc: 0.9306\n",
      "Epoch 36/100\n",
      "284/284 [==============================] - 0s 825us/step - loss: 0.7940 - acc: 0.9120 - val_loss: 0.7824 - val_acc: 0.9444\n",
      "Epoch 37/100\n",
      "284/284 [==============================] - 0s 813us/step - loss: 0.7635 - acc: 0.9155 - val_loss: 0.7490 - val_acc: 0.9444\n",
      "Epoch 38/100\n",
      "284/284 [==============================] - 0s 828us/step - loss: 0.7743 - acc: 0.9014 - val_loss: 0.7177 - val_acc: 0.9583\n",
      "Epoch 39/100\n",
      "284/284 [==============================] - 0s 825us/step - loss: 0.7110 - acc: 0.9155 - val_loss: 0.6875 - val_acc: 0.9583\n",
      "Epoch 40/100\n",
      "284/284 [==============================] - 0s 811us/step - loss: 0.6899 - acc: 0.9155 - val_loss: 0.6582 - val_acc: 0.9583\n",
      "Epoch 41/100\n",
      "284/284 [==============================] - 0s 871us/step - loss: 0.6479 - acc: 0.9155 - val_loss: 0.6297 - val_acc: 0.9583\n",
      "Epoch 42/100\n",
      "284/284 [==============================] - 0s 846us/step - loss: 0.6208 - acc: 0.9155 - val_loss: 0.6020 - val_acc: 0.9583\n",
      "Epoch 43/100\n",
      "284/284 [==============================] - 0s 824us/step - loss: 0.6141 - acc: 0.9296 - val_loss: 0.5753 - val_acc: 0.9583\n",
      "Epoch 44/100\n",
      "284/284 [==============================] - 0s 841us/step - loss: 0.5885 - acc: 0.9366 - val_loss: 0.5504 - val_acc: 0.9583\n",
      "Epoch 45/100\n",
      "284/284 [==============================] - 0s 834us/step - loss: 0.5833 - acc: 0.9331 - val_loss: 0.5275 - val_acc: 0.9583\n",
      "Epoch 46/100\n",
      "284/284 [==============================] - 0s 825us/step - loss: 0.5485 - acc: 0.9296 - val_loss: 0.5058 - val_acc: 0.9583\n",
      "Epoch 47/100\n",
      "284/284 [==============================] - 0s 854us/step - loss: 0.5303 - acc: 0.9366 - val_loss: 0.4848 - val_acc: 0.9583\n",
      "Epoch 48/100\n",
      "284/284 [==============================] - 0s 824us/step - loss: 0.5083 - acc: 0.9401 - val_loss: 0.4650 - val_acc: 0.9583\n",
      "Epoch 49/100\n",
      "284/284 [==============================] - 0s 847us/step - loss: 0.4912 - acc: 0.9366 - val_loss: 0.4463 - val_acc: 0.9583\n",
      "Epoch 50/100\n",
      "284/284 [==============================] - 0s 844us/step - loss: 0.4839 - acc: 0.9366 - val_loss: 0.4281 - val_acc: 0.9583\n",
      "Epoch 51/100\n",
      "284/284 [==============================] - 0s 824us/step - loss: 0.4484 - acc: 0.9437 - val_loss: 0.4108 - val_acc: 0.9583\n",
      "Epoch 52/100\n",
      "284/284 [==============================] - 0s 842us/step - loss: 0.4395 - acc: 0.9331 - val_loss: 0.3942 - val_acc: 0.9583\n",
      "Epoch 53/100\n",
      "284/284 [==============================] - 0s 842us/step - loss: 0.4231 - acc: 0.9401 - val_loss: 0.3772 - val_acc: 0.9583\n",
      "Epoch 54/100\n",
      "284/284 [==============================] - 0s 848us/step - loss: 0.3994 - acc: 0.9472 - val_loss: 0.3594 - val_acc: 0.9583\n",
      "Epoch 55/100\n",
      "284/284 [==============================] - 0s 810us/step - loss: 0.4101 - acc: 0.9542 - val_loss: 0.3432 - val_acc: 0.9583\n",
      "Epoch 56/100\n",
      "284/284 [==============================] - 0s 814us/step - loss: 0.3839 - acc: 0.9507 - val_loss: 0.3289 - val_acc: 0.9583\n",
      "Epoch 57/100\n",
      "284/284 [==============================] - 0s 836us/step - loss: 0.3711 - acc: 0.9577 - val_loss: 0.3158 - val_acc: 0.9722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "284/284 [==============================] - 0s 851us/step - loss: 0.3734 - acc: 0.9507 - val_loss: 0.3034 - val_acc: 0.9722\n",
      "Epoch 59/100\n",
      "284/284 [==============================] - 0s 843us/step - loss: 0.3519 - acc: 0.9577 - val_loss: 0.2916 - val_acc: 0.9722\n",
      "Epoch 60/100\n",
      "284/284 [==============================] - 0s 805us/step - loss: 0.3472 - acc: 0.9472 - val_loss: 0.2804 - val_acc: 0.9722\n",
      "Epoch 61/100\n",
      "284/284 [==============================] - 0s 805us/step - loss: 0.3174 - acc: 0.9683 - val_loss: 0.2698 - val_acc: 0.9722\n",
      "Epoch 62/100\n",
      "284/284 [==============================] - 0s 853us/step - loss: 0.3177 - acc: 0.9577 - val_loss: 0.2597 - val_acc: 0.9722\n",
      "Epoch 63/100\n",
      "284/284 [==============================] - 0s 842us/step - loss: 0.3081 - acc: 0.9613 - val_loss: 0.2500 - val_acc: 0.9861\n",
      "Epoch 64/100\n",
      "284/284 [==============================] - 0s 799us/step - loss: 0.3062 - acc: 0.9648 - val_loss: 0.2407 - val_acc: 0.9861\n",
      "Epoch 65/100\n",
      "284/284 [==============================] - 0s 802us/step - loss: 0.2884 - acc: 0.9718 - val_loss: 0.2320 - val_acc: 0.9861\n",
      "Epoch 66/100\n",
      "284/284 [==============================] - 0s 840us/step - loss: 0.2935 - acc: 0.9683 - val_loss: 0.2238 - val_acc: 0.9861\n",
      "Epoch 67/100\n",
      "284/284 [==============================] - 0s 820us/step - loss: 0.2853 - acc: 0.9683 - val_loss: 0.2160 - val_acc: 0.9861\n",
      "Epoch 68/100\n",
      "284/284 [==============================] - 0s 807us/step - loss: 0.2636 - acc: 0.9718 - val_loss: 0.2085 - val_acc: 0.9861\n",
      "Epoch 69/100\n",
      "284/284 [==============================] - 0s 819us/step - loss: 0.2464 - acc: 0.9754 - val_loss: 0.2014 - val_acc: 0.9861\n",
      "Epoch 70/100\n",
      "284/284 [==============================] - 0s 801us/step - loss: 0.2545 - acc: 0.9824 - val_loss: 0.1946 - val_acc: 0.9861\n",
      "Epoch 71/100\n",
      "284/284 [==============================] - 0s 830us/step - loss: 0.2387 - acc: 0.9789 - val_loss: 0.1880 - val_acc: 0.9861\n",
      "Epoch 72/100\n",
      "284/284 [==============================] - 0s 842us/step - loss: 0.2324 - acc: 0.9859 - val_loss: 0.1817 - val_acc: 0.9861\n",
      "Epoch 73/100\n",
      "284/284 [==============================] - 0s 817us/step - loss: 0.2222 - acc: 0.9894 - val_loss: 0.1757 - val_acc: 0.9861\n",
      "Epoch 74/100\n",
      "284/284 [==============================] - 0s 808us/step - loss: 0.2195 - acc: 0.9859 - val_loss: 0.1696 - val_acc: 0.9861\n",
      "Epoch 75/100\n",
      "284/284 [==============================] - 0s 865us/step - loss: 0.2180 - acc: 0.9930 - val_loss: 0.1635 - val_acc: 0.9861\n",
      "Epoch 76/100\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.2194 - acc: 0.9894 - val_loss: 0.1580 - val_acc: 0.9861\n",
      "Epoch 77/100\n",
      "284/284 [==============================] - 0s 858us/step - loss: 0.2086 - acc: 0.9965 - val_loss: 0.1526 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "284/284 [==============================] - 0s 853us/step - loss: 0.2104 - acc: 0.9930 - val_loss: 0.1480 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "284/284 [==============================] - 0s 837us/step - loss: 0.1983 - acc: 0.9894 - val_loss: 0.1438 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "284/284 [==============================] - 0s 818us/step - loss: 0.1965 - acc: 0.9894 - val_loss: 0.1397 - val_acc: 0.9861\n",
      "Epoch 81/100\n",
      "284/284 [==============================] - 0s 831us/step - loss: 0.1979 - acc: 0.9824 - val_loss: 0.1361 - val_acc: 0.9861\n",
      "Epoch 82/100\n",
      "284/284 [==============================] - 0s 809us/step - loss: 0.1930 - acc: 0.9965 - val_loss: 0.1323 - val_acc: 0.9861\n",
      "Epoch 83/100\n",
      "284/284 [==============================] - 0s 819us/step - loss: 0.1825 - acc: 0.9930 - val_loss: 0.1287 - val_acc: 0.9861\n",
      "Epoch 84/100\n",
      "284/284 [==============================] - 0s 875us/step - loss: 0.1689 - acc: 0.9930 - val_loss: 0.1251 - val_acc: 0.9861\n",
      "Epoch 85/100\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.1776 - acc: 1.0000 - val_loss: 0.1215 - val_acc: 0.9861\n",
      "Epoch 86/100\n",
      "284/284 [==============================] - 0s 848us/step - loss: 0.1628 - acc: 0.9894 - val_loss: 0.1180 - val_acc: 0.9861\n",
      "Epoch 87/100\n",
      "284/284 [==============================] - 0s 802us/step - loss: 0.1678 - acc: 0.9965 - val_loss: 0.1146 - val_acc: 0.9861\n",
      "Epoch 88/100\n",
      "284/284 [==============================] - 0s 850us/step - loss: 0.1715 - acc: 1.0000 - val_loss: 0.1112 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "284/284 [==============================] - 0s 834us/step - loss: 0.1448 - acc: 0.9965 - val_loss: 0.1080 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "284/284 [==============================] - 0s 854us/step - loss: 0.1467 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "284/284 [==============================] - 0s 868us/step - loss: 0.1415 - acc: 1.0000 - val_loss: 0.1022 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "284/284 [==============================] - 0s 819us/step - loss: 0.1412 - acc: 1.0000 - val_loss: 0.0995 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "284/284 [==============================] - 0s 845us/step - loss: 0.1407 - acc: 0.9965 - val_loss: 0.0968 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "284/284 [==============================] - 0s 793us/step - loss: 0.1436 - acc: 1.0000 - val_loss: 0.0940 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "284/284 [==============================] - 0s 825us/step - loss: 0.1348 - acc: 1.0000 - val_loss: 0.0914 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "284/284 [==============================] - 0s 858us/step - loss: 0.1376 - acc: 0.9965 - val_loss: 0.0889 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "284/284 [==============================] - 0s 777us/step - loss: 0.1238 - acc: 1.0000 - val_loss: 0.0864 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "284/284 [==============================] - 0s 819us/step - loss: 0.1187 - acc: 1.0000 - val_loss: 0.0838 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "284/284 [==============================] - 0s 853us/step - loss: 0.1201 - acc: 1.0000 - val_loss: 0.0812 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "284/284 [==============================] - 0s 814us/step - loss: 0.1109 - acc: 0.9965 - val_loss: 0.0785 - val_acc: 1.0000\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (279, 50, 128)\n",
      "Shape Y (279, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 223 samples, validate on 56 samples\n",
      "Epoch 1/100\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 2.2508 - acc: 0.0852 - val_loss: 2.1664 - val_acc: 0.1250\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 2.1983 - acc: 0.0673 - val_loss: 2.1235 - val_acc: 0.1250\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 2.1434 - acc: 0.1525 - val_loss: 2.0823 - val_acc: 0.1607\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 2.1064 - acc: 0.1839 - val_loss: 2.0376 - val_acc: 0.1786\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 2.0773 - acc: 0.1973 - val_loss: 1.9906 - val_acc: 0.3929\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 2.0238 - acc: 0.2646 - val_loss: 1.9499 - val_acc: 0.5536\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.9837 - acc: 0.3722 - val_loss: 1.9105 - val_acc: 0.6429\n",
      "Epoch 8/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.9578 - acc: 0.4036 - val_loss: 1.8719 - val_acc: 0.7679\n",
      "Epoch 9/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.8906 - acc: 0.5247 - val_loss: 1.8333 - val_acc: 0.8036\n",
      "Epoch 10/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.8670 - acc: 0.5516 - val_loss: 1.7941 - val_acc: 0.8393\n",
      "Epoch 11/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.8300 - acc: 0.6278 - val_loss: 1.7540 - val_acc: 0.8393\n",
      "Epoch 12/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.7899 - acc: 0.6368 - val_loss: 1.7128 - val_acc: 0.8393\n",
      "Epoch 13/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.7661 - acc: 0.6278 - val_loss: 1.6713 - val_acc: 0.8393\n",
      "Epoch 14/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.6999 - acc: 0.7265 - val_loss: 1.6292 - val_acc: 0.8393\n",
      "Epoch 15/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.6709 - acc: 0.7130 - val_loss: 1.5862 - val_acc: 0.8393\n",
      "Epoch 16/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.6310 - acc: 0.7399 - val_loss: 1.5424 - val_acc: 0.8393\n",
      "Epoch 17/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.5927 - acc: 0.7130 - val_loss: 1.4985 - val_acc: 0.8393\n",
      "Epoch 18/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.5767 - acc: 0.7220 - val_loss: 1.4549 - val_acc: 0.8393\n",
      "Epoch 19/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.5116 - acc: 0.7534 - val_loss: 1.4117 - val_acc: 0.8393\n",
      "Epoch 20/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.4767 - acc: 0.7668 - val_loss: 1.3687 - val_acc: 0.8393\n",
      "Epoch 21/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.4327 - acc: 0.7803 - val_loss: 1.3263 - val_acc: 0.8393\n",
      "Epoch 22/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.3910 - acc: 0.7937 - val_loss: 1.2846 - val_acc: 0.8393\n",
      "Epoch 23/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.3743 - acc: 0.7803 - val_loss: 1.2438 - val_acc: 0.8393\n",
      "Epoch 24/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.3064 - acc: 0.8027 - val_loss: 1.2041 - val_acc: 0.8393\n",
      "Epoch 25/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.3198 - acc: 0.7578 - val_loss: 1.1653 - val_acc: 0.8393\n",
      "Epoch 26/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.2713 - acc: 0.7892 - val_loss: 1.1275 - val_acc: 0.8393\n",
      "Epoch 27/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.2233 - acc: 0.7803 - val_loss: 1.0906 - val_acc: 0.8393\n",
      "Epoch 28/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.2028 - acc: 0.7758 - val_loss: 1.0547 - val_acc: 0.8393\n",
      "Epoch 29/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.1775 - acc: 0.7758 - val_loss: 1.0204 - val_acc: 0.8571\n",
      "Epoch 30/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.1334 - acc: 0.7892 - val_loss: 0.9873 - val_acc: 0.8571\n",
      "Epoch 31/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.1030 - acc: 0.7982 - val_loss: 0.9549 - val_acc: 0.8571\n",
      "Epoch 32/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.0684 - acc: 0.8072 - val_loss: 0.9226 - val_acc: 0.8571\n",
      "Epoch 33/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 1.0478 - acc: 0.8161 - val_loss: 0.8907 - val_acc: 0.8571\n",
      "Epoch 34/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.9932 - acc: 0.8296 - val_loss: 0.8592 - val_acc: 0.8929\n",
      "Epoch 35/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.9846 - acc: 0.8610 - val_loss: 0.8286 - val_acc: 0.8929\n",
      "Epoch 36/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.9610 - acc: 0.8341 - val_loss: 0.7988 - val_acc: 0.8929\n",
      "Epoch 37/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.9179 - acc: 0.8700 - val_loss: 0.7698 - val_acc: 0.8929\n",
      "Epoch 38/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.8805 - acc: 0.8610 - val_loss: 0.7417 - val_acc: 0.9107\n",
      "Epoch 39/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.8494 - acc: 0.8700 - val_loss: 0.7152 - val_acc: 0.9286\n",
      "Epoch 40/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.8248 - acc: 0.8789 - val_loss: 0.6903 - val_acc: 0.9286\n",
      "Epoch 41/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.7979 - acc: 0.8744 - val_loss: 0.6665 - val_acc: 0.9286\n",
      "Epoch 42/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.7701 - acc: 0.8879 - val_loss: 0.6437 - val_acc: 0.9286\n",
      "Epoch 43/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.7458 - acc: 0.8879 - val_loss: 0.6220 - val_acc: 0.9286\n",
      "Epoch 44/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.7318 - acc: 0.9013 - val_loss: 0.6015 - val_acc: 0.9286\n",
      "Epoch 45/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.6954 - acc: 0.8879 - val_loss: 0.5809 - val_acc: 0.9286\n",
      "Epoch 46/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.6575 - acc: 0.9148 - val_loss: 0.5581 - val_acc: 0.9286\n",
      "Epoch 47/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.6695 - acc: 0.9193 - val_loss: 0.5347 - val_acc: 0.9286\n",
      "Epoch 48/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.6241 - acc: 0.9058 - val_loss: 0.5129 - val_acc: 0.9286\n",
      "Epoch 49/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.6308 - acc: 0.9148 - val_loss: 0.4929 - val_acc: 0.9286\n",
      "Epoch 50/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.6143 - acc: 0.9058 - val_loss: 0.4742 - val_acc: 0.9286\n",
      "Epoch 51/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.5805 - acc: 0.9148 - val_loss: 0.4565 - val_acc: 0.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.5512 - acc: 0.9283 - val_loss: 0.4394 - val_acc: 0.9286\n",
      "Epoch 53/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.5339 - acc: 0.9417 - val_loss: 0.4227 - val_acc: 0.9286\n",
      "Epoch 54/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.5413 - acc: 0.9327 - val_loss: 0.4064 - val_acc: 0.9286\n",
      "Epoch 55/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.5072 - acc: 0.9552 - val_loss: 0.3911 - val_acc: 0.9464\n",
      "Epoch 56/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.4832 - acc: 0.9507 - val_loss: 0.3793 - val_acc: 0.9821\n",
      "Epoch 57/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.4590 - acc: 0.9507 - val_loss: 0.3651 - val_acc: 0.9821\n",
      "Epoch 58/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.4589 - acc: 0.9641 - val_loss: 0.3515 - val_acc: 0.9821\n",
      "Epoch 59/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.4267 - acc: 0.9596 - val_loss: 0.3382 - val_acc: 0.9821\n",
      "Epoch 60/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.4245 - acc: 0.9686 - val_loss: 0.3254 - val_acc: 0.9821\n",
      "Epoch 61/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.4013 - acc: 0.9686 - val_loss: 0.3130 - val_acc: 0.9821\n",
      "Epoch 62/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.4086 - acc: 0.9686 - val_loss: 0.3010 - val_acc: 0.9821\n",
      "Epoch 63/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.3717 - acc: 0.9821 - val_loss: 0.2897 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.3505 - acc: 0.9731 - val_loss: 0.2791 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.3515 - acc: 0.9821 - val_loss: 0.2691 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.3413 - acc: 0.9731 - val_loss: 0.2598 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.3248 - acc: 0.9641 - val_loss: 0.2509 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.3200 - acc: 0.9686 - val_loss: 0.2426 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.3244 - acc: 0.9776 - val_loss: 0.2347 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.3161 - acc: 0.9776 - val_loss: 0.2271 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2890 - acc: 0.9776 - val_loss: 0.2199 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2829 - acc: 0.9776 - val_loss: 0.2130 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2689 - acc: 0.9821 - val_loss: 0.2065 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2918 - acc: 0.9865 - val_loss: 0.2003 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2602 - acc: 0.9821 - val_loss: 0.1943 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2596 - acc: 0.9731 - val_loss: 0.1886 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2358 - acc: 0.9955 - val_loss: 0.1836 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2358 - acc: 0.9955 - val_loss: 0.1787 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2274 - acc: 0.9910 - val_loss: 0.1740 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2437 - acc: 0.9865 - val_loss: 0.1694 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2242 - acc: 0.9865 - val_loss: 0.1650 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2205 - acc: 0.9865 - val_loss: 0.1606 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2187 - acc: 0.9955 - val_loss: 0.1563 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2173 - acc: 0.9955 - val_loss: 0.1520 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2136 - acc: 0.9821 - val_loss: 0.1478 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2023 - acc: 0.9955 - val_loss: 0.1436 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.2036 - acc: 0.9910 - val_loss: 0.1396 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1831 - acc: 0.9955 - val_loss: 0.1358 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1833 - acc: 0.9910 - val_loss: 0.1320 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1765 - acc: 0.9955 - val_loss: 0.1285 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1713 - acc: 1.0000 - val_loss: 0.1254 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1764 - acc: 0.9910 - val_loss: 0.1225 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1649 - acc: 0.9955 - val_loss: 0.1194 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1819 - acc: 0.9910 - val_loss: 0.1166 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1640 - acc: 0.9910 - val_loss: 0.1138 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1783 - acc: 0.9865 - val_loss: 0.1110 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1623 - acc: 0.9865 - val_loss: 0.1084 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1499 - acc: 0.9910 - val_loss: 0.1057 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1527 - acc: 0.9910 - val_loss: 0.1032 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "223/223 [==============================] - 0s 1ms/step - loss: 0.1419 - acc: 0.9865 - val_loss: 0.1009 - val_acc: 1.0000\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (482, 20, 128)\n",
      "Shape Y (482, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 385 samples, validate on 97 samples\n",
      "Epoch 1/100\n",
      "385/385 [==============================] - 4s 10ms/step - loss: 2.1450 - acc: 0.1584 - val_loss: 2.1074 - val_acc: 0.1753\n",
      "Epoch 2/100\n",
      "385/385 [==============================] - 0s 377us/step - loss: 2.0981 - acc: 0.2312 - val_loss: 2.0537 - val_acc: 0.3196\n",
      "Epoch 3/100\n",
      "385/385 [==============================] - 0s 430us/step - loss: 2.0322 - acc: 0.3013 - val_loss: 2.0031 - val_acc: 0.4433\n",
      "Epoch 4/100\n",
      "385/385 [==============================] - 0s 391us/step - loss: 1.9927 - acc: 0.3403 - val_loss: 1.9600 - val_acc: 0.4742\n",
      "Epoch 5/100\n",
      "385/385 [==============================] - 0s 397us/step - loss: 1.9366 - acc: 0.3948 - val_loss: 1.9173 - val_acc: 0.4948\n",
      "Epoch 6/100\n",
      "385/385 [==============================] - 0s 385us/step - loss: 1.8983 - acc: 0.4442 - val_loss: 1.8775 - val_acc: 0.4948\n",
      "Epoch 7/100\n",
      "385/385 [==============================] - 0s 403us/step - loss: 1.8518 - acc: 0.4909 - val_loss: 1.8388 - val_acc: 0.5155\n",
      "Epoch 8/100\n",
      "385/385 [==============================] - 0s 394us/step - loss: 1.8419 - acc: 0.4935 - val_loss: 1.8004 - val_acc: 0.5155\n",
      "Epoch 9/100\n",
      "385/385 [==============================] - 0s 404us/step - loss: 1.7788 - acc: 0.5169 - val_loss: 1.7630 - val_acc: 0.5361\n",
      "Epoch 10/100\n",
      "385/385 [==============================] - 0s 389us/step - loss: 1.7243 - acc: 0.5688 - val_loss: 1.7272 - val_acc: 0.5567\n",
      "Epoch 11/100\n",
      "385/385 [==============================] - 0s 395us/step - loss: 1.6944 - acc: 0.5688 - val_loss: 1.6928 - val_acc: 0.5979\n",
      "Epoch 12/100\n",
      "385/385 [==============================] - 0s 398us/step - loss: 1.6683 - acc: 0.6104 - val_loss: 1.6590 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "385/385 [==============================] - 0s 396us/step - loss: 1.6226 - acc: 0.6468 - val_loss: 1.6251 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "385/385 [==============================] - 0s 381us/step - loss: 1.5889 - acc: 0.6390 - val_loss: 1.5909 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "385/385 [==============================] - 0s 407us/step - loss: 1.5875 - acc: 0.6494 - val_loss: 1.5565 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "385/385 [==============================] - 0s 389us/step - loss: 1.5222 - acc: 0.6805 - val_loss: 1.5223 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "385/385 [==============================] - 0s 415us/step - loss: 1.4766 - acc: 0.6805 - val_loss: 1.4882 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "385/385 [==============================] - 0s 394us/step - loss: 1.4452 - acc: 0.6857 - val_loss: 1.4542 - val_acc: 0.6392\n",
      "Epoch 19/100\n",
      "385/385 [==============================] - 0s 401us/step - loss: 1.4146 - acc: 0.7091 - val_loss: 1.4200 - val_acc: 0.6392\n",
      "Epoch 20/100\n",
      "385/385 [==============================] - 0s 394us/step - loss: 1.3726 - acc: 0.7221 - val_loss: 1.3858 - val_acc: 0.6701\n",
      "Epoch 21/100\n",
      "385/385 [==============================] - 0s 395us/step - loss: 1.3402 - acc: 0.7558 - val_loss: 1.3512 - val_acc: 0.6701\n",
      "Epoch 22/100\n",
      "385/385 [==============================] - 0s 411us/step - loss: 1.3231 - acc: 0.7117 - val_loss: 1.3163 - val_acc: 0.7010\n",
      "Epoch 23/100\n",
      "385/385 [==============================] - 0s 414us/step - loss: 1.2739 - acc: 0.7610 - val_loss: 1.2814 - val_acc: 0.7113\n",
      "Epoch 24/100\n",
      "385/385 [==============================] - 0s 414us/step - loss: 1.2588 - acc: 0.7403 - val_loss: 1.2472 - val_acc: 0.7423\n",
      "Epoch 25/100\n",
      "385/385 [==============================] - 0s 409us/step - loss: 1.2162 - acc: 0.7610 - val_loss: 1.2135 - val_acc: 0.7629\n",
      "Epoch 26/100\n",
      "385/385 [==============================] - 0s 390us/step - loss: 1.1757 - acc: 0.7948 - val_loss: 1.1805 - val_acc: 0.7629\n",
      "Epoch 27/100\n",
      "385/385 [==============================] - 0s 376us/step - loss: 1.1433 - acc: 0.7870 - val_loss: 1.1480 - val_acc: 0.7732\n",
      "Epoch 28/100\n",
      "385/385 [==============================] - 0s 401us/step - loss: 1.1079 - acc: 0.8078 - val_loss: 1.1154 - val_acc: 0.7732\n",
      "Epoch 29/100\n",
      "385/385 [==============================] - 0s 382us/step - loss: 1.0903 - acc: 0.8338 - val_loss: 1.0829 - val_acc: 0.7938\n",
      "Epoch 30/100\n",
      "385/385 [==============================] - 0s 392us/step - loss: 1.0650 - acc: 0.8182 - val_loss: 1.0507 - val_acc: 0.7938\n",
      "Epoch 31/100\n",
      "385/385 [==============================] - 0s 385us/step - loss: 1.0144 - acc: 0.8312 - val_loss: 1.0184 - val_acc: 0.8041\n",
      "Epoch 32/100\n",
      "385/385 [==============================] - 0s 403us/step - loss: 0.9925 - acc: 0.8494 - val_loss: 0.9874 - val_acc: 0.8041\n",
      "Epoch 33/100\n",
      "385/385 [==============================] - 0s 389us/step - loss: 0.9647 - acc: 0.8416 - val_loss: 0.9579 - val_acc: 0.8144\n",
      "Epoch 34/100\n",
      "385/385 [==============================] - 0s 407us/step - loss: 0.9316 - acc: 0.8571 - val_loss: 0.9297 - val_acc: 0.8454\n",
      "Epoch 35/100\n",
      "385/385 [==============================] - 0s 386us/step - loss: 0.8968 - acc: 0.8649 - val_loss: 0.9024 - val_acc: 0.8557\n",
      "Epoch 36/100\n",
      "385/385 [==============================] - 0s 508us/step - loss: 0.8750 - acc: 0.8675 - val_loss: 0.8766 - val_acc: 0.8660\n",
      "Epoch 37/100\n",
      "385/385 [==============================] - 0s 508us/step - loss: 0.8460 - acc: 0.8727 - val_loss: 0.8519 - val_acc: 0.8763\n",
      "Epoch 38/100\n",
      "385/385 [==============================] - 0s 440us/step - loss: 0.8083 - acc: 0.8961 - val_loss: 0.8267 - val_acc: 0.8866\n",
      "Epoch 39/100\n",
      "385/385 [==============================] - 0s 410us/step - loss: 0.7979 - acc: 0.8805 - val_loss: 0.8015 - val_acc: 0.8763\n",
      "Epoch 40/100\n",
      "385/385 [==============================] - 0s 396us/step - loss: 0.7699 - acc: 0.9013 - val_loss: 0.7748 - val_acc: 0.8969\n",
      "Epoch 41/100\n",
      "385/385 [==============================] - 0s 405us/step - loss: 0.7434 - acc: 0.9169 - val_loss: 0.7466 - val_acc: 0.9175\n",
      "Epoch 42/100\n",
      "385/385 [==============================] - 0s 410us/step - loss: 0.7172 - acc: 0.9117 - val_loss: 0.7183 - val_acc: 0.9175\n",
      "Epoch 43/100\n",
      "385/385 [==============================] - 0s 396us/step - loss: 0.6828 - acc: 0.9013 - val_loss: 0.6920 - val_acc: 0.9175\n",
      "Epoch 44/100\n",
      "385/385 [==============================] - 0s 394us/step - loss: 0.6761 - acc: 0.9091 - val_loss: 0.6679 - val_acc: 0.9175\n",
      "Epoch 45/100\n",
      "385/385 [==============================] - 0s 405us/step - loss: 0.6564 - acc: 0.9143 - val_loss: 0.6444 - val_acc: 0.9278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "385/385 [==============================] - 0s 391us/step - loss: 0.6056 - acc: 0.9351 - val_loss: 0.6205 - val_acc: 0.9278\n",
      "Epoch 47/100\n",
      "385/385 [==============================] - 0s 476us/step - loss: 0.6242 - acc: 0.9091 - val_loss: 0.5959 - val_acc: 0.9278\n",
      "Epoch 48/100\n",
      "385/385 [==============================] - 0s 430us/step - loss: 0.5813 - acc: 0.9195 - val_loss: 0.5739 - val_acc: 0.9381\n",
      "Epoch 49/100\n",
      "385/385 [==============================] - 0s 387us/step - loss: 0.5772 - acc: 0.9169 - val_loss: 0.5535 - val_acc: 0.9381\n",
      "Epoch 50/100\n",
      "385/385 [==============================] - 0s 450us/step - loss: 0.5510 - acc: 0.9429 - val_loss: 0.5337 - val_acc: 0.9381\n",
      "Epoch 51/100\n",
      "385/385 [==============================] - 0s 408us/step - loss: 0.5311 - acc: 0.9351 - val_loss: 0.5143 - val_acc: 0.9381\n",
      "Epoch 52/100\n",
      "385/385 [==============================] - 0s 387us/step - loss: 0.5120 - acc: 0.9351 - val_loss: 0.4960 - val_acc: 0.9381\n",
      "Epoch 53/100\n",
      "385/385 [==============================] - 0s 399us/step - loss: 0.4792 - acc: 0.9429 - val_loss: 0.4784 - val_acc: 0.9381\n",
      "Epoch 54/100\n",
      "385/385 [==============================] - 0s 392us/step - loss: 0.4829 - acc: 0.9506 - val_loss: 0.4625 - val_acc: 0.9381\n",
      "Epoch 55/100\n",
      "385/385 [==============================] - 0s 402us/step - loss: 0.4500 - acc: 0.9584 - val_loss: 0.4474 - val_acc: 0.9381\n",
      "Epoch 56/100\n",
      "385/385 [==============================] - 0s 397us/step - loss: 0.4476 - acc: 0.9506 - val_loss: 0.4312 - val_acc: 0.9485\n",
      "Epoch 57/100\n",
      "385/385 [==============================] - 0s 402us/step - loss: 0.4143 - acc: 0.9688 - val_loss: 0.4142 - val_acc: 0.9485\n",
      "Epoch 58/100\n",
      "385/385 [==============================] - 0s 380us/step - loss: 0.4087 - acc: 0.9584 - val_loss: 0.3974 - val_acc: 0.9485\n",
      "Epoch 59/100\n",
      "385/385 [==============================] - 0s 414us/step - loss: 0.4117 - acc: 0.9688 - val_loss: 0.3800 - val_acc: 0.9485\n",
      "Epoch 60/100\n",
      "385/385 [==============================] - 0s 397us/step - loss: 0.3629 - acc: 0.9688 - val_loss: 0.3634 - val_acc: 0.9485\n",
      "Epoch 61/100\n",
      "385/385 [==============================] - 0s 412us/step - loss: 0.3596 - acc: 0.9740 - val_loss: 0.3475 - val_acc: 0.9485\n",
      "Epoch 62/100\n",
      "385/385 [==============================] - 0s 384us/step - loss: 0.3414 - acc: 0.9766 - val_loss: 0.3325 - val_acc: 0.9485\n",
      "Epoch 63/100\n",
      "385/385 [==============================] - 0s 400us/step - loss: 0.3234 - acc: 0.9818 - val_loss: 0.3178 - val_acc: 0.9588\n",
      "Epoch 64/100\n",
      "385/385 [==============================] - 0s 401us/step - loss: 0.3140 - acc: 0.9844 - val_loss: 0.3035 - val_acc: 0.9485\n",
      "Epoch 65/100\n",
      "385/385 [==============================] - 0s 398us/step - loss: 0.3125 - acc: 0.9948 - val_loss: 0.2915 - val_acc: 0.9485\n",
      "Epoch 66/100\n",
      "385/385 [==============================] - 0s 401us/step - loss: 0.2947 - acc: 0.9844 - val_loss: 0.2822 - val_acc: 0.9485\n",
      "Epoch 67/100\n",
      "385/385 [==============================] - 0s 398us/step - loss: 0.2811 - acc: 0.9870 - val_loss: 0.2729 - val_acc: 0.9485\n",
      "Epoch 68/100\n",
      "385/385 [==============================] - 0s 401us/step - loss: 0.2652 - acc: 0.9922 - val_loss: 0.2638 - val_acc: 0.9485\n",
      "Epoch 69/100\n",
      "385/385 [==============================] - 0s 378us/step - loss: 0.2715 - acc: 0.9844 - val_loss: 0.2532 - val_acc: 0.9485\n",
      "Epoch 70/100\n",
      "385/385 [==============================] - 0s 400us/step - loss: 0.2433 - acc: 0.9922 - val_loss: 0.2394 - val_acc: 0.9485\n",
      "Epoch 71/100\n",
      "385/385 [==============================] - 0s 392us/step - loss: 0.2417 - acc: 0.9948 - val_loss: 0.2276 - val_acc: 0.9588\n",
      "Epoch 72/100\n",
      "385/385 [==============================] - 0s 404us/step - loss: 0.2375 - acc: 0.9922 - val_loss: 0.2169 - val_acc: 0.9691\n",
      "Epoch 73/100\n",
      "385/385 [==============================] - 0s 391us/step - loss: 0.2365 - acc: 0.9948 - val_loss: 0.2077 - val_acc: 0.9691\n",
      "Epoch 74/100\n",
      "385/385 [==============================] - 0s 412us/step - loss: 0.2072 - acc: 0.9974 - val_loss: 0.1997 - val_acc: 0.9794\n",
      "Epoch 75/100\n",
      "385/385 [==============================] - 0s 402us/step - loss: 0.2115 - acc: 0.9922 - val_loss: 0.1922 - val_acc: 0.9794\n",
      "Epoch 76/100\n",
      "385/385 [==============================] - 0s 399us/step - loss: 0.1991 - acc: 0.9974 - val_loss: 0.1854 - val_acc: 0.9794\n",
      "Epoch 77/100\n",
      "385/385 [==============================] - 0s 381us/step - loss: 0.1921 - acc: 0.9974 - val_loss: 0.1795 - val_acc: 0.9794\n",
      "Epoch 78/100\n",
      "385/385 [==============================] - 0s 402us/step - loss: 0.1823 - acc: 0.9948 - val_loss: 0.1742 - val_acc: 0.9794\n",
      "Epoch 79/100\n",
      "385/385 [==============================] - 0s 388us/step - loss: 0.1736 - acc: 0.9974 - val_loss: 0.1691 - val_acc: 0.9794\n",
      "Epoch 80/100\n",
      "385/385 [==============================] - 0s 401us/step - loss: 0.1689 - acc: 1.0000 - val_loss: 0.1637 - val_acc: 0.9794\n",
      "Epoch 81/100\n",
      "385/385 [==============================] - 0s 392us/step - loss: 0.1539 - acc: 0.9974 - val_loss: 0.1583 - val_acc: 0.9794\n",
      "Epoch 82/100\n",
      "385/385 [==============================] - 0s 399us/step - loss: 0.1535 - acc: 0.9974 - val_loss: 0.1531 - val_acc: 0.9794\n",
      "Epoch 83/100\n",
      "385/385 [==============================] - 0s 390us/step - loss: 0.1537 - acc: 0.9974 - val_loss: 0.1480 - val_acc: 0.9794\n",
      "Epoch 84/100\n",
      "385/385 [==============================] - 0s 398us/step - loss: 0.1440 - acc: 0.9974 - val_loss: 0.1432 - val_acc: 0.9794\n",
      "Epoch 85/100\n",
      "385/385 [==============================] - 0s 404us/step - loss: 0.1446 - acc: 1.0000 - val_loss: 0.1386 - val_acc: 0.9794\n",
      "Epoch 86/100\n",
      "385/385 [==============================] - 0s 394us/step - loss: 0.1334 - acc: 1.0000 - val_loss: 0.1347 - val_acc: 0.9794\n",
      "Epoch 87/100\n",
      "385/385 [==============================] - 0s 414us/step - loss: 0.1343 - acc: 1.0000 - val_loss: 0.1302 - val_acc: 0.9794\n",
      "Epoch 88/100\n",
      "385/385 [==============================] - 0s 393us/step - loss: 0.1262 - acc: 1.0000 - val_loss: 0.1255 - val_acc: 0.9897\n",
      "Epoch 89/100\n",
      "385/385 [==============================] - 0s 398us/step - loss: 0.1229 - acc: 1.0000 - val_loss: 0.1219 - val_acc: 0.9897\n",
      "Epoch 90/100\n",
      "385/385 [==============================] - 0s 386us/step - loss: 0.1147 - acc: 0.9974 - val_loss: 0.1191 - val_acc: 0.9897\n",
      "Epoch 91/100\n",
      "385/385 [==============================] - 0s 409us/step - loss: 0.1111 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9897\n",
      "Epoch 92/100\n",
      "385/385 [==============================] - 0s 392us/step - loss: 0.1103 - acc: 1.0000 - val_loss: 0.1138 - val_acc: 0.9897\n",
      "Epoch 93/100\n",
      "385/385 [==============================] - 0s 400us/step - loss: 0.1082 - acc: 1.0000 - val_loss: 0.1112 - val_acc: 0.9897\n",
      "Epoch 94/100\n",
      "385/385 [==============================] - 0s 394us/step - loss: 0.1052 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9794\n",
      "Epoch 95/100\n",
      "385/385 [==============================] - 0s 398us/step - loss: 0.1049 - acc: 1.0000 - val_loss: 0.1058 - val_acc: 0.9794\n",
      "Epoch 96/100\n",
      "385/385 [==============================] - 0s 400us/step - loss: 0.0991 - acc: 0.9974 - val_loss: 0.1036 - val_acc: 0.9794\n",
      "Epoch 97/100\n",
      "385/385 [==============================] - 0s 413us/step - loss: 0.0871 - acc: 1.0000 - val_loss: 0.1012 - val_acc: 0.9794\n",
      "Epoch 98/100\n",
      "385/385 [==============================] - 0s 401us/step - loss: 0.0930 - acc: 1.0000 - val_loss: 0.0989 - val_acc: 0.9794\n",
      "Epoch 99/100\n",
      "385/385 [==============================] - 0s 397us/step - loss: 0.0904 - acc: 1.0000 - val_loss: 0.0969 - val_acc: 0.9794\n",
      "Epoch 100/100\n",
      "385/385 [==============================] - 0s 407us/step - loss: 0.0850 - acc: 1.0000 - val_loss: 0.0951 - val_acc: 0.9794\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (402, 30, 128)\n",
      "Shape Y (402, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 321 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      "321/321 [==============================] - 4s 13ms/step - loss: 2.2952 - acc: 0.0592 - val_loss: 2.2276 - val_acc: 0.1235\n",
      "Epoch 2/100\n",
      "321/321 [==============================] - 0s 551us/step - loss: 2.2357 - acc: 0.1090 - val_loss: 2.1744 - val_acc: 0.1728\n",
      "Epoch 3/100\n",
      "321/321 [==============================] - 0s 571us/step - loss: 2.1768 - acc: 0.1433 - val_loss: 2.1242 - val_acc: 0.2222\n",
      "Epoch 4/100\n",
      "321/321 [==============================] - 0s 598us/step - loss: 2.1368 - acc: 0.1713 - val_loss: 2.0770 - val_acc: 0.2593\n",
      "Epoch 5/100\n",
      "321/321 [==============================] - 0s 582us/step - loss: 2.0916 - acc: 0.2368 - val_loss: 2.0310 - val_acc: 0.3086\n",
      "Epoch 6/100\n",
      "321/321 [==============================] - 0s 553us/step - loss: 2.0559 - acc: 0.2555 - val_loss: 1.9872 - val_acc: 0.4074\n",
      "Epoch 7/100\n",
      "321/321 [==============================] - 0s 563us/step - loss: 2.0016 - acc: 0.3209 - val_loss: 1.9463 - val_acc: 0.4938\n",
      "Epoch 8/100\n",
      "321/321 [==============================] - 0s 556us/step - loss: 1.9755 - acc: 0.4206 - val_loss: 1.9062 - val_acc: 0.5556\n",
      "Epoch 9/100\n",
      "321/321 [==============================] - 0s 573us/step - loss: 1.9264 - acc: 0.4361 - val_loss: 1.8658 - val_acc: 0.6049\n",
      "Epoch 10/100\n",
      "321/321 [==============================] - 0s 601us/step - loss: 1.8882 - acc: 0.5078 - val_loss: 1.8251 - val_acc: 0.6173\n",
      "Epoch 11/100\n",
      "321/321 [==============================] - 0s 579us/step - loss: 1.8424 - acc: 0.5576 - val_loss: 1.7875 - val_acc: 0.6420\n",
      "Epoch 12/100\n",
      "321/321 [==============================] - 0s 577us/step - loss: 1.7857 - acc: 0.5950 - val_loss: 1.7511 - val_acc: 0.6667\n",
      "Epoch 13/100\n",
      "321/321 [==============================] - 0s 564us/step - loss: 1.7812 - acc: 0.5950 - val_loss: 1.7152 - val_acc: 0.6667\n",
      "Epoch 14/100\n",
      "321/321 [==============================] - 0s 587us/step - loss: 1.7326 - acc: 0.6231 - val_loss: 1.6793 - val_acc: 0.6790\n",
      "Epoch 15/100\n",
      "321/321 [==============================] - 0s 558us/step - loss: 1.6687 - acc: 0.7072 - val_loss: 1.6432 - val_acc: 0.7160\n",
      "Epoch 16/100\n",
      "321/321 [==============================] - 0s 579us/step - loss: 1.6659 - acc: 0.6386 - val_loss: 1.6070 - val_acc: 0.7407\n",
      "Epoch 17/100\n",
      "321/321 [==============================] - 0s 568us/step - loss: 1.6247 - acc: 0.6916 - val_loss: 1.5705 - val_acc: 0.7654\n",
      "Epoch 18/100\n",
      "321/321 [==============================] - 0s 566us/step - loss: 1.5719 - acc: 0.7321 - val_loss: 1.5337 - val_acc: 0.7901\n",
      "Epoch 19/100\n",
      "321/321 [==============================] - 0s 560us/step - loss: 1.5551 - acc: 0.7009 - val_loss: 1.4971 - val_acc: 0.7901\n",
      "Epoch 20/100\n",
      "321/321 [==============================] - 0s 580us/step - loss: 1.5188 - acc: 0.7196 - val_loss: 1.4605 - val_acc: 0.8148\n",
      "Epoch 21/100\n",
      "321/321 [==============================] - 0s 571us/step - loss: 1.4686 - acc: 0.7445 - val_loss: 1.4236 - val_acc: 0.8272\n",
      "Epoch 22/100\n",
      "321/321 [==============================] - 0s 572us/step - loss: 1.4404 - acc: 0.7508 - val_loss: 1.3868 - val_acc: 0.8148\n",
      "Epoch 23/100\n",
      "321/321 [==============================] - 0s 595us/step - loss: 1.3888 - acc: 0.7726 - val_loss: 1.3500 - val_acc: 0.8148\n",
      "Epoch 24/100\n",
      "321/321 [==============================] - 0s 589us/step - loss: 1.3575 - acc: 0.7975 - val_loss: 1.3134 - val_acc: 0.8025\n",
      "Epoch 25/100\n",
      "321/321 [==============================] - 0s 565us/step - loss: 1.3216 - acc: 0.7850 - val_loss: 1.2767 - val_acc: 0.8025\n",
      "Epoch 26/100\n",
      "321/321 [==============================] - 0s 565us/step - loss: 1.2770 - acc: 0.8006 - val_loss: 1.2398 - val_acc: 0.8025\n",
      "Epoch 27/100\n",
      "321/321 [==============================] - 0s 585us/step - loss: 1.2418 - acc: 0.7944 - val_loss: 1.2027 - val_acc: 0.8025\n",
      "Epoch 28/100\n",
      "321/321 [==============================] - 0s 592us/step - loss: 1.2115 - acc: 0.7944 - val_loss: 1.1656 - val_acc: 0.8025\n",
      "Epoch 29/100\n",
      "321/321 [==============================] - 0s 592us/step - loss: 1.1552 - acc: 0.8100 - val_loss: 1.1295 - val_acc: 0.8025\n",
      "Epoch 30/100\n",
      "321/321 [==============================] - 0s 555us/step - loss: 1.1177 - acc: 0.8255 - val_loss: 1.0936 - val_acc: 0.7901\n",
      "Epoch 31/100\n",
      "321/321 [==============================] - 0s 592us/step - loss: 1.0977 - acc: 0.8255 - val_loss: 1.0579 - val_acc: 0.8025\n",
      "Epoch 32/100\n",
      "321/321 [==============================] - 0s 578us/step - loss: 1.0581 - acc: 0.8255 - val_loss: 1.0247 - val_acc: 0.8025\n",
      "Epoch 33/100\n",
      "321/321 [==============================] - 0s 623us/step - loss: 1.0219 - acc: 0.8318 - val_loss: 0.9939 - val_acc: 0.8025\n",
      "Epoch 34/100\n",
      "321/321 [==============================] - 0s 581us/step - loss: 0.9854 - acc: 0.8442 - val_loss: 0.9661 - val_acc: 0.8025\n",
      "Epoch 35/100\n",
      "321/321 [==============================] - 0s 600us/step - loss: 0.9619 - acc: 0.8287 - val_loss: 0.9398 - val_acc: 0.8272\n",
      "Epoch 36/100\n",
      "321/321 [==============================] - 0s 590us/step - loss: 0.9474 - acc: 0.8318 - val_loss: 0.9141 - val_acc: 0.8272\n",
      "Epoch 37/100\n",
      "321/321 [==============================] - 0s 607us/step - loss: 0.9182 - acc: 0.8349 - val_loss: 0.8888 - val_acc: 0.8272\n",
      "Epoch 38/100\n",
      "321/321 [==============================] - 0s 594us/step - loss: 0.8706 - acc: 0.8505 - val_loss: 0.8635 - val_acc: 0.8272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "321/321 [==============================] - 0s 601us/step - loss: 0.8490 - acc: 0.8567 - val_loss: 0.8374 - val_acc: 0.8272\n",
      "Epoch 40/100\n",
      "321/321 [==============================] - 0s 593us/step - loss: 0.8060 - acc: 0.8536 - val_loss: 0.8094 - val_acc: 0.8395\n",
      "Epoch 41/100\n",
      "321/321 [==============================] - 0s 604us/step - loss: 0.7905 - acc: 0.8629 - val_loss: 0.7804 - val_acc: 0.8395\n",
      "Epoch 42/100\n",
      "321/321 [==============================] - 0s 590us/step - loss: 0.7415 - acc: 0.8785 - val_loss: 0.7550 - val_acc: 0.8519\n",
      "Epoch 43/100\n",
      "321/321 [==============================] - 0s 577us/step - loss: 0.7207 - acc: 0.8785 - val_loss: 0.7310 - val_acc: 0.8519\n",
      "Epoch 44/100\n",
      "321/321 [==============================] - 0s 618us/step - loss: 0.7184 - acc: 0.8879 - val_loss: 0.7083 - val_acc: 0.8642\n",
      "Epoch 45/100\n",
      "321/321 [==============================] - 0s 583us/step - loss: 0.6981 - acc: 0.8972 - val_loss: 0.6867 - val_acc: 0.8642\n",
      "Epoch 46/100\n",
      "321/321 [==============================] - 0s 605us/step - loss: 0.6769 - acc: 0.9065 - val_loss: 0.6668 - val_acc: 0.8642\n",
      "Epoch 47/100\n",
      "321/321 [==============================] - 0s 608us/step - loss: 0.6406 - acc: 0.9034 - val_loss: 0.6492 - val_acc: 0.8642\n",
      "Epoch 48/100\n",
      "321/321 [==============================] - 0s 587us/step - loss: 0.6051 - acc: 0.9034 - val_loss: 0.6339 - val_acc: 0.8642\n",
      "Epoch 49/100\n",
      "321/321 [==============================] - 0s 597us/step - loss: 0.5940 - acc: 0.9128 - val_loss: 0.6186 - val_acc: 0.8765\n",
      "Epoch 50/100\n",
      "321/321 [==============================] - 0s 597us/step - loss: 0.5631 - acc: 0.9221 - val_loss: 0.6025 - val_acc: 0.8889\n",
      "Epoch 51/100\n",
      "321/321 [==============================] - 0s 602us/step - loss: 0.5644 - acc: 0.9065 - val_loss: 0.5856 - val_acc: 0.8889\n",
      "Epoch 52/100\n",
      "321/321 [==============================] - 0s 599us/step - loss: 0.5333 - acc: 0.9190 - val_loss: 0.5691 - val_acc: 0.9012\n",
      "Epoch 53/100\n",
      "321/321 [==============================] - 0s 606us/step - loss: 0.5094 - acc: 0.9252 - val_loss: 0.5539 - val_acc: 0.9012\n",
      "Epoch 54/100\n",
      "321/321 [==============================] - 0s 607us/step - loss: 0.4984 - acc: 0.9190 - val_loss: 0.5385 - val_acc: 0.9136\n",
      "Epoch 55/100\n",
      "321/321 [==============================] - 0s 575us/step - loss: 0.4861 - acc: 0.9190 - val_loss: 0.5236 - val_acc: 0.9136\n",
      "Epoch 56/100\n",
      "321/321 [==============================] - 0s 603us/step - loss: 0.4879 - acc: 0.9190 - val_loss: 0.5061 - val_acc: 0.9136\n",
      "Epoch 57/100\n",
      "321/321 [==============================] - 0s 603us/step - loss: 0.4605 - acc: 0.9408 - val_loss: 0.4831 - val_acc: 0.9136\n",
      "Epoch 58/100\n",
      "321/321 [==============================] - 0s 591us/step - loss: 0.4452 - acc: 0.9346 - val_loss: 0.4640 - val_acc: 0.9136\n",
      "Epoch 59/100\n",
      "321/321 [==============================] - 0s 639us/step - loss: 0.4231 - acc: 0.9470 - val_loss: 0.4490 - val_acc: 0.9136\n",
      "Epoch 60/100\n",
      "321/321 [==============================] - 0s 592us/step - loss: 0.4130 - acc: 0.9408 - val_loss: 0.4356 - val_acc: 0.9136\n",
      "Epoch 61/100\n",
      "321/321 [==============================] - 0s 595us/step - loss: 0.4114 - acc: 0.9408 - val_loss: 0.4228 - val_acc: 0.9136\n",
      "Epoch 62/100\n",
      "321/321 [==============================] - 0s 595us/step - loss: 0.3861 - acc: 0.9470 - val_loss: 0.4105 - val_acc: 0.9136\n",
      "Epoch 63/100\n",
      "321/321 [==============================] - 0s 593us/step - loss: 0.3890 - acc: 0.9470 - val_loss: 0.3999 - val_acc: 0.9136\n",
      "Epoch 64/100\n",
      "321/321 [==============================] - 0s 594us/step - loss: 0.3604 - acc: 0.9564 - val_loss: 0.3992 - val_acc: 0.9136\n",
      "Epoch 65/100\n",
      "321/321 [==============================] - 0s 617us/step - loss: 0.3355 - acc: 0.9595 - val_loss: 0.4058 - val_acc: 0.9136\n",
      "Epoch 66/100\n",
      "321/321 [==============================] - 0s 600us/step - loss: 0.3408 - acc: 0.9657 - val_loss: 0.3991 - val_acc: 0.9136\n",
      "Epoch 67/100\n",
      "321/321 [==============================] - 0s 605us/step - loss: 0.3150 - acc: 0.9564 - val_loss: 0.3917 - val_acc: 0.9136\n",
      "Epoch 68/100\n",
      "321/321 [==============================] - 0s 574us/step - loss: 0.3208 - acc: 0.9595 - val_loss: 0.3841 - val_acc: 0.9136\n",
      "Epoch 69/100\n",
      "321/321 [==============================] - 0s 614us/step - loss: 0.2922 - acc: 0.9657 - val_loss: 0.3762 - val_acc: 0.9259\n",
      "Epoch 70/100\n",
      "321/321 [==============================] - 0s 589us/step - loss: 0.2916 - acc: 0.9595 - val_loss: 0.3686 - val_acc: 0.9259\n",
      "Epoch 71/100\n",
      "321/321 [==============================] - 0s 650us/step - loss: 0.2823 - acc: 0.9626 - val_loss: 0.3613 - val_acc: 0.9383\n",
      "Epoch 72/100\n",
      "321/321 [==============================] - 0s 617us/step - loss: 0.2593 - acc: 0.9782 - val_loss: 0.3528 - val_acc: 0.9506\n",
      "Epoch 73/100\n",
      "321/321 [==============================] - 0s 580us/step - loss: 0.2744 - acc: 0.9688 - val_loss: 0.3438 - val_acc: 0.9506\n",
      "Epoch 74/100\n",
      "321/321 [==============================] - 0s 602us/step - loss: 0.2586 - acc: 0.9688 - val_loss: 0.3352 - val_acc: 0.9506\n",
      "Epoch 75/100\n",
      "321/321 [==============================] - 0s 605us/step - loss: 0.2460 - acc: 0.9657 - val_loss: 0.3275 - val_acc: 0.9506\n",
      "Epoch 76/100\n",
      "321/321 [==============================] - 0s 601us/step - loss: 0.2264 - acc: 0.9720 - val_loss: 0.3203 - val_acc: 0.9630\n",
      "Epoch 77/100\n",
      "321/321 [==============================] - 0s 602us/step - loss: 0.2346 - acc: 0.9720 - val_loss: 0.3134 - val_acc: 0.9630\n",
      "Epoch 78/100\n",
      "321/321 [==============================] - 0s 606us/step - loss: 0.2265 - acc: 0.9720 - val_loss: 0.3067 - val_acc: 0.9630\n",
      "Epoch 79/100\n",
      "321/321 [==============================] - 0s 602us/step - loss: 0.2245 - acc: 0.9720 - val_loss: 0.3001 - val_acc: 0.9630\n",
      "Epoch 80/100\n",
      "321/321 [==============================] - 0s 613us/step - loss: 0.2187 - acc: 0.9782 - val_loss: 0.2948 - val_acc: 0.9630\n",
      "Epoch 81/100\n",
      "321/321 [==============================] - 0s 587us/step - loss: 0.2029 - acc: 0.9782 - val_loss: 0.3058 - val_acc: 0.9630\n",
      "Epoch 82/100\n",
      "321/321 [==============================] - 0s 650us/step - loss: 0.1967 - acc: 0.9782 - val_loss: 0.3120 - val_acc: 0.9630\n",
      "Epoch 83/100\n",
      "321/321 [==============================] - 0s 600us/step - loss: 0.1903 - acc: 0.9844 - val_loss: 0.3099 - val_acc: 0.9630\n",
      "Epoch 84/100\n",
      "321/321 [==============================] - 0s 623us/step - loss: 0.1859 - acc: 0.9844 - val_loss: 0.3061 - val_acc: 0.9630\n",
      "Epoch 85/100\n",
      "321/321 [==============================] - 0s 580us/step - loss: 0.1785 - acc: 0.9813 - val_loss: 0.2978 - val_acc: 0.9630\n",
      "Epoch 86/100\n",
      "321/321 [==============================] - 0s 582us/step - loss: 0.1769 - acc: 0.9813 - val_loss: 0.2634 - val_acc: 0.9630\n",
      "Epoch 87/100\n",
      "321/321 [==============================] - 0s 604us/step - loss: 0.1652 - acc: 0.9813 - val_loss: 0.2596 - val_acc: 0.9630\n",
      "Epoch 88/100\n",
      "321/321 [==============================] - 0s 629us/step - loss: 0.1664 - acc: 0.9875 - val_loss: 0.2599 - val_acc: 0.9630\n",
      "Epoch 89/100\n",
      "321/321 [==============================] - 0s 640us/step - loss: 0.1483 - acc: 0.9875 - val_loss: 0.2578 - val_acc: 0.9630\n",
      "Epoch 90/100\n",
      "321/321 [==============================] - 0s 621us/step - loss: 0.1570 - acc: 0.9844 - val_loss: 0.2544 - val_acc: 0.9630\n",
      "Epoch 91/100\n",
      "321/321 [==============================] - 0s 594us/step - loss: 0.1488 - acc: 0.9844 - val_loss: 0.2507 - val_acc: 0.9630\n",
      "Epoch 92/100\n",
      "321/321 [==============================] - 0s 603us/step - loss: 0.1392 - acc: 0.9907 - val_loss: 0.2473 - val_acc: 0.9630\n",
      "Epoch 93/100\n",
      "321/321 [==============================] - 0s 598us/step - loss: 0.1412 - acc: 0.9938 - val_loss: 0.2441 - val_acc: 0.9630\n",
      "Epoch 94/100\n",
      "321/321 [==============================] - 0s 592us/step - loss: 0.1437 - acc: 0.9813 - val_loss: 0.2411 - val_acc: 0.9630\n",
      "Epoch 95/100\n",
      "321/321 [==============================] - 0s 611us/step - loss: 0.1269 - acc: 0.9969 - val_loss: 0.2379 - val_acc: 0.9630\n",
      "Epoch 96/100\n",
      "321/321 [==============================] - 0s 598us/step - loss: 0.1281 - acc: 0.9969 - val_loss: 0.2362 - val_acc: 0.9630\n",
      "Epoch 97/100\n",
      "321/321 [==============================] - 0s 589us/step - loss: 0.1257 - acc: 0.9938 - val_loss: 0.2352 - val_acc: 0.9630\n",
      "Epoch 98/100\n",
      "321/321 [==============================] - 0s 612us/step - loss: 0.1281 - acc: 0.9907 - val_loss: 0.2340 - val_acc: 0.9630\n",
      "Epoch 99/100\n",
      "321/321 [==============================] - 0s 590us/step - loss: 0.1162 - acc: 0.9969 - val_loss: 0.2290 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "321/321 [==============================] - 0s 611us/step - loss: 0.1137 - acc: 0.9969 - val_loss: 0.2147 - val_acc: 0.9630\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (322, 40, 128)\n",
      "Shape Y (322, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 257 samples, validate on 65 samples\n",
      "Epoch 1/100\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 2.2143 - acc: 0.1323 - val_loss: 2.1484 - val_acc: 0.2154\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 0s 777us/step - loss: 2.1103 - acc: 0.2257 - val_loss: 2.0748 - val_acc: 0.3538\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 0s 837us/step - loss: 2.0588 - acc: 0.2840 - val_loss: 2.0174 - val_acc: 0.4308\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 0s 805us/step - loss: 1.9805 - acc: 0.3619 - val_loss: 1.9590 - val_acc: 0.4615\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 0s 787us/step - loss: 1.9106 - acc: 0.4319 - val_loss: 1.9082 - val_acc: 0.4769\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 0s 805us/step - loss: 1.8535 - acc: 0.4864 - val_loss: 1.8601 - val_acc: 0.4462\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 0s 828us/step - loss: 1.8241 - acc: 0.5058 - val_loss: 1.8124 - val_acc: 0.5077\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 0s 870us/step - loss: 1.7770 - acc: 0.5603 - val_loss: 1.7637 - val_acc: 0.5231\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 0s 794us/step - loss: 1.7366 - acc: 0.5681 - val_loss: 1.7152 - val_acc: 0.5385\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 0s 840us/step - loss: 1.6872 - acc: 0.6342 - val_loss: 1.6688 - val_acc: 0.6000\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 0s 867us/step - loss: 1.6283 - acc: 0.6304 - val_loss: 1.6243 - val_acc: 0.6308\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 0s 818us/step - loss: 1.5971 - acc: 0.6770 - val_loss: 1.5814 - val_acc: 0.6154\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 0s 811us/step - loss: 1.5559 - acc: 0.7043 - val_loss: 1.5395 - val_acc: 0.6154\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 0s 817us/step - loss: 1.5121 - acc: 0.7354 - val_loss: 1.4985 - val_acc: 0.6308\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 0s 813us/step - loss: 1.4565 - acc: 0.7432 - val_loss: 1.4576 - val_acc: 0.6462\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 0s 831us/step - loss: 1.4361 - acc: 0.7471 - val_loss: 1.4175 - val_acc: 0.6615\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 0s 860us/step - loss: 1.3921 - acc: 0.7354 - val_loss: 1.3763 - val_acc: 0.6615\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 0s 807us/step - loss: 1.3355 - acc: 0.7977 - val_loss: 1.3366 - val_acc: 0.6615\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 0s 819us/step - loss: 1.3044 - acc: 0.8016 - val_loss: 1.2975 - val_acc: 0.6615\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 0s 840us/step - loss: 1.2596 - acc: 0.7938 - val_loss: 1.2614 - val_acc: 0.6923\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 0s 816us/step - loss: 1.2122 - acc: 0.8132 - val_loss: 1.2265 - val_acc: 0.7077\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 0s 872us/step - loss: 1.2127 - acc: 0.7938 - val_loss: 1.1914 - val_acc: 0.7231\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 0s 794us/step - loss: 1.1353 - acc: 0.8327 - val_loss: 1.1571 - val_acc: 0.7692\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 0s 803us/step - loss: 1.1032 - acc: 0.8288 - val_loss: 1.1232 - val_acc: 0.7846\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 0s 818us/step - loss: 1.0665 - acc: 0.8405 - val_loss: 1.0896 - val_acc: 0.7846\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 0s 829us/step - loss: 1.0315 - acc: 0.8327 - val_loss: 1.0575 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 0s 859us/step - loss: 0.9721 - acc: 0.8405 - val_loss: 1.0252 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 0s 811us/step - loss: 0.9508 - acc: 0.8716 - val_loss: 0.9956 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 0s 826us/step - loss: 0.9143 - acc: 0.8794 - val_loss: 0.9681 - val_acc: 0.8308\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 0s 843us/step - loss: 0.8973 - acc: 0.8755 - val_loss: 0.9446 - val_acc: 0.8462\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 0s 853us/step - loss: 0.8417 - acc: 0.8911 - val_loss: 0.9231 - val_acc: 0.8462\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 0s 832us/step - loss: 0.8331 - acc: 0.8988 - val_loss: 0.8998 - val_acc: 0.8462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "257/257 [==============================] - 0s 817us/step - loss: 0.7851 - acc: 0.9105 - val_loss: 0.8754 - val_acc: 0.8615\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 0s 822us/step - loss: 0.7701 - acc: 0.9027 - val_loss: 0.8502 - val_acc: 0.8615\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 0s 792us/step - loss: 0.7363 - acc: 0.8949 - val_loss: 0.8210 - val_acc: 0.8615\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 0s 824us/step - loss: 0.7035 - acc: 0.9144 - val_loss: 0.7893 - val_acc: 0.8615\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 0s 803us/step - loss: 0.6717 - acc: 0.9144 - val_loss: 0.7600 - val_acc: 0.8615\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 0s 807us/step - loss: 0.6599 - acc: 0.9144 - val_loss: 0.7326 - val_acc: 0.8615\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 0s 810us/step - loss: 0.6246 - acc: 0.9027 - val_loss: 0.7067 - val_acc: 0.8615\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 0s 812us/step - loss: 0.6126 - acc: 0.9261 - val_loss: 0.6825 - val_acc: 0.8615\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 0s 873us/step - loss: 0.5943 - acc: 0.9339 - val_loss: 0.6581 - val_acc: 0.8615\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 0s 837us/step - loss: 0.5979 - acc: 0.9261 - val_loss: 0.6356 - val_acc: 0.8769\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 0s 821us/step - loss: 0.5476 - acc: 0.9416 - val_loss: 0.6157 - val_acc: 0.8769\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 0s 830us/step - loss: 0.5247 - acc: 0.9377 - val_loss: 0.5970 - val_acc: 0.8923\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 0s 864us/step - loss: 0.5012 - acc: 0.9494 - val_loss: 0.5777 - val_acc: 0.8923\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 0s 839us/step - loss: 0.4978 - acc: 0.9494 - val_loss: 0.5558 - val_acc: 0.8923\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 0s 844us/step - loss: 0.4697 - acc: 0.9339 - val_loss: 0.5328 - val_acc: 0.8923\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 0s 879us/step - loss: 0.4722 - acc: 0.9416 - val_loss: 0.5139 - val_acc: 0.8923\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 0s 936us/step - loss: 0.4405 - acc: 0.9377 - val_loss: 0.4981 - val_acc: 0.9077\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 0s 882us/step - loss: 0.4190 - acc: 0.9611 - val_loss: 0.4840 - val_acc: 0.9077\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 0s 849us/step - loss: 0.4350 - acc: 0.9494 - val_loss: 0.4711 - val_acc: 0.9077\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 0s 857us/step - loss: 0.4328 - acc: 0.9533 - val_loss: 0.4586 - val_acc: 0.9077\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 0s 834us/step - loss: 0.4075 - acc: 0.9494 - val_loss: 0.4465 - val_acc: 0.9077\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 0s 885us/step - loss: 0.3877 - acc: 0.9533 - val_loss: 0.4350 - val_acc: 0.9077\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 0s 836us/step - loss: 0.3669 - acc: 0.9533 - val_loss: 0.4243 - val_acc: 0.9231\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 0s 843us/step - loss: 0.3728 - acc: 0.9650 - val_loss: 0.4135 - val_acc: 0.9385\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 0s 876us/step - loss: 0.3787 - acc: 0.9650 - val_loss: 0.4030 - val_acc: 0.9385\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 0s 824us/step - loss: 0.3531 - acc: 0.9572 - val_loss: 0.3937 - val_acc: 0.9385\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 0s 849us/step - loss: 0.3370 - acc: 0.9650 - val_loss: 0.3857 - val_acc: 0.9385\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 0s 832us/step - loss: 0.3197 - acc: 0.9689 - val_loss: 0.3793 - val_acc: 0.9385\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 0s 847us/step - loss: 0.3036 - acc: 0.9728 - val_loss: 0.3744 - val_acc: 0.9385\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 0s 842us/step - loss: 0.3150 - acc: 0.9650 - val_loss: 0.3709 - val_acc: 0.9385\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 0s 872us/step - loss: 0.2982 - acc: 0.9689 - val_loss: 0.3704 - val_acc: 0.9231\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 0s 1ms/step - loss: 0.2769 - acc: 0.9728 - val_loss: 0.3732 - val_acc: 0.9077\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 0s 830us/step - loss: 0.2729 - acc: 0.9767 - val_loss: 0.3756 - val_acc: 0.9077\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 0s 886us/step - loss: 0.2870 - acc: 0.9689 - val_loss: 0.3761 - val_acc: 0.9077\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 0s 834us/step - loss: 0.2736 - acc: 0.9805 - val_loss: 0.3750 - val_acc: 0.9077\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 0s 847us/step - loss: 0.2702 - acc: 0.9844 - val_loss: 0.3704 - val_acc: 0.9077\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 0s 821us/step - loss: 0.2523 - acc: 0.9844 - val_loss: 0.3655 - val_acc: 0.9077\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 0s 840us/step - loss: 0.2591 - acc: 0.9728 - val_loss: 0.3525 - val_acc: 0.9077\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 0s 847us/step - loss: 0.2642 - acc: 0.9767 - val_loss: 0.3382 - val_acc: 0.9231\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 0s 853us/step - loss: 0.2369 - acc: 0.9767 - val_loss: 0.3311 - val_acc: 0.9231\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 0s 854us/step - loss: 0.2392 - acc: 0.9883 - val_loss: 0.3271 - val_acc: 0.9231\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 0s 833us/step - loss: 0.2274 - acc: 0.9844 - val_loss: 0.3242 - val_acc: 0.9231\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 0s 864us/step - loss: 0.2343 - acc: 0.9844 - val_loss: 0.3217 - val_acc: 0.9231\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 0s 822us/step - loss: 0.2108 - acc: 0.9961 - val_loss: 0.3201 - val_acc: 0.9231\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 0s 889us/step - loss: 0.2185 - acc: 0.9805 - val_loss: 0.3190 - val_acc: 0.9231\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 0s 842us/step - loss: 0.2010 - acc: 0.9844 - val_loss: 0.3188 - val_acc: 0.9231\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 0s 929us/step - loss: 0.2025 - acc: 0.9883 - val_loss: 0.3180 - val_acc: 0.9231\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 0s 869us/step - loss: 0.2065 - acc: 0.9961 - val_loss: 0.3174 - val_acc: 0.9231\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 0s 861us/step - loss: 0.2001 - acc: 0.9844 - val_loss: 0.3174 - val_acc: 0.9231\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 0s 845us/step - loss: 0.1806 - acc: 0.9922 - val_loss: 0.3184 - val_acc: 0.9231\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 0s 870us/step - loss: 0.1915 - acc: 0.9883 - val_loss: 0.3197 - val_acc: 0.9231\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 0s 871us/step - loss: 0.1886 - acc: 0.9922 - val_loss: 0.3215 - val_acc: 0.9231\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 0s 834us/step - loss: 0.1954 - acc: 0.9922 - val_loss: 0.3231 - val_acc: 0.9231\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 0s 867us/step - loss: 0.1777 - acc: 0.9961 - val_loss: 0.3258 - val_acc: 0.9231\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 0s 862us/step - loss: 0.1693 - acc: 0.9922 - val_loss: 0.3279 - val_acc: 0.9231\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 0s 829us/step - loss: 0.1659 - acc: 0.9922 - val_loss: 0.3280 - val_acc: 0.9231\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 0s 826us/step - loss: 0.1660 - acc: 0.9922 - val_loss: 0.3261 - val_acc: 0.9231\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 0s 847us/step - loss: 0.1633 - acc: 0.9961 - val_loss: 0.3257 - val_acc: 0.9231\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 0s 872us/step - loss: 0.1557 - acc: 0.9922 - val_loss: 0.3253 - val_acc: 0.9231\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 0s 833us/step - loss: 0.1498 - acc: 0.9961 - val_loss: 0.3237 - val_acc: 0.9231\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 0s 844us/step - loss: 0.1517 - acc: 0.9922 - val_loss: 0.3231 - val_acc: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "257/257 [==============================] - 0s 833us/step - loss: 0.1554 - acc: 0.9961 - val_loss: 0.3238 - val_acc: 0.9231\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 0s 849us/step - loss: 0.1430 - acc: 1.0000 - val_loss: 0.3240 - val_acc: 0.9231\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 0s 857us/step - loss: 0.1441 - acc: 0.9961 - val_loss: 0.3247 - val_acc: 0.9231\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 0s 876us/step - loss: 0.1371 - acc: 1.0000 - val_loss: 0.3264 - val_acc: 0.9385\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 0s 855us/step - loss: 0.1329 - acc: 0.9961 - val_loss: 0.3262 - val_acc: 0.9385\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 0s 845us/step - loss: 0.1320 - acc: 1.0000 - val_loss: 0.3259 - val_acc: 0.9385\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 0s 862us/step - loss: 0.1310 - acc: 1.0000 - val_loss: 0.3243 - val_acc: 0.9385\n",
      "Processed 014 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 006 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 006 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 005 of class Lifting\n",
      "Processed 003 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 014 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 006 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Training\n",
      "Shape X (254, 50, 128)\n",
      "Shape Y (254, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Train on 203 samples, validate on 51 samples\n",
      "Epoch 1/100\n",
      "203/203 [==============================] - 5s 25ms/step - loss: 2.2732 - acc: 0.0887 - val_loss: 2.2057 - val_acc: 0.1569\n",
      "Epoch 2/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 2.2016 - acc: 0.1429 - val_loss: 2.1555 - val_acc: 0.1765\n",
      "Epoch 3/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 2.1436 - acc: 0.1576 - val_loss: 2.1033 - val_acc: 0.1961\n",
      "Epoch 4/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 2.0812 - acc: 0.2118 - val_loss: 2.0485 - val_acc: 0.2549\n",
      "Epoch 5/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 2.0595 - acc: 0.2167 - val_loss: 2.0035 - val_acc: 0.3529\n",
      "Epoch 6/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.9966 - acc: 0.2660 - val_loss: 1.9607 - val_acc: 0.4510\n",
      "Epoch 7/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.9474 - acc: 0.3793 - val_loss: 1.9209 - val_acc: 0.4510\n",
      "Epoch 8/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.8921 - acc: 0.4236 - val_loss: 1.8828 - val_acc: 0.4510\n",
      "Epoch 9/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.8629 - acc: 0.4729 - val_loss: 1.8455 - val_acc: 0.4902\n",
      "Epoch 10/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.8193 - acc: 0.4729 - val_loss: 1.8082 - val_acc: 0.5294\n",
      "Epoch 11/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.7869 - acc: 0.5616 - val_loss: 1.7711 - val_acc: 0.5294\n",
      "Epoch 12/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.7450 - acc: 0.6158 - val_loss: 1.7334 - val_acc: 0.5490\n",
      "Epoch 13/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.6889 - acc: 0.6404 - val_loss: 1.6954 - val_acc: 0.5882\n",
      "Epoch 14/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.6702 - acc: 0.5911 - val_loss: 1.6582 - val_acc: 0.6078\n",
      "Epoch 15/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.6197 - acc: 0.6946 - val_loss: 1.6215 - val_acc: 0.6275\n",
      "Epoch 16/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.5602 - acc: 0.6798 - val_loss: 1.5844 - val_acc: 0.6667\n",
      "Epoch 17/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.5554 - acc: 0.6995 - val_loss: 1.5470 - val_acc: 0.7059\n",
      "Epoch 18/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.5080 - acc: 0.7488 - val_loss: 1.5092 - val_acc: 0.7255\n",
      "Epoch 19/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.4714 - acc: 0.7241 - val_loss: 1.4702 - val_acc: 0.7451\n",
      "Epoch 20/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.4276 - acc: 0.7685 - val_loss: 1.4311 - val_acc: 0.7843\n",
      "Epoch 21/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.3933 - acc: 0.7685 - val_loss: 1.3922 - val_acc: 0.7843\n",
      "Epoch 22/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.3694 - acc: 0.7833 - val_loss: 1.3539 - val_acc: 0.7647\n",
      "Epoch 23/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.3159 - acc: 0.7685 - val_loss: 1.3170 - val_acc: 0.7647\n",
      "Epoch 24/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.2765 - acc: 0.7833 - val_loss: 1.2804 - val_acc: 0.7647\n",
      "Epoch 25/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.2206 - acc: 0.8227 - val_loss: 1.2448 - val_acc: 0.7647\n",
      "Epoch 26/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.2021 - acc: 0.8177 - val_loss: 1.2112 - val_acc: 0.7843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.1710 - acc: 0.7931 - val_loss: 1.1765 - val_acc: 0.7843\n",
      "Epoch 28/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.1398 - acc: 0.8276 - val_loss: 1.1415 - val_acc: 0.7843\n",
      "Epoch 29/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.0955 - acc: 0.8325 - val_loss: 1.1061 - val_acc: 0.7843\n",
      "Epoch 30/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.0605 - acc: 0.8177 - val_loss: 1.0677 - val_acc: 0.7843\n",
      "Epoch 31/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.9995 - acc: 0.8522 - val_loss: 1.0339 - val_acc: 0.7843\n",
      "Epoch 32/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.9753 - acc: 0.8522 - val_loss: 1.0007 - val_acc: 0.8039\n",
      "Epoch 33/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.9610 - acc: 0.8424 - val_loss: 0.9597 - val_acc: 0.8235\n",
      "Epoch 34/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.9353 - acc: 0.8424 - val_loss: 0.9220 - val_acc: 0.8235\n",
      "Epoch 35/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.8919 - acc: 0.8522 - val_loss: 0.8870 - val_acc: 0.8235\n",
      "Epoch 36/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.8578 - acc: 0.8571 - val_loss: 0.8519 - val_acc: 0.8627\n",
      "Epoch 37/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.8211 - acc: 0.8818 - val_loss: 0.8174 - val_acc: 0.8627\n",
      "Epoch 38/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.8143 - acc: 0.8719 - val_loss: 0.7853 - val_acc: 0.8627\n",
      "Epoch 39/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.7910 - acc: 0.8818 - val_loss: 0.7552 - val_acc: 0.8627\n",
      "Epoch 40/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.7405 - acc: 0.8867 - val_loss: 0.7269 - val_acc: 0.8824\n",
      "Epoch 41/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.7235 - acc: 0.8867 - val_loss: 0.6976 - val_acc: 0.9216\n",
      "Epoch 42/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.6956 - acc: 0.8966 - val_loss: 0.6729 - val_acc: 0.9216\n",
      "Epoch 43/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.6851 - acc: 0.8818 - val_loss: 0.6496 - val_acc: 0.9216\n",
      "Epoch 44/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.6912 - acc: 0.9064 - val_loss: 0.6281 - val_acc: 0.9216\n",
      "Epoch 45/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.6366 - acc: 0.9015 - val_loss: 0.6082 - val_acc: 0.9216\n",
      "Epoch 46/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.6364 - acc: 0.9163 - val_loss: 0.5893 - val_acc: 0.9216\n",
      "Epoch 47/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.6204 - acc: 0.9113 - val_loss: 0.5715 - val_acc: 0.9412\n",
      "Epoch 48/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.6054 - acc: 0.9064 - val_loss: 0.5545 - val_acc: 0.9412\n",
      "Epoch 49/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.5695 - acc: 0.9310 - val_loss: 0.5375 - val_acc: 0.9412\n",
      "Epoch 50/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.5729 - acc: 0.9261 - val_loss: 0.5211 - val_acc: 0.9412\n",
      "Epoch 51/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.5475 - acc: 0.9409 - val_loss: 0.5046 - val_acc: 0.9412\n",
      "Epoch 52/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.5143 - acc: 0.9507 - val_loss: 0.4881 - val_acc: 0.9412\n",
      "Epoch 53/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.5143 - acc: 0.9557 - val_loss: 0.4732 - val_acc: 0.9608\n",
      "Epoch 54/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.5137 - acc: 0.9458 - val_loss: 0.4590 - val_acc: 0.9608\n",
      "Epoch 55/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.4805 - acc: 0.9409 - val_loss: 0.4463 - val_acc: 0.9608\n",
      "Epoch 56/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.4859 - acc: 0.9606 - val_loss: 0.4342 - val_acc: 0.9608\n",
      "Epoch 57/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.4812 - acc: 0.9606 - val_loss: 0.4238 - val_acc: 0.9608\n",
      "Epoch 58/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.4466 - acc: 0.9754 - val_loss: 0.4131 - val_acc: 0.9608\n",
      "Epoch 59/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.4289 - acc: 0.9754 - val_loss: 0.4028 - val_acc: 0.9608\n",
      "Epoch 60/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.4389 - acc: 0.9754 - val_loss: 0.3925 - val_acc: 0.9608\n",
      "Epoch 61/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.4093 - acc: 0.9754 - val_loss: 0.3824 - val_acc: 0.9608\n",
      "Epoch 62/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3999 - acc: 0.9803 - val_loss: 0.3730 - val_acc: 0.9608\n",
      "Epoch 63/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3927 - acc: 0.9901 - val_loss: 0.3661 - val_acc: 0.9608\n",
      "Epoch 64/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3899 - acc: 0.9754 - val_loss: 0.3584 - val_acc: 0.9608\n",
      "Epoch 65/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3749 - acc: 0.9852 - val_loss: 0.3505 - val_acc: 0.9608\n",
      "Epoch 66/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3793 - acc: 0.9852 - val_loss: 0.3420 - val_acc: 0.9608\n",
      "Epoch 67/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3473 - acc: 0.9852 - val_loss: 0.3346 - val_acc: 0.9608\n",
      "Epoch 68/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3379 - acc: 0.9754 - val_loss: 0.3273 - val_acc: 0.9608\n",
      "Epoch 69/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3189 - acc: 0.9901 - val_loss: 0.3188 - val_acc: 0.9608\n",
      "Epoch 70/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3138 - acc: 0.9803 - val_loss: 0.3098 - val_acc: 0.9608\n",
      "Epoch 71/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3142 - acc: 0.9852 - val_loss: 0.3016 - val_acc: 0.9608\n",
      "Epoch 72/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2975 - acc: 0.9803 - val_loss: 0.2942 - val_acc: 0.9608\n",
      "Epoch 73/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2851 - acc: 0.9901 - val_loss: 0.2848 - val_acc: 0.9608\n",
      "Epoch 74/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2786 - acc: 0.9901 - val_loss: 0.2785 - val_acc: 0.9608\n",
      "Epoch 75/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2703 - acc: 0.9852 - val_loss: 0.2732 - val_acc: 0.9608\n",
      "Epoch 76/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2583 - acc: 0.9901 - val_loss: 0.2683 - val_acc: 0.9608\n",
      "Epoch 77/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2527 - acc: 0.9852 - val_loss: 0.2634 - val_acc: 0.9608\n",
      "Epoch 78/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2350 - acc: 0.9901 - val_loss: 0.2587 - val_acc: 0.9608\n",
      "Epoch 79/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.2381 - acc: 0.9901 - val_loss: 0.2543 - val_acc: 0.9608\n",
      "Epoch 80/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.2496 - acc: 0.9803 - val_loss: 0.2502 - val_acc: 0.9608\n",
      "Epoch 81/100\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2254 - acc: 0.9901 - val_loss: 0.2462 - val_acc: 0.9608\n",
      "Epoch 82/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.2139 - acc: 0.9901 - val_loss: 0.2423 - val_acc: 0.9608\n",
      "Epoch 83/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.2085 - acc: 0.9852 - val_loss: 0.2386 - val_acc: 0.9608\n",
      "Epoch 84/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1908 - acc: 0.9901 - val_loss: 0.2350 - val_acc: 0.9608\n",
      "Epoch 85/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1919 - acc: 0.9901 - val_loss: 0.2315 - val_acc: 0.9608\n",
      "Epoch 86/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1884 - acc: 0.9852 - val_loss: 0.2281 - val_acc: 0.9608\n",
      "Epoch 87/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1878 - acc: 0.9852 - val_loss: 0.2250 - val_acc: 0.9608\n",
      "Epoch 88/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1818 - acc: 0.9901 - val_loss: 0.2220 - val_acc: 0.9608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1734 - acc: 0.9901 - val_loss: 0.2193 - val_acc: 0.9608\n",
      "Epoch 90/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1728 - acc: 0.9951 - val_loss: 0.2158 - val_acc: 0.9608\n",
      "Epoch 91/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1503 - acc: 0.9951 - val_loss: 0.2121 - val_acc: 0.9608\n",
      "Epoch 92/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1592 - acc: 0.9951 - val_loss: 0.2095 - val_acc: 0.9608\n",
      "Epoch 93/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1635 - acc: 0.9951 - val_loss: 0.2077 - val_acc: 0.9608\n",
      "Epoch 94/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1350 - acc: 0.9901 - val_loss: 0.2069 - val_acc: 0.9608\n",
      "Epoch 95/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1379 - acc: 0.9951 - val_loss: 0.2069 - val_acc: 0.9608\n",
      "Epoch 96/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1544 - acc: 0.9901 - val_loss: 0.3531 - val_acc: 0.9216\n",
      "Epoch 97/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1994 - acc: 0.9754 - val_loss: 0.3563 - val_acc: 0.9216\n",
      "Epoch 98/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.2213 - acc: 0.9754 - val_loss: 0.3547 - val_acc: 0.9216\n",
      "Epoch 99/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1902 - acc: 0.9754 - val_loss: 0.3538 - val_acc: 0.9216\n",
      "Epoch 100/100\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1962 - acc: 0.9754 - val_loss: 0.3545 - val_acc: 0.9216\n",
      "5072.993871688843\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "results, histories = search()\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [2.2832119464874268, 2.2261219024658203, 2.172034978866577, 2.121187686920166, 2.0728635787963867, 2.026477813720703, 1.9819071292877197, 1.9384453296661377, 1.895646333694458, 1.8536524772644043, 1.8127917051315308, 1.7724930047988892, 1.7319284677505493, 1.6911121606826782, 1.6507118940353394, 1.6110646724700928, 1.571265697479248, 1.5312467813491821, 1.4904510974884033, 1.4488615989685059, 1.4062772989273071, 1.3633582592010498, 1.3198163509368896, 1.2760250568389893, 1.2317285537719727, 1.1864784955978394, 1.1415950059890747, 1.0977016687393188, 1.0558370351791382, 1.015629768371582, 0.977288007736206, 0.9404245018959045, 0.9043866991996765, 0.8701678514480591, 0.836543083190918, 0.8044388294219971, 0.7743943929672241, 0.7464659214019775, 0.7198847532272339, 0.6946978569030762, 0.6706190705299377, 0.647598147392273, 0.6256670355796814, 0.6043695211410522, 0.5836827754974365, 0.5638894438743591, 0.5445824861526489, 0.5252348184585571, 0.5061926245689392, 0.48749294877052307, 0.46915119886398315, 0.4510710537433624, 0.4332517385482788, 0.41576671600341797, 0.39831778407096863, 0.38162723183631897, 0.36605918407440186, 0.35121652483940125, 0.33586764335632324, 0.3208068609237671, 0.30675163865089417, 0.2936655282974243, 0.28120896220207214, 0.2692204713821411, 0.25807473063468933, 0.24750283360481262, 0.23739349842071533, 0.2275615632534027, 0.21813267469406128, 0.20910052955150604, 0.2007671594619751, 0.1923142969608307, 0.18420028686523438, 0.17626400291919708, 0.1687185913324356, 0.16158455610275269, 0.15490974485874176, 0.1485419124364853, 0.14269810914993286, 0.1378665417432785, 0.1324436217546463, 0.12736591696739197, 0.12235982716083527, 0.1176055371761322, 0.11299701780080795, 0.11271274834871292, 0.11312578618526459, 0.11260596662759781, 0.11177585273981094, 0.10993365198373795, 0.10635770857334137, 0.10439446568489075, 0.10226324945688248, 0.10031680762767792, 0.09799902886152267, 0.10017100721597672, 0.10210949182510376, 0.10340612381696701, 0.10457540303468704, 0.0944487601518631], 'val_acc': [0.08571428805589676, 0.11428571492433548, 0.15238095819950104, 0.190476194024086, 0.2571428716182709, 0.3523809611797333, 0.41904762387275696, 0.46666666865348816, 0.5523809790611267, 0.6095238327980042, 0.6476190686225891, 0.6857143044471741, 0.6952381134033203, 0.6952381134033203, 0.7047619223594666, 0.7142857313156128, 0.723809540271759, 0.761904776096344, 0.761904776096344, 0.7714285850524902, 0.7809523940086365, 0.7809523940086365, 0.7904762029647827, 0.7904762029647827, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.8095238208770752, 0.8095238208770752, 0.8190476298332214, 0.8190476298332214, 0.8380952477455139, 0.8476190567016602, 0.8476190567016602, 0.8476190567016602, 0.8476190567016602, 0.8476190567016602, 0.8476190567016602, 0.8476190567016602, 0.8571428656578064, 0.8761904835700989, 0.8952381014823914, 0.8952381014823914, 0.8952381014823914, 0.8952381014823914, 0.9047619104385376, 0.9047619104385376, 0.9142857193946838, 0.9142857193946838, 0.9428571462631226, 0.9428571462631226, 0.9428571462631226, 0.9428571462631226, 0.9333333373069763, 0.9428571462631226, 0.9428571462631226, 0.9428571462631226, 0.9428571462631226, 0.9428571462631226, 0.9523809552192688, 0.9523809552192688, 0.9523809552192688, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9714285731315613, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9904761910438538, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075, 0.9809523820877075], 'loss': [2.3119888305664062, 2.2450108528137207, 2.184790849685669, 2.130927085876465, 2.0727310180664062, 2.045677900314331, 2.0004820823669434, 1.932504653930664, 1.888278603553772, 1.8539745807647705, 1.8076584339141846, 1.7692838907241821, 1.719512701034546, 1.703305721282959, 1.6463940143585205, 1.5993480682373047, 1.5629127025604248, 1.5191504955291748, 1.4952027797698975, 1.4508867263793945, 1.386173963546753, 1.369852066040039, 1.326398253440857, 1.276102900505066, 1.2495609521865845, 1.2160910367965698, 1.1710048913955688, 1.140881896018982, 1.0851290225982666, 1.0270631313323975, 1.0125213861465454, 0.9649302959442139, 0.9258963465690613, 0.9034995436668396, 0.8611916899681091, 0.8317080736160278, 0.8173865675926208, 0.7781152129173279, 0.731408417224884, 0.6964701414108276, 0.670367419719696, 0.6647752523422241, 0.648523211479187, 0.6102768778800964, 0.590282678604126, 0.5719795823097229, 0.5261770486831665, 0.5355139374732971, 0.5050795674324036, 0.5000619888305664, 0.46139663457870483, 0.45766064524650574, 0.4342672824859619, 0.4098663032054901, 0.3910885155200958, 0.37796035408973694, 0.376608669757843, 0.3504795730113983, 0.3329799771308899, 0.3183535933494568, 0.30641135573387146, 0.27943840622901917, 0.2844313383102417, 0.262371689081192, 0.2556808292865753, 0.2534916400909424, 0.2281757891178131, 0.21625159680843353, 0.22045135498046875, 0.22077502310276031, 0.20572319626808167, 0.18907172977924347, 0.17593799531459808, 0.17340633273124695, 0.1655946969985962, 0.15913720428943634, 0.15198789536952972, 0.14510686695575714, 0.14637477695941925, 0.13581576943397522, 0.13856065273284912, 0.12735925614833832, 0.12192202359437943, 0.12031587213277817, 0.10495098680257797, 0.10457471758127213, 0.10218831896781921, 0.09680109471082687, 0.09119940549135208, 0.098963163793087, 0.09605958312749863, 0.09202276170253754, 0.08349929004907608, 0.08394714444875717, 0.0729915201663971, 0.08025401085615158, 0.07890257984399796, 0.069435253739357, 0.07246343791484833, 0.06756269186735153], 'acc': [0.08095238357782364, 0.09285714477300644, 0.18571428954601288, 0.20000000298023224, 0.2547619044780731, 0.3214285671710968, 0.3857142925262451, 0.45476189255714417, 0.526190459728241, 0.5452380776405334, 0.5880952477455139, 0.6404761672019958, 0.6452381014823914, 0.6214285492897034, 0.723809540271759, 0.7190476059913635, 0.7404761910438538, 0.7333333492279053, 0.723809540271759, 0.738095223903656, 0.7857142686843872, 0.788095235824585, 0.7928571701049805, 0.8214285969734192, 0.8142856955528259, 0.8214285969734192, 0.8261904716491699, 0.8404762148857117, 0.8357142806053162, 0.8666666746139526, 0.8642857074737549, 0.8619047403335571, 0.8642857074737549, 0.8690476417541504, 0.8666666746139526, 0.8809523582458496, 0.8738095164299011, 0.8952381014823914, 0.8928571343421936, 0.8880952596664429, 0.8999999761581421, 0.8952381014823914, 0.9095237851142883, 0.9047619104385376, 0.9095237851142883, 0.9095237851142883, 0.9119047522544861, 0.9047619104385376, 0.9214285612106323, 0.9357143044471741, 0.938095211982727, 0.9285714030265808, 0.9523809552192688, 0.9428571462631226, 0.9595237970352173, 0.961904764175415, 0.9690476059913635, 0.961904764175415, 0.9785714149475098, 0.9690476059913635, 0.9785714149475098, 0.9809523820877075, 0.9785714149475098, 0.9857142567634583, 0.9857142567634583, 0.9785714149475098, 0.9928571581840515, 0.9857142567634583, 0.9952380657196045, 0.9857142567634583, 0.988095223903656, 0.9928571581840515, 0.9904761910438538, 0.9928571581840515, 0.9928571581840515, 0.9952380657196045, 0.9928571581840515, 0.9952380657196045, 0.9928571581840515, 0.9952380657196045, 0.9952380657196045, 0.9952380657196045, 0.9928571581840515, 0.9976190328598022, 1.0, 0.9976190328598022, 0.9952380657196045, 0.9976190328598022, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9976190328598022]}\n"
     ]
    }
   ],
   "source": [
    "print(histories['11_20'].history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"histories.pkl\", \"rb\") as f:\n",
    "    histories2  = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.18692810833454132,\n",
       "  0.265359491109848,\n",
       "  0.3150326907634735,\n",
       "  0.3986928164958954,\n",
       "  0.46405228972435,\n",
       "  0.5084967613220215,\n",
       "  0.5346405506134033,\n",
       "  0.5856209397315979,\n",
       "  0.6026144027709961,\n",
       "  0.6326797604560852,\n",
       "  0.6562091708183289,\n",
       "  0.6901960968971252,\n",
       "  0.7058823704719543,\n",
       "  0.7176470756530762,\n",
       "  0.7137255072593689,\n",
       "  0.7202614545822144,\n",
       "  0.7424836754798889,\n",
       "  0.7503268122673035,\n",
       "  0.7529411911964417,\n",
       "  0.758169949054718,\n",
       "  0.7803921699523926,\n",
       "  0.7816993594169617,\n",
       "  0.7934640645980835,\n",
       "  0.7921568751335144,\n",
       "  0.8039215803146362,\n",
       "  0.8196078538894653,\n",
       "  0.8209150433540344,\n",
       "  0.8418300747871399,\n",
       "  0.8339869379997253,\n",
       "  0.843137264251709,\n",
       "  0.8588235378265381,\n",
       "  0.8679738640785217,\n",
       "  0.8797385692596436,\n",
       "  0.8797385692596436,\n",
       "  0.8797385692596436,\n",
       "  0.8980392217636108,\n",
       "  0.9019607901573181,\n",
       "  0.9111111164093018,\n",
       "  0.8993464112281799,\n",
       "  0.9084967374801636,\n",
       "  0.9071895480155945,\n",
       "  0.9215686321258545,\n",
       "  0.9189542531967163,\n",
       "  0.9241830110549927,\n",
       "  0.9241830110549927,\n",
       "  0.9267973899841309,\n",
       "  0.9281045794487,\n",
       "  0.9333333373069763,\n",
       "  0.9333333373069763,\n",
       "  0.9346405267715454,\n",
       "  0.9411764740943909,\n",
       "  0.94248366355896,\n",
       "  0.9450980424880981,\n",
       "  0.9490196108818054,\n",
       "  0.9542483687400818,\n",
       "  0.9516339898109436,\n",
       "  0.9542483687400818,\n",
       "  0.9529411792755127,\n",
       "  0.9555555582046509,\n",
       "  0.9542483687400818,\n",
       "  0.9607843160629272,\n",
       "  0.9581699371337891,\n",
       "  0.9647058844566345,\n",
       "  0.9620915055274963,\n",
       "  0.9633986949920654,\n",
       "  0.9673202633857727,\n",
       "  0.9660130739212036,\n",
       "  0.9686274528503418,\n",
       "  0.97124183177948,\n",
       "  0.9673202633857727,\n",
       "  0.9686274528503418,\n",
       "  0.97124183177948,\n",
       "  0.9686274528503418,\n",
       "  0.9673202633857727,\n",
       "  0.9725490212440491,\n",
       "  0.97124183177948,\n",
       "  0.9725490212440491,\n",
       "  0.9738562107086182,\n",
       "  0.9738562107086182,\n",
       "  0.97124183177948,\n",
       "  0.9738562107086182,\n",
       "  0.9751634001731873,\n",
       "  0.9764705896377563,\n",
       "  0.97124183177948,\n",
       "  0.9725490212440491,\n",
       "  0.9738562107086182,\n",
       "  0.9751634001731873,\n",
       "  0.9777777791023254,\n",
       "  0.9738562107086182,\n",
       "  0.9751634001731873,\n",
       "  0.9764705896377563,\n",
       "  0.9751634001731873,\n",
       "  0.9777777791023254,\n",
       "  0.9751634001731873,\n",
       "  0.9764705896377563,\n",
       "  0.9777777791023254,\n",
       "  0.9751634001731873,\n",
       "  0.9764705896377563,\n",
       "  0.9751634001731873,\n",
       "  0.9790849685668945],\n",
       " 'loss': [2.160057783126831,\n",
       "  2.1044516563415527,\n",
       "  2.0562450885772705,\n",
       "  1.9905180931091309,\n",
       "  1.936949610710144,\n",
       "  1.8946715593338013,\n",
       "  1.8409159183502197,\n",
       "  1.7887873649597168,\n",
       "  1.739530086517334,\n",
       "  1.7041648626327515,\n",
       "  1.6343469619750977,\n",
       "  1.5999888181686401,\n",
       "  1.5500730276107788,\n",
       "  1.5060378313064575,\n",
       "  1.4621913433074951,\n",
       "  1.4145209789276123,\n",
       "  1.3555951118469238,\n",
       "  1.3305481672286987,\n",
       "  1.277451992034912,\n",
       "  1.2270582914352417,\n",
       "  1.1990423202514648,\n",
       "  1.153903841972351,\n",
       "  1.123374581336975,\n",
       "  1.091139554977417,\n",
       "  1.0449258089065552,\n",
       "  1.0151735544204712,\n",
       "  0.9767515063285828,\n",
       "  0.963182806968689,\n",
       "  0.9281497597694397,\n",
       "  0.9079471826553345,\n",
       "  0.8409088850021362,\n",
       "  0.8467741012573242,\n",
       "  0.7935898900032043,\n",
       "  0.7775887846946716,\n",
       "  0.7632379531860352,\n",
       "  0.7305830121040344,\n",
       "  0.7046914100646973,\n",
       "  0.6829749941825867,\n",
       "  0.6635549664497375,\n",
       "  0.6542179584503174,\n",
       "  0.6297030448913574,\n",
       "  0.6116117835044861,\n",
       "  0.5934680700302124,\n",
       "  0.5673546195030212,\n",
       "  0.5543705821037292,\n",
       "  0.5532989501953125,\n",
       "  0.5268306136131287,\n",
       "  0.5184839963912964,\n",
       "  0.501911461353302,\n",
       "  0.48295143246650696,\n",
       "  0.4660651981830597,\n",
       "  0.45720160007476807,\n",
       "  0.44393250346183777,\n",
       "  0.4337090253829956,\n",
       "  0.4172239601612091,\n",
       "  0.4026755392551422,\n",
       "  0.3945203721523285,\n",
       "  0.38357341289520264,\n",
       "  0.3675486445426941,\n",
       "  0.36047112941741943,\n",
       "  0.3496575951576233,\n",
       "  0.33213019371032715,\n",
       "  0.31696560978889465,\n",
       "  0.3170960545539856,\n",
       "  0.2934812605381012,\n",
       "  0.28508561849594116,\n",
       "  0.28112155199050903,\n",
       "  0.27151966094970703,\n",
       "  0.2620702087879181,\n",
       "  0.2554934322834015,\n",
       "  0.25529882311820984,\n",
       "  0.24086232483386993,\n",
       "  0.2419806569814682,\n",
       "  0.22388942539691925,\n",
       "  0.2088213413953781,\n",
       "  0.2195621132850647,\n",
       "  0.20349514484405518,\n",
       "  0.20526716113090515,\n",
       "  0.19523000717163086,\n",
       "  0.19299156963825226,\n",
       "  0.18685536086559296,\n",
       "  0.17622579634189606,\n",
       "  0.17155107855796814,\n",
       "  0.17353902757167816,\n",
       "  0.16758304834365845,\n",
       "  0.1605871468782425,\n",
       "  0.15395908057689667,\n",
       "  0.15086600184440613,\n",
       "  0.1462939828634262,\n",
       "  0.14511258900165558,\n",
       "  0.13899628818035126,\n",
       "  0.14275944232940674,\n",
       "  0.13293638825416565,\n",
       "  0.13047592341899872,\n",
       "  0.1268923133611679,\n",
       "  0.11888530105352402,\n",
       "  0.12430056929588318,\n",
       "  0.11703799664974213,\n",
       "  0.11917876452207565,\n",
       "  0.10947822034358978],\n",
       " 'val_acc': [0.28125,\n",
       "  0.375,\n",
       "  0.4479166567325592,\n",
       "  0.5,\n",
       "  0.53125,\n",
       "  0.5833333134651184,\n",
       "  0.6302083134651184,\n",
       "  0.671875,\n",
       "  0.6875,\n",
       "  0.7135416865348816,\n",
       "  0.7239583134651184,\n",
       "  0.7239583134651184,\n",
       "  0.7291666865348816,\n",
       "  0.7291666865348816,\n",
       "  0.7395833134651184,\n",
       "  0.7447916865348816,\n",
       "  0.7447916865348816,\n",
       "  0.7604166865348816,\n",
       "  0.78125,\n",
       "  0.7864583134651184,\n",
       "  0.7916666865348816,\n",
       "  0.7916666865348816,\n",
       "  0.8125,\n",
       "  0.828125,\n",
       "  0.8385416865348816,\n",
       "  0.859375,\n",
       "  0.859375,\n",
       "  0.859375,\n",
       "  0.8645833134651184,\n",
       "  0.875,\n",
       "  0.8854166865348816,\n",
       "  0.890625,\n",
       "  0.8958333134651184,\n",
       "  0.8958333134651184,\n",
       "  0.9010416865348816,\n",
       "  0.9010416865348816,\n",
       "  0.90625,\n",
       "  0.90625,\n",
       "  0.9322916865348816,\n",
       "  0.9375,\n",
       "  0.9427083134651184,\n",
       "  0.9479166865348816,\n",
       "  0.9479166865348816,\n",
       "  0.9479166865348816,\n",
       "  0.9479166865348816,\n",
       "  0.9479166865348816,\n",
       "  0.9479166865348816,\n",
       "  0.9479166865348816,\n",
       "  0.9479166865348816,\n",
       "  0.9479166865348816,\n",
       "  0.953125,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9739583134651184,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816,\n",
       "  0.9791666865348816],\n",
       " 'val_loss': [2.098386526107788,\n",
       "  2.0433835983276367,\n",
       "  1.9897165298461914,\n",
       "  1.937765121459961,\n",
       "  1.8877328634262085,\n",
       "  1.8385306596755981,\n",
       "  1.7900727987289429,\n",
       "  1.7417923212051392,\n",
       "  1.6933302879333496,\n",
       "  1.644788146018982,\n",
       "  1.5961599349975586,\n",
       "  1.5473990440368652,\n",
       "  1.4980125427246094,\n",
       "  1.4483747482299805,\n",
       "  1.3999696969985962,\n",
       "  1.352856993675232,\n",
       "  1.306846261024475,\n",
       "  1.262193202972412,\n",
       "  1.2188496589660645,\n",
       "  1.1764183044433594,\n",
       "  1.1350312232971191,\n",
       "  1.0950034856796265,\n",
       "  1.0563701391220093,\n",
       "  1.019148349761963,\n",
       "  0.983614444732666,\n",
       "  0.9495210647583008,\n",
       "  0.916830837726593,\n",
       "  0.8856690526008606,\n",
       "  0.8559078574180603,\n",
       "  0.827363908290863,\n",
       "  0.7998202443122864,\n",
       "  0.7732303738594055,\n",
       "  0.747359037399292,\n",
       "  0.7224128842353821,\n",
       "  0.6984832286834717,\n",
       "  0.6757299304008484,\n",
       "  0.6540500521659851,\n",
       "  0.6331753730773926,\n",
       "  0.6132656931877136,\n",
       "  0.5942286849021912,\n",
       "  0.5759261250495911,\n",
       "  0.5580081343650818,\n",
       "  0.5404663681983948,\n",
       "  0.5233201384544373,\n",
       "  0.5065217614173889,\n",
       "  0.48986637592315674,\n",
       "  0.47286954522132874,\n",
       "  0.4565488398075104,\n",
       "  0.4411565065383911,\n",
       "  0.42631685733795166,\n",
       "  0.41126537322998047,\n",
       "  0.3966933786869049,\n",
       "  0.38250604271888733,\n",
       "  0.3687262535095215,\n",
       "  0.35545316338539124,\n",
       "  0.34268105030059814,\n",
       "  0.33029428124427795,\n",
       "  0.3182303011417389,\n",
       "  0.30636709928512573,\n",
       "  0.29492124915122986,\n",
       "  0.2837150990962982,\n",
       "  0.272525429725647,\n",
       "  0.26175346970558167,\n",
       "  0.25133976340293884,\n",
       "  0.24200241267681122,\n",
       "  0.23335452377796173,\n",
       "  0.22511400282382965,\n",
       "  0.21733598411083221,\n",
       "  0.20987939834594727,\n",
       "  0.20281864702701569,\n",
       "  0.19595925509929657,\n",
       "  0.18937699496746063,\n",
       "  0.1830965280532837,\n",
       "  0.17700965702533722,\n",
       "  0.17115019261837006,\n",
       "  0.1654094159603119,\n",
       "  0.159755676984787,\n",
       "  0.1542542278766632,\n",
       "  0.14900913834571838,\n",
       "  0.14416271448135376,\n",
       "  0.13974888622760773,\n",
       "  0.13569040596485138,\n",
       "  0.1318589448928833,\n",
       "  0.12800727784633636,\n",
       "  0.12392403930425644,\n",
       "  0.11975175142288208,\n",
       "  0.11610474437475204,\n",
       "  0.11279713362455368,\n",
       "  0.10965219140052795,\n",
       "  0.10659132152795792,\n",
       "  0.10353031009435654,\n",
       "  0.10053785890340805,\n",
       "  0.09763655811548233,\n",
       "  0.09486842155456543,\n",
       "  0.09216979891061783,\n",
       "  0.08970464020967484,\n",
       "  0.08729169517755508,\n",
       "  0.08494243770837784,\n",
       "  0.08267436176538467,\n",
       "  0.08045166730880737]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories['5_20'].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 364 samples, validate on 92 samples\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 0s 660us/step - loss: 0.0677 - acc: 1.0000 - val_loss: 0.1058 - val_acc: 0.9783\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 0s 662us/step - loss: 0.0738 - acc: 0.9973 - val_loss: 0.1052 - val_acc: 0.9783\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 0s 909us/step - loss: 0.0645 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9783\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 0s 712us/step - loss: 0.0659 - acc: 1.0000 - val_loss: 0.1052 - val_acc: 0.9783\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 0s 673us/step - loss: 0.0655 - acc: 1.0000 - val_loss: 0.1058 - val_acc: 0.9783\n"
     ]
    }
   ],
   "source": [
    "history = rnn.fit(X_train_rnn, Y_train_rnn, epochs=5, batch_size = X_train_rnn.shape[0], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "(14, 9)\n",
      "Max Preds time [8]\n",
      "Pred Golf-Swing Actual Kicking\n",
      "\n",
      "Max Preds time [0]\n",
      "Pred Kicking Actual Kicking\n",
      "\n",
      "Max Preds time [1, 1, 1, 1]\n",
      "Pred Riding-Horse Actual Riding-Horse\n",
      "\n",
      "Max Preds time [7, 7]\n",
      "Pred Walking Actual Riding-Horse\n",
      "\n",
      "Max Preds time [1, 1, 1, 1, 1]\n",
      "Pred Riding-Horse Actual Running\n",
      "\n",
      "Max Preds time [4, 4, 4, 4, 4]\n",
      "Pred Swing-Bench Actual SkateBoarding\n",
      "\n",
      "Max Preds time [4, 4, 4]\n",
      "Pred Swing-Bench Actual Swing-Bench\n",
      "\n",
      "Max Preds time [4, 4, 4]\n",
      "Pred Swing-Bench Actual Swing-Bench\n",
      "\n",
      "Max Preds time [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "Pred Lifting Actual Lifting\n",
      "\n",
      "Max Preds time [6]\n",
      "Pred Swing-Side Actual Swing-Side\n",
      "\n",
      "Max Preds time [7, 7, 7, 5]\n",
      "Pred Walking Actual Walking\n",
      "\n",
      "Max Preds time [7, 7, 7, 7, 7, 7, 7, 7, 2]\n",
      "Pred Walking Actual Walking\n",
      "\n",
      "Max Preds time [8]\n",
      "Pred Golf-Swing Actual Golf-Swing\n",
      "\n",
      "Max Preds time [8, 8, 8, 8]\n",
      "Pred Golf-Swing Actual Golf-Swing\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.42857142857143"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rnn = load_model('models/LSTM_Strided/500ep_valacc_97_single_LSTM.h5')\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "evaluate(X_test,Y_test, rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.save('models/LSTM_Strided/100ep_valacc_94_double_LSTM_dropout_10_30.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_test_dataset(image_size, stride = 10, max_len = 40):\n",
    "    \n",
    "    model = load_model('models/Conv/17epochs_valacc_94.h5')\n",
    "    \n",
    "    X_test_images = []\n",
    "    Y_test_images = []\n",
    "    \n",
    "    VIDEOS_DIR = './UCF_Unseen/'\n",
    "    IMAGES_DIR = './UCF_Images/'\n",
    "    \n",
    "    videos = []\n",
    "    for x in classes:\n",
    "        videos.append(list(os.listdir(VIDEOS_DIR+x+'/')))\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        cls = classes[i]\n",
    "\n",
    "        for j in range(len(videos[i])):\n",
    "            vid = videos[i][j]\n",
    "            video_r = VIDEOS_DIR+cls+'/'+ vid +'/'\n",
    "            image_r = IMAGES_DIR+cls+'/'+ vid +'/'\n",
    "            \n",
    "            filelist = sorted(list(os.listdir(image_r)))\n",
    "            X_train_images_class = []\n",
    "            \n",
    "            for file in filelist:\n",
    "                if file.endswith(\".png\"):\n",
    "                    image = load_image(image_r+file,image_size)\n",
    "                    X_train_images_class.append(image)\n",
    "            X_cnn = model_predict(model,np.array(X_train_images_class))\n",
    "            print(X_cnn.shape)\n",
    "            \n",
    "            del X_train_images_class\n",
    "            X_test_frames = []                                \n",
    "            for k in range(0,X_cnn.shape[0],stride):\n",
    "                lower = k\n",
    "                upper = min(X_cnn.shape[0],k+max_len)\n",
    "                if upper == X_cnn.shape[0]:\n",
    "                    X_test_frames.append(pad(X_cnn[lower:upper],max_len))\n",
    "                    X_test_images.append(np.array(X_test_frames))        \n",
    "                    Y_test_images.append(i)\n",
    "                    print(\"Padded frames\" , lower , \"to\" , upper)\n",
    "                    break\n",
    "                else:\n",
    "                    X_test_frames.append(X_cnn[lower:upper])\n",
    "                    print(\"Added frames\" , lower , \"to\" , upper)\n",
    "                    \n",
    "            print(\"Processed\",videos[i][j],\"of\",\"class\",classes[i])\n",
    "\n",
    "    return X_test_images,Y_test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 128)\n",
      "Padded frames 0 to 22\n",
      "Processed 010 of class Kicking\n",
      "(23, 128)\n",
      "Padded frames 0 to 23\n",
      "Processed 006 of class Kicking\n",
      "(23, 128)\n",
      "Padded frames 0 to 23\n",
      "Processed 004 of class Kicking\n",
      "(20, 128)\n",
      "Padded frames 0 to 20\n",
      "Processed 008 of class Kicking\n",
      "(58, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Padded frames 20 to 58\n",
      "Processed 011 of class Riding-Horse\n",
      "(36, 128)\n",
      "Padded frames 0 to 36\n",
      "Processed 012 of class Riding-Horse\n",
      "(65, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Padded frames 30 to 65\n",
      "Processed 012 of class Running\n",
      "(70, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Padded frames 30 to 70\n",
      "Processed 011 of class SkateBoarding\n",
      "(70, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Padded frames 30 to 70\n",
      "Processed 012 of class SkateBoarding\n",
      "(50, 128)\n",
      "Added frames 0 to 40\n",
      "Padded frames 10 to 50\n",
      "Processed 018 of class Swing-Bench\n",
      "(50, 128)\n",
      "Added frames 0 to 40\n",
      "Padded frames 10 to 50\n",
      "Processed 020 of class Swing-Bench\n",
      "(50, 128)\n",
      "Added frames 0 to 40\n",
      "Padded frames 10 to 50\n",
      "Processed 019 of class Swing-Bench\n",
      "(127, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Added frames 30 to 70\n",
      "Added frames 40 to 80\n",
      "Added frames 50 to 90\n",
      "Added frames 60 to 100\n",
      "Added frames 70 to 110\n",
      "Added frames 80 to 120\n",
      "Padded frames 90 to 127\n",
      "Processed 006 of class Lifting\n",
      "(75, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Added frames 30 to 70\n",
      "Padded frames 40 to 75\n",
      "Processed 012 of class Swing-Side\n",
      "(7, 128)\n",
      "Padded frames 0 to 7\n",
      "Processed 013 of class Swing-Side\n",
      "(109, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Added frames 30 to 70\n",
      "Added frames 40 to 80\n",
      "Added frames 50 to 90\n",
      "Added frames 60 to 100\n",
      "Padded frames 70 to 109\n",
      "Processed 021 of class Walking\n",
      "(71, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Added frames 30 to 70\n",
      "Padded frames 40 to 71\n",
      "Processed 020 of class Walking\n",
      "(101, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Added frames 30 to 70\n",
      "Added frames 40 to 80\n",
      "Added frames 50 to 90\n",
      "Added frames 60 to 100\n",
      "Padded frames 70 to 101\n",
      "Processed 022 of class Walking\n",
      "(60, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Padded frames 20 to 60\n",
      "Processed 009 of class Golf-Swing\n",
      "(60, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Padded frames 20 to 60\n",
      "Processed 005 of class Golf-Swing\n",
      "(60, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Padded frames 20 to 60\n",
      "Processed 007 of class Golf-Swing\n",
      "(60, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Padded frames 20 to 60\n",
      "Processed 008 of class Golf-Swing\n"
     ]
    }
   ],
   "source": [
    "X_test,Y_test = build_test_dataset((172,172))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (3, 40, 128),\n",
       " (1, 40, 128),\n",
       " (4, 40, 128),\n",
       " (4, 40, 128),\n",
       " (4, 40, 128),\n",
       " (2, 40, 128),\n",
       " (2, 40, 128),\n",
       " (2, 40, 128),\n",
       " (10, 40, 128),\n",
       " (5, 40, 128),\n",
       " (1, 40, 128),\n",
       " (8, 40, 128),\n",
       " (5, 40, 128),\n",
       " (8, 40, 128),\n",
       " (3, 40, 128),\n",
       " (3, 40, 128),\n",
       " (3, 40, 128),\n",
       " (3, 40, 128)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(X_test)\n",
    "[i.shape for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 9)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = convert_to_one_hot(np.array(Y_test), 9)\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Preds time [0]\n",
      "Pred Kicking Actual Kicking\n",
      "Max Preds time [0]\n",
      "Pred Kicking Actual Kicking\n",
      "Max Preds time [2]\n",
      "Pred Running Actual Kicking\n",
      "Max Preds time [7]\n",
      "Pred Walking Actual Kicking\n",
      "Max Preds time [1, 1, 1]\n",
      "Pred Riding-Horse Actual Riding-Horse\n",
      "Max Preds time [1]\n",
      "Pred Riding-Horse Actual Riding-Horse\n",
      "Max Preds time [8, 8, 8, 8]\n",
      "Pred Golf-Swing Actual Running\n",
      "Max Preds time [0, 3, 3, 3]\n",
      "Pred SkateBoarding Actual SkateBoarding\n",
      "Max Preds time [2, 2, 2, 2]\n",
      "Pred Running Actual SkateBoarding\n",
      "Max Preds time [4, 4]\n",
      "Pred Swing-Bench Actual Swing-Bench\n",
      "Max Preds time [4, 4]\n",
      "Pred Swing-Bench Actual Swing-Bench\n",
      "Max Preds time [4, 4]\n",
      "Pred Swing-Bench Actual Swing-Bench\n",
      "Max Preds time [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "Pred Lifting Actual Lifting\n",
      "Max Preds time [6, 6, 6, 6, 6]\n",
      "Pred Swing-Side Actual Swing-Side\n",
      "Max Preds time [6]\n",
      "Pred Swing-Side Actual Swing-Side\n",
      "Max Preds time [7, 7, 7, 7, 7, 7, 7, 7]\n",
      "Pred Walking Actual Walking\n",
      "Max Preds time [7, 7, 7, 7, 7]\n",
      "Pred Walking Actual Walking\n",
      "Max Preds time [7, 7, 7, 7, 7, 7, 7, 7]\n",
      "Pred Walking Actual Walking\n",
      "Max Preds time [8, 8, 8]\n",
      "Pred Golf-Swing Actual Golf-Swing\n",
      "Max Preds time [8, 8, 8]\n",
      "Pred Golf-Swing Actual Golf-Swing\n",
      "Max Preds time [8, 8, 8]\n",
      "Pred Golf-Swing Actual Golf-Swing\n",
      "Max Preds time [8, 8, 8]\n",
      "Pred Golf-Swing Actual Golf-Swing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.81818181818183"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_test,Y_test,rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras_gpu_tensorflow]",
   "language": "python",
   "name": "conda-env-keras_gpu_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
